<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Spark MLlib / Other ML Libraries / scikit-learn - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/img/favicon.ico"/>
<script>window.settings = {"sparkDocsSearchGoogleCx":"004588677886978090460:_rj0wilqwdm","dbcForumURL":"http://forums.databricks.com/","dbfsS3Host":"https://databricks-prod-storage-oregon.s3.amazonaws.com","enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"isAdmin":false,"enablePresentationTimerConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"clusters":false,"hideOffHeapCache":false,"applications":false,"useStaticGuide":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"sparkVersions":[{"key":"1.3.x","displayName":"Spark 1.3.0","packageLabel":"spark-1.3-jenkins-ip-10-2-0-138-U094163cf51-S47b89c350f-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.4.x","displayName":"Spark 1.4.1","packageLabel":"spark-1.4-jenkins-ip-10-2-0-138-U094163cf51-S2f95f6c227-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x","displayName":"Spark 1.6 Branch Preview","packageLabel":"spark-1.6-jenkins-ip-10-2-0-138-U094163cf51-S3436f2ea50-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.8.1","local":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":false,"enableStaticNotebooks":true,"dbcGuideURL":"#workspace/databricks_guide/00 Welcome to Databricks","enableClusterAclsConfig":false,"orgId":0,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":false,"driverLog4jFilePrefix":"log4j","enableMavenLibraries":true,"defaultSparkVersion":{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},"clusterPublisherRootId":5,"enableLatestJobRunResultPermalink":true,"enableSparkConfUI":true,"enableJdbcImport":true,"logfiles":"logfiles/","enableClusterDeltaUpdates":true,"csrfToken":"d3dde7ae-fd45-4989-86b8-e91415a5ebcf","useFixedStaticNotebookVersionForDevelopment":false,"enableBasicReactDialogBoxes":true,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableWorkspaceAclService":true,"enableWorkspaceAcls":true,"gitHash":"094163cf51fcd4717c3ea96799d1008723ae8985","userFullname":"Suresh Jayaram","enableImportFromUrl":true,"enableMiniClusters":false,"enableWebSocketDeltaUpdates":true,"enableDebugUI":false,"showHiddenSparkVersions":false,"allowNonAdminUsers":true,"userId":100017,"dbcSupportURL":"","staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/","enableSparkPackages":true,"enableNotebookHistoryUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"databricksGuideStaticUrl":"","notebookLoadingBackground":"#fff","enableNewJobRunDetailsPage":true,"enableDashboardExport":true,"user":"surjayaram@paypal.com","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"tablesPublisherRootId":7,"accounts":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":2388,"name":"Spark MLlib / Other ML Libraries / scikit-learn","language":"python","commands":[{"version":"CommandV1","origId":2389,"guid":"72442cb5-b5da-4ea9-bb9a-aa8977c72dc8","subtype":"command","commandType":"auto","position":2.0,"command":"%md # Using scikit-learn with Spark on Databricks Cloud\n\nThis notebook demonstrates how to take advantage of Spark and Databricks Cloud to use [scikit-learn](http://scikit-learn.org/), the popular Python library for doing Machine Learning on a single compute node.\n\nEven though the algorithms in scikit-learn are not distributed, we can still take advantage of distributed computation for certain ML tasks.  This can help with the transition from single-node workflows to fully distributed workflows: One can start by porting an existing workflow to Spark, begin to distribute certain tasks, and eventually move to fully distributed training via MLlib algorithms.\n\n**Contents**\n1. Running scikit-learn on the driver\n2. Distributing scikit-learn jobs\n3. Converting between scikit-learn and MLlib models","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401678E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"28e702d0-024d-48b0-a0af-ca5e2de06aa5"},{"version":"CommandV1","origId":2390,"guid":"9edd9e0d-5c2e-454a-ac5a-57d5591761d6","subtype":"command","commandType":"auto","position":3.0,"command":"%md ## 1. Running scikit-learn on the driver\n\nThe simplest way to use scikit-learn with Spark and DBC is to run scikit-learn jobs as usual.  However, this will run scikit-learn jobs on the driver, so **be careful** not to run large jobs, especially if other users are working on the same cluster as you.  Nevertheless, a reasonable way to port existing scikit-learn workflows to Spark and start benefiting from distributed computing is to: (a) copy the workflow into DBC and (b) start parallelizing the workflow piece-by-piece.  We discuss parallelization in the next section.\n\nIn this section, we will do the following:\n* Load data into a Pandas dataframe\n* Explore the data\n* Transform features\n* Hold out a random test dataset\n* Learn an initial model\n* Evaluate the initial model","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401688E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"587a0573-ffa3-42e4-a6a8-edab9e1c403b"},{"version":"CommandV1","origId":2391,"guid":"5ee9b0d9-08f2-4f9b-a80e-897857a8f3ad","subtype":"command","commandType":"auto","position":4.0,"command":"%md ### Load data into a Pandas dataframe\n\nWe will use the R \"diamonds\" dataset from the \"ggplot2\" package.  This is a dataset hosted on DBC.  To learn more about importing data, see [Accessing Data Notebook](../../03 Accessing Data/0 Accessing Data.html).\n\nOur task will be to predict the price of a diamond from its properties.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401696E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"7f2376f4-03f1-476f-a24b-3a1fe22c6ff1"},{"version":"CommandV1","origId":2392,"guid":"de905b4f-8eff-4e37-8f62-ea115fa8dba3","subtype":"command","commandType":"auto","position":5.0,"command":"displayHTML(sc.wholeTextFiles(\"/databricks-datasets/Rdatasets/data-001/doc/ggplot2/diamonds.html\").take(1)[0][1])","commandVersion":1,"state":"finished","results":{"type":"htmlSandbox","data":"<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n<html><head><title>R: Prices of 50,000 round cut diamonds</title>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"R.css\">\n</head><body>\n\n<table width=\"100%\" summary=\"page for diamonds\"><tr><td>diamonds</td><td align=\"right\">R Documentation</td></tr></table>\n\n<h2>Prices of 50,000 round cut diamonds</h2>\n\n<h3>Description</h3>\n\n<p>A dataset containing the prices and other attributes of almost 54,000\ndiamonds. The variables are as follows:\n</p>\n\n\n<h3>Usage</h3>\n\n<pre>\ndata(diamonds)\n</pre>\n\n\n<h3>Format</h3>\n\n<p>A data frame with 53940 rows and 10 variables</p>\n\n\n<h3>Details</h3>\n\n\n<ul>\n<li><p> price. price in US dollars (\\$326&ndash;\\$18,823)\n</p>\n</li>\n<li><p> carat. weight of the diamond (0.2&ndash;5.01)\n</p>\n</li>\n<li><p> cut. quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n</p>\n</li>\n<li><p> colour. diamond colour, from J (worst) to D (best)\n</p>\n</li>\n<li><p> clarity. a measurement of how clear the diamond is (I1 (worst), SI1, SI2, VS1, VS2, VVS1, VVS2, IF (best))\n</p>\n</li>\n<li><p> x. length in mm (0&ndash;10.74)\n</p>\n</li>\n<li><p> y. width in mm (0&ndash;58.9)\n</p>\n</li>\n<li><p> z. depth in mm (0&ndash;31.8)\n</p>\n</li>\n<li><p> depth. total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43&ndash;79)\n</p>\n</li>\n<li><p> table. width of top of diamond relative to widest point (43&ndash;95)\n</p>\n</li></ul>\n\n\n\n</body></html>\n","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806402239E12,"submitTime":1.435806401706E12,"finishTime":1.435806402867E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"72546a86-1910-4424-8840-670e680ed6f1"},{"version":"CommandV1","origId":2393,"guid":"440ff299-fa71-46b3-b0e1-5834002c35e9","subtype":"command","commandType":"auto","position":6.0,"command":"# Load data into a Pandas dataframe\nimport pandas\nimport cStringIO\nfrom pyspark.sql import *\nlocalData = sc.wholeTextFiles(\"/databricks-datasets/Rdatasets/data-001/csv/ggplot2/diamonds.csv\").collect()[0][1]\noutput = cStringIO.StringIO(localData)\npandasData = pandas.read_csv(output)\npandasData = pandasData.iloc[:,1:] # remove line number","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806402869E12,"submitTime":1.435806401715E12,"finishTime":1.435806403377E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"b6d2196f-6994-48f0-b355-1ac45cb6876a"},{"version":"CommandV1","origId":2394,"guid":"e9f17aa9-a41a-4c17-99f5-2dd6d06b3ff6","subtype":"command","commandType":"auto","position":7.0,"command":"%md ### Explore the data\n\nWe quickly demonstrate how to start exploring the data.  For a longer tutorial, see the [Visualizations Notebook](../../04 Visualizations/0 Visualizations Overview.html).","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401724E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"d84c4ebe-7359-4c63-9f11-c7b281c4c6e4"},{"version":"CommandV1","origId":2395,"guid":"3c2a57a3-c262-4a0d-ba55-eb1fe160938c","subtype":"command","commandType":"auto","position":8.0,"command":"# We can view the Pandas dataframe using Pandas' native display\npandasData","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>\n       carat        cut color clarity  depth  table  price     x     y     z\n0       0.23      Ideal     E     SI2   61.5     55    326  3.95  3.98  2.43\n1       0.21    Premium     E     SI1   59.8     61    326  3.89  3.84  2.31\n2       0.23       Good     E     VS1   56.9     65    327  4.05  4.07  2.31\n3       0.29    Premium     I     VS2   62.4     58    334  4.20  4.23  2.63\n4       0.31       Good     J     SI2   63.3     58    335  4.34  4.35  2.75\n5       0.24  Very Good     J    VVS2   62.8     57    336  3.94  3.96  2.48\n6       0.24  Very Good     I    VVS1   62.3     57    336  3.95  3.98  2.47\n7       0.26  Very Good     H     SI1   61.9     55    337  4.07  4.11  2.53\n8       0.22       Fair     E     VS2   65.1     61    337  3.87  3.78  2.49\n9       0.23  Very Good     H     VS1   59.4     61    338  4.00  4.05  2.39\n10      0.30       Good     J     SI1   64.0     55    339  4.25  4.28  2.73\n11      0.23      Ideal     J     VS1   62.8     56    340  3.93  3.90  2.46\n12      0.22    Premium     F     SI1   60.4     61    342  3.88  3.84  2.33\n13      0.31      Ideal     J     SI2   62.2     54    344  4.35  4.37  2.71\n14      0.20    Premium     E     SI2   60.2     62    345  3.79  3.75  2.27\n15      0.32    Premium     E      I1   60.9     58    345  4.38  4.42  2.68\n16      0.30      Ideal     I     SI2   62.0     54    348  4.31  4.34  2.68\n17      0.30       Good     J     SI1   63.4     54    351  4.23  4.29  2.70\n18      0.30       Good     J     SI1   63.8     56    351  4.23  4.26  2.71\n19      0.30  Very Good     J     SI1   62.7     59    351  4.21  4.27  2.66\n20      0.30       Good     I     SI2   63.3     56    351  4.26  4.30  2.71\n21      0.23  Very Good     E     VS2   63.8     55    352  3.85  3.92  2.48\n22      0.23  Very Good     H     VS1   61.0     57    353  3.94  3.96  2.41\n23      0.31  Very Good     J     SI1   59.4     62    353  4.39  4.43  2.62\n24      0.31  Very Good     J     SI1   58.1     62    353  4.44  4.47  2.59\n25      0.23  Very Good     G    VVS2   60.4     58    354  3.97  4.01  2.41\n26      0.24    Premium     I     VS1   62.5     57    355  3.97  3.94  2.47\n27      0.30  Very Good     J     VS2   62.2     57    357  4.28  4.30  2.67\n28      0.23  Very Good     D     VS2   60.5     61    357  3.96  3.97  2.40\n29      0.23  Very Good     F     VS1   60.9     57    357  3.96  3.99  2.42\n...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n53910   0.70    Premium     E     SI1   60.5     58   2753  5.74  5.77  3.48\n53911   0.57    Premium     E      IF   59.8     60   2753  5.43  5.38  3.23\n53912   0.61    Premium     F    VVS1   61.8     59   2753  5.48  5.40  3.36\n53913   0.80       Good     G     VS2   64.2     58   2753  5.84  5.81  3.74\n53914   0.84       Good     I     VS1   63.7     59   2753  5.94  5.90  3.77\n53915   0.77      Ideal     E     SI2   62.1     56   2753  5.84  5.86  3.63\n53916   0.74       Good     D     SI1   63.1     59   2753  5.71  5.74  3.61\n53917   0.90  Very Good     J     SI1   63.2     60   2753  6.12  6.09  3.86\n53918   0.76    Premium     I     VS1   59.3     62   2753  5.93  5.85  3.49\n53919   0.76      Ideal     I    VVS1   62.2     55   2753  5.89  5.87  3.66\n53920   0.70  Very Good     E     VS2   62.4     60   2755  5.57  5.61  3.49\n53921   0.70  Very Good     E     VS2   62.8     60   2755  5.59  5.65  3.53\n53922   0.70  Very Good     D     VS1   63.1     59   2755  5.67  5.58  3.55\n53923   0.73      Ideal     I     VS2   61.3     56   2756  5.80  5.84  3.57\n53924   0.73      Ideal     I     VS2   61.6     55   2756  5.82  5.84  3.59\n53925   0.79      Ideal     I     SI1   61.6     56   2756  5.95  5.97  3.67\n53926   0.71      Ideal     E     SI1   61.9     56   2756  5.71  5.73  3.54\n53927   0.79       Good     F     SI1   58.1     59   2756  6.06  6.13  3.54\n53928   0.79    Premium     E     SI2   61.4     58   2756  6.03  5.96  3.68\n53929   0.71      Ideal     G     VS1   61.4     56   2756  5.76  5.73  3.53\n53930   0.71    Premium     E     SI1   60.5     55   2756  5.79  5.74  3.49\n53931   0.71    Premium     F     SI1   59.8     62   2756  5.74  5.73  3.43\n53932   0.70  Very Good     E     VS2   60.5     59   2757  5.71  5.76  3.47\n53933   0.70  Very Good     E     VS2   61.2     59   2757  5.69  5.72  3.49\n53934   0.72    Premium     D     SI1   62.7     59   2757  5.69  5.73  3.58\n53935   0.72      Ideal     D     SI1   60.8     57   2757  5.75  5.76  3.50\n53936   0.72       Good     D     SI1   63.1     55   2757  5.69  5.75  3.61\n53937   0.70  Very Good     D     SI1   62.8     60   2757  5.66  5.68  3.56\n53938   0.86    Premium     H     SI2   61.0     58   2757  6.15  6.12  3.74\n53939   0.75      Ideal     D     SI2   62.2     55   2757  5.83  5.87  3.64\n\n[53940 rows x 10 columns]\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806403386E12,"submitTime":1.435806401732E12,"finishTime":1.435806403511E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"0d2aa9c6-0038-4cc9-ae8a-7a02a63be582"},{"version":"CommandV1","origId":2396,"guid":"4df2b612-2d0d-4849-a857-870209204be9","subtype":"command","commandType":"auto","position":9.0,"command":"%md We can make plots using Python tools like matplotlib.  For more examples, see the [Matplotlib and GGPlot Notebook](../../04 Visualizations/4 Matplotlib and GGPlot.html).","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.43580640174E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"cc96f99c-e03e-4725-9e4d-53dc9c92fac1"},{"version":"CommandV1","origId":2397,"guid":"f8ddb5f1-f022-4534-8af8-9e56462593ee","subtype":"command","commandType":"auto","position":10.0,"command":"import matplotlib.pyplot as plt\nplt.clf()\nplt.plot(pandasData['carat'], pandasData['price'], '.')\nplt.xlabel('carat')\nplt.ylabel('price')\ndisplay()","commandVersion":1,"state":"finished","results":{"type":"image","data":"cc6e7347-c501-47e8-a6f6-ab22fd003bcf.png","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.43580640352E12,"submitTime":1.43580640175E12,"finishTime":1.435806407262E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"5d045f52-2396-45cc-b7fb-00ac7232a794"},{"version":"CommandV1","origId":2398,"guid":"ea61cc68-ece2-436e-9df0-416986151dbf","subtype":"command","commandType":"auto","position":11.0,"command":"%md We can also convert the Pandas dataframe into a Spark DataFrame and use DBC's display methods.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401759E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"8107404c-bb53-4ba9-b409-9611836fd6ea"},{"version":"CommandV1","origId":2399,"guid":"1e323e02-cc80-4d06-be38-da97cae1278f","subtype":"command","commandType":"auto","position":12.0,"command":"# Create this plot by calling display on the Spark DataFrame, clicking the plot icon, selecting Plot Options, and creating a Histogram of 'carat' values.\nsparkDataframe = sqlContext.createDataFrame(pandasData)\ndisplay(sparkDataframe)","commandVersion":1,"state":"finished","results":{"type":"table","data":[[0.23,"Ideal","E","SI2",61.5,55.0,326.0,3.95,3.98,2.43],[0.21,"Premium","E","SI1",59.8,61.0,326.0,3.89,3.84,2.31],[0.23,"Good","E","VS1",56.9,65.0,327.0,4.05,4.07,2.31],[0.29,"Premium","I","VS2",62.4,58.0,334.0,4.2,4.23,2.63],[0.31,"Good","J","SI2",63.3,58.0,335.0,4.34,4.35,2.75],[0.24,"Very Good","J","VVS2",62.8,57.0,336.0,3.94,3.96,2.48],[0.24,"Very Good","I","VVS1",62.3,57.0,336.0,3.95,3.98,2.47],[0.26,"Very Good","H","SI1",61.9,55.0,337.0,4.07,4.11,2.53],[0.22,"Fair","E","VS2",65.1,61.0,337.0,3.87,3.78,2.49],[0.23,"Very Good","H","VS1",59.4,61.0,338.0,4.0,4.05,2.39],[0.3,"Good","J","SI1",64.0,55.0,339.0,4.25,4.28,2.73],[0.23,"Ideal","J","VS1",62.8,56.0,340.0,3.93,3.9,2.46],[0.22,"Premium","F","SI1",60.4,61.0,342.0,3.88,3.84,2.33],[0.31,"Ideal","J","SI2",62.2,54.0,344.0,4.35,4.37,2.71],[0.2,"Premium","E","SI2",60.2,62.0,345.0,3.79,3.75,2.27],[0.32,"Premium","E","I1",60.9,58.0,345.0,4.38,4.42,2.68],[0.3,"Ideal","I","SI2",62.0,54.0,348.0,4.31,4.34,2.68],[0.3,"Good","J","SI1",63.4,54.0,351.0,4.23,4.29,2.7],[0.3,"Good","J","SI1",63.8,56.0,351.0,4.23,4.26,2.71],[0.3,"Very Good","J","SI1",62.7,59.0,351.0,4.21,4.27,2.66],[0.3,"Good","I","SI2",63.3,56.0,351.0,4.26,4.3,2.71],[0.23,"Very Good","E","VS2",63.8,55.0,352.0,3.85,3.92,2.48],[0.23,"Very Good","H","VS1",61.0,57.0,353.0,3.94,3.96,2.41],[0.31,"Very Good","J","SI1",59.4,62.0,353.0,4.39,4.43,2.62],[0.31,"Very Good","J","SI1",58.1,62.0,353.0,4.44,4.47,2.59],[0.23,"Very Good","G","VVS2",60.4,58.0,354.0,3.97,4.01,2.41],[0.24,"Premium","I","VS1",62.5,57.0,355.0,3.97,3.94,2.47],[0.3,"Very Good","J","VS2",62.2,57.0,357.0,4.28,4.3,2.67],[0.23,"Very Good","D","VS2",60.5,61.0,357.0,3.96,3.97,2.4],[0.23,"Very Good","F","VS1",60.9,57.0,357.0,3.96,3.99,2.42],[0.23,"Very Good","F","VS1",60.0,57.0,402.0,4.0,4.03,2.41],[0.23,"Very Good","F","VS1",59.8,57.0,402.0,4.04,4.06,2.42],[0.23,"Very Good","E","VS1",60.7,59.0,402.0,3.97,4.01,2.42],[0.23,"Very Good","E","VS1",59.5,58.0,402.0,4.01,4.06,2.4],[0.23,"Very Good","D","VS1",61.9,58.0,402.0,3.92,3.96,2.44],[0.23,"Good","F","VS1",58.2,59.0,402.0,4.06,4.08,2.37],[0.23,"Good","E","VS1",64.1,59.0,402.0,3.83,3.85,2.46],[0.31,"Good","H","SI1",64.0,54.0,402.0,4.29,4.31,2.75],[0.26,"Very Good","D","VS2",60.8,59.0,403.0,4.13,4.16,2.52],[0.33,"Ideal","I","SI2",61.8,55.0,403.0,4.49,4.51,2.78],[0.33,"Ideal","I","SI2",61.2,56.0,403.0,4.49,4.5,2.75],[0.33,"Ideal","J","SI1",61.1,56.0,403.0,4.49,4.55,2.76],[0.26,"Good","D","VS2",65.2,56.0,403.0,3.99,4.02,2.61],[0.26,"Good","D","VS1",58.4,63.0,403.0,4.19,4.24,2.46],[0.32,"Good","H","SI2",63.1,56.0,403.0,4.34,4.37,2.75],[0.29,"Premium","F","SI1",62.4,58.0,403.0,4.24,4.26,2.65],[0.32,"Very Good","H","SI2",61.8,55.0,403.0,4.35,4.42,2.71],[0.32,"Good","H","SI2",63.8,56.0,403.0,4.36,4.38,2.79],[0.25,"Very Good","E","VS2",63.3,60.0,404.0,4.0,4.03,2.54],[0.29,"Very Good","H","SI2",60.7,60.0,404.0,4.33,4.37,2.64],[0.24,"Very Good","F","SI1",60.9,61.0,404.0,4.02,4.03,2.45],[0.23,"Ideal","G","VS1",61.9,54.0,404.0,3.93,3.95,2.44],[0.32,"Ideal","I","SI1",60.9,55.0,404.0,4.45,4.48,2.72],[0.22,"Premium","E","VS2",61.6,58.0,404.0,3.93,3.89,2.41],[0.22,"Premium","D","VS2",59.3,62.0,404.0,3.91,3.88,2.31],[0.3,"Ideal","I","SI2",61.0,59.0,405.0,4.3,4.33,2.63],[0.3,"Premium","J","SI2",59.3,61.0,405.0,4.43,4.38,2.61],[0.3,"Very Good","I","SI1",62.6,57.0,405.0,4.25,4.28,2.67],[0.3,"Very Good","I","SI1",63.0,57.0,405.0,4.28,4.32,2.71],[0.3,"Good","I","SI1",63.2,55.0,405.0,4.25,4.29,2.7],[0.35,"Ideal","I","VS1",60.9,57.0,552.0,4.54,4.59,2.78],[0.3,"Premium","D","SI1",62.6,59.0,552.0,4.23,4.27,2.66],[0.3,"Ideal","D","SI1",62.5,57.0,552.0,4.29,4.32,2.69],[0.3,"Ideal","D","SI1",62.1,56.0,552.0,4.3,4.33,2.68],[0.42,"Premium","I","SI2",61.5,59.0,552.0,4.78,4.84,2.96],[0.28,"Ideal","G","VVS2",61.4,56.0,553.0,4.19,4.22,2.58],[0.32,"Ideal","I","VVS1",62.0,55.3,553.0,4.39,4.42,2.73],[0.31,"Very Good","G","SI1",63.3,57.0,553.0,4.33,4.3,2.73],[0.31,"Premium","G","SI1",61.8,58.0,553.0,4.35,4.32,2.68],[0.24,"Premium","E","VVS1",60.7,58.0,553.0,4.01,4.03,2.44],[0.24,"Very Good","D","VVS1",61.5,60.0,553.0,3.97,4.0,2.45],[0.3,"Very Good","H","SI1",63.1,56.0,554.0,4.29,4.27,2.7],[0.3,"Premium","H","SI1",62.9,59.0,554.0,4.28,4.24,2.68],[0.3,"Premium","H","SI1",62.5,57.0,554.0,4.29,4.25,2.67],[0.3,"Good","H","SI1",63.7,57.0,554.0,4.28,4.26,2.72],[0.26,"Very Good","F","VVS2",59.2,60.0,554.0,4.19,4.22,2.49],[0.26,"Very Good","E","VVS2",59.9,58.0,554.0,4.15,4.23,2.51],[0.26,"Very Good","D","VVS2",62.4,54.0,554.0,4.08,4.13,2.56],[0.26,"Very Good","D","VVS2",62.8,60.0,554.0,4.01,4.05,2.53],[0.26,"Very Good","E","VVS1",62.6,59.0,554.0,4.06,4.09,2.55],[0.26,"Very Good","E","VVS1",63.4,59.0,554.0,4.0,4.04,2.55],[0.26,"Very Good","D","VVS1",62.1,60.0,554.0,4.03,4.12,2.53],[0.26,"Ideal","E","VVS2",62.9,58.0,554.0,4.02,4.06,2.54],[0.38,"Ideal","I","SI2",61.6,56.0,554.0,4.65,4.67,2.87],[0.26,"Good","E","VVS1",57.9,60.0,554.0,4.22,4.25,2.45],[0.24,"Premium","G","VVS1",62.3,59.0,554.0,3.95,3.92,2.45],[0.24,"Premium","H","VVS1",61.2,58.0,554.0,4.01,3.96,2.44],[0.24,"Premium","H","VVS1",60.8,59.0,554.0,4.02,4.0,2.44],[0.24,"Premium","H","VVS2",60.7,58.0,554.0,4.07,4.04,2.46],[0.32,"Premium","I","SI1",62.9,58.0,554.0,4.35,4.33,2.73],[0.7,"Ideal","E","SI1",62.5,57.0,2757.0,5.7,5.72,3.57],[0.86,"Fair","E","SI2",55.1,69.0,2757.0,6.45,6.33,3.52],[0.7,"Ideal","G","VS2",61.6,56.0,2757.0,5.7,5.67,3.5],[0.71,"Very Good","E","VS2",62.4,57.0,2759.0,5.68,5.73,3.56],[0.78,"Very Good","G","SI2",63.8,56.0,2759.0,5.81,5.85,3.72],[0.7,"Good","E","VS2",57.5,58.0,2759.0,5.85,5.9,3.38],[0.7,"Good","F","VS1",59.4,62.0,2759.0,5.71,5.76,3.4],[0.96,"Fair","F","SI2",66.3,62.0,2759.0,6.27,5.95,4.07],[0.73,"Very Good","E","SI1",61.6,59.0,2760.0,5.77,5.78,3.56],[0.8,"Premium","H","SI1",61.5,58.0,2760.0,5.97,5.93,3.66],[0.75,"Very Good","D","SI1",63.2,56.0,2760.0,5.8,5.75,3.65],[0.75,"Premium","E","SI1",59.9,54.0,2760.0,6.0,5.96,3.58],[0.74,"Ideal","G","SI1",61.6,55.0,2760.0,5.8,5.85,3.59],[0.75,"Premium","G","VS2",61.7,58.0,2760.0,5.85,5.79,3.59],[0.8,"Ideal","I","VS1",62.9,56.0,2760.0,5.94,5.87,3.72],[0.75,"Ideal","G","SI1",62.2,55.0,2760.0,5.87,5.8,3.63],[0.8,"Premium","G","SI1",63.0,59.0,2760.0,5.9,5.81,3.69],[0.74,"Ideal","I","VVS2",62.3,55.0,2761.0,5.77,5.81,3.61],[0.81,"Ideal","F","SI2",58.8,57.0,2761.0,6.14,6.11,3.6],[0.59,"Ideal","E","VVS2",62.0,55.0,2761.0,5.38,5.43,3.35],[0.8,"Ideal","F","SI2",61.4,57.0,2761.0,5.96,6.0,3.67],[0.74,"Ideal","E","SI2",62.2,56.0,2761.0,5.8,5.84,3.62],[0.9,"Premium","I","VS2",63.0,58.0,2761.0,6.16,6.12,3.87],[0.74,"Very Good","G","SI1",62.2,59.0,2762.0,5.73,5.82,3.59],[0.73,"Ideal","F","VS2",62.6,56.0,2762.0,5.77,5.74,3.6],[0.73,"Ideal","F","VS2",62.7,53.0,2762.0,5.8,5.75,3.62],[0.8,"Premium","F","SI2",61.7,58.0,2762.0,5.98,5.94,3.68],[0.71,"Ideal","G","VS2",62.4,54.0,2762.0,5.72,5.76,3.58],[0.7,"Ideal","E","VS2",60.7,58.0,2762.0,5.73,5.76,3.49],[0.8,"Ideal","F","SI2",59.9,59.0,2762.0,6.01,6.07,3.62],[0.71,"Ideal","D","SI2",62.3,56.0,2762.0,5.73,5.69,3.56],[0.74,"Ideal","E","SI1",62.3,54.0,2762.0,5.8,5.83,3.62],[0.7,"Very Good","F","VS2",61.7,63.0,2762.0,5.64,5.61,3.47],[0.7,"Fair","F","VS2",64.5,57.0,2762.0,5.57,5.53,3.58],[0.7,"Fair","F","VS2",65.3,55.0,2762.0,5.63,5.58,3.66],[0.7,"Premium","F","VS2",61.6,60.0,2762.0,5.65,5.59,3.46],[0.91,"Premium","H","SI1",61.4,56.0,2763.0,6.09,5.97,3.7],[0.61,"Very Good","D","VVS2",59.6,57.0,2763.0,5.56,5.58,3.32],[0.91,"Fair","H","SI2",64.4,57.0,2763.0,6.11,6.09,3.93],[0.91,"Fair","H","SI2",65.7,60.0,2763.0,6.03,5.99,3.95],[0.77,"Ideal","H","VS2",62.0,56.0,2763.0,5.89,5.86,3.64],[0.71,"Very Good","D","SI1",63.6,58.0,2764.0,5.64,5.68,3.6],[0.71,"Ideal","D","SI1",61.9,59.0,2764.0,5.69,5.72,3.53],[0.7,"Very Good","E","VS2",62.6,60.0,2765.0,5.62,5.65,3.53],[0.77,"Very Good","H","VS1",61.3,60.0,2765.0,5.88,5.9,3.61],[0.63,"Premium","E","VVS1",60.9,60.0,2765.0,5.52,5.55,3.37],[0.71,"Very Good","F","VS1",60.1,62.0,2765.0,5.74,5.77,3.46],[0.71,"Premium","F","VS1",61.8,59.0,2765.0,5.69,5.73,3.53],[0.76,"Ideal","H","SI1",61.2,57.0,2765.0,5.88,5.91,3.61],[0.64,"Ideal","G","VVS1",61.9,56.0,2766.0,5.53,5.56,3.43],[0.71,"Premium","G","VS2",60.9,57.0,2766.0,5.78,5.75,3.51],[0.71,"Premium","G","VS2",59.8,56.0,2766.0,5.89,5.81,3.5],[0.7,"Very Good","D","VS2",61.8,55.0,2767.0,5.68,5.72,3.52],[0.7,"Very Good","F","VS1",60.0,57.0,2767.0,5.8,5.87,3.5],[0.71,"Ideal","D","SI2",61.6,55.0,2767.0,5.74,5.76,3.54],[0.7,"Good","H","VVS2",62.1,64.0,2767.0,5.62,5.65,3.5],[0.71,"Very Good","G","VS1",63.3,59.0,2768.0,5.52,5.61,3.52],[0.73,"Very Good","D","SI1",60.2,56.0,2768.0,5.83,5.87,3.52],[0.7,"Very Good","D","SI1",61.1,58.0,2768.0,5.66,5.73,3.48],[0.7,"Ideal","E","SI1",60.9,57.0,2768.0,5.73,5.76,3.5],[0.71,"Premium","D","SI2",61.7,59.0,2768.0,5.71,5.67,3.51],[0.74,"Ideal","I","SI1",61.3,56.0,2769.0,5.82,5.86,3.57],[0.71,"Premium","D","VS2",62.5,60.0,2770.0,5.65,5.61,3.52],[0.73,"Premium","G","VS2",61.4,59.0,2770.0,5.83,5.76,3.56],[0.76,"Very Good","F","SI1",62.9,57.0,2770.0,5.79,5.81,3.65],[0.76,"Ideal","D","SI2",62.4,57.0,2770.0,5.78,5.83,3.62],[0.71,"Ideal","F","SI1",60.7,56.0,2770.0,5.77,5.8,3.51],[0.73,"Premium","G","VS2",60.7,58.0,2770.0,5.87,5.82,3.55],[0.73,"Premium","G","VS1",61.5,58.0,2770.0,5.79,5.75,3.55],[0.73,"Ideal","D","SI2",59.9,57.0,2770.0,5.92,5.89,3.54],[0.73,"Premium","G","VS2",59.2,59.0,2770.0,5.92,5.87,3.49],[0.72,"Very Good","H","VVS2",60.3,56.0,2771.0,5.81,5.83,3.51],[0.73,"Very Good","F","SI1",61.7,60.0,2771.0,5.79,5.82,3.58],[0.71,"Ideal","G","VS2",61.9,57.0,2771.0,5.73,5.77,3.56],[0.79,"Ideal","F","SI2",61.9,55.0,2771.0,5.97,5.92,3.68],[0.73,"Very Good","H","VVS1",60.4,59.0,2772.0,5.83,5.89,3.54],[0.8,"Very Good","F","SI2",61.0,57.0,2772.0,6.01,6.03,3.67],[0.58,"Ideal","G","VVS1",61.5,55.0,2772.0,5.39,5.44,3.33],[0.58,"Ideal","F","VVS1",61.7,56.0,2772.0,5.33,5.37,3.3],[0.71,"Good","E","VS2",59.2,61.0,2772.0,5.8,5.88,3.46],[0.75,"Ideal","D","SI2",61.3,56.0,2773.0,5.85,5.89,3.6],[0.7,"Premium","D","VS2",58.0,62.0,2773.0,5.87,5.78,3.38],[1.17,"Very Good","J","I1",60.2,61.0,2774.0,6.83,6.9,4.13],[0.6,"Ideal","E","VS1",61.7,55.0,2774.0,5.41,5.44,3.35],[0.7,"Ideal","E","SI1",62.7,55.0,2774.0,5.68,5.74,3.58],[0.83,"Good","I","VS2",64.6,54.0,2774.0,5.85,5.88,3.79],[0.74,"Very Good","F","VS2",61.3,61.0,2775.0,5.8,5.84,3.57],[0.72,"Very Good","G","VS2",63.7,56.4,2776.0,5.62,5.69,3.61],[0.71,"Premium","E","VS2",62.7,58.0,2776.0,5.74,5.68,3.58],[0.71,"Ideal","E","VS2",62.2,57.0,2776.0,5.79,5.62,3.55],[0.54,"Ideal","E","VVS2",61.6,56.0,2776.0,5.25,5.27,3.24],[0.54,"Ideal","E","VVS2",61.5,57.0,2776.0,5.24,5.26,3.23],[0.72,"Ideal","G","SI1",61.8,56.0,2776.0,5.72,5.75,3.55],[0.72,"Ideal","G","SI1",60.7,56.0,2776.0,5.79,5.82,3.53],[0.72,"Good","G","VS2",59.7,60.5,2776.0,5.8,5.84,3.47],[0.71,"Ideal","G","SI1",60.5,56.0,2776.0,5.8,5.76,3.5],[0.7,"Very Good","D","VS1",62.7,58.0,2777.0,5.66,5.73,3.57],[0.71,"Premium","F","VS2",62.1,58.0,2777.0,5.67,5.7,3.53],[0.71,"Very Good","F","VS2",62.8,57.0,2777.0,5.64,5.69,3.56],[0.71,"Good","F","VS2",63.8,58.0,2777.0,5.61,5.64,3.59],[0.71,"Good","F","VS2",57.8,60.0,2777.0,5.87,5.9,3.4],[0.7,"Ideal","E","VS2",62.1,55.0,2777.0,5.7,5.67,3.53],[0.7,"Premium","E","VS2",61.1,60.0,2777.0,5.71,5.64,3.47],[0.7,"Premium","E","SI1",60.0,59.0,2777.0,5.79,5.75,3.46],[0.7,"Premium","E","SI1",61.2,57.0,2777.0,5.73,5.68,3.49],[0.7,"Premium","E","SI1",62.7,59.0,2777.0,5.67,5.63,3.54],[0.7,"Premium","E","SI1",61.0,57.0,2777.0,5.73,5.68,3.48],[0.7,"Premium","E","SI1",61.0,58.0,2777.0,5.78,5.72,3.51],[0.7,"Ideal","E","SI1",61.4,57.0,2777.0,5.76,5.7,3.52],[0.72,"Premium","F","SI1",61.8,61.0,2777.0,5.82,5.71,3.56],[0.7,"Very Good","E","SI1",59.9,63.0,2777.0,5.76,5.7,3.43],[0.7,"Premium","E","SI1",61.3,58.0,2777.0,5.71,5.68,3.49],[0.7,"Premium","E","SI1",60.5,58.0,2777.0,5.77,5.74,3.48],[0.7,"Good","E","VS2",64.1,59.0,2777.0,5.64,5.59,3.6],[0.98,"Fair","H","SI2",67.9,60.0,2777.0,6.05,5.97,4.08],[0.78,"Premium","F","SI1",62.4,58.0,2777.0,5.83,5.8,3.63],[0.7,"Very Good","E","SI1",63.2,60.0,2777.0,5.6,5.51,3.51],[0.52,"Ideal","F","VVS1",61.3,55.0,2778.0,5.19,5.22,3.19],[0.73,"Very Good","H","VS2",60.8,56.0,2779.0,5.82,5.84,3.55],[0.74,"Ideal","E","SI1",61.7,56.0,2779.0,5.84,5.8,3.59],[0.7,"Very Good","F","VS2",63.6,57.0,2780.0,5.61,5.65,3.58],[0.77,"Premium","G","VS2",61.2,58.0,2780.0,5.9,5.93,3.62],[0.71,"Ideal","F","VS2",62.1,54.0,2780.0,5.68,5.72,3.54],[0.74,"Ideal","G","VS1",61.5,55.0,2780.0,5.81,5.86,3.59],[0.7,"Ideal","G","VS1",61.4,59.0,2780.0,5.64,5.73,3.49],[1.01,"Premium","F","I1",61.8,60.0,2781.0,6.39,6.36,3.94],[0.77,"Ideal","H","SI1",62.2,56.0,2781.0,5.83,5.88,3.64],[0.78,"Ideal","H","SI1",61.2,56.0,2781.0,5.92,5.99,3.64],[0.72,"Very Good","H","VS1",60.6,63.0,2782.0,5.83,5.76,3.51],[0.53,"Very Good","D","VVS2",57.5,64.0,2782.0,5.34,5.37,3.08],[0.76,"Ideal","G","VS2",61.3,56.0,2782.0,5.9,5.94,3.63],[0.7,"Good","E","VS1",57.2,62.0,2782.0,5.81,5.77,3.31],[0.7,"Premium","E","VS1",62.9,60.0,2782.0,5.62,5.54,3.51],[0.75,"Very Good","D","SI2",63.1,58.0,2782.0,5.78,5.73,3.63],[0.72,"Ideal","D","SI1",60.8,57.0,2782.0,5.76,5.75,3.5],[0.72,"Premium","D","SI1",62.7,59.0,2782.0,5.73,5.69,3.58],[0.7,"Premium","D","SI1",62.8,60.0,2782.0,5.68,5.66,3.56],[0.84,"Fair","G","SI1",55.1,67.0,2782.0,6.39,6.2,3.47],[0.75,"Premium","F","SI1",61.4,59.0,2782.0,5.88,5.85,3.6],[0.52,"Ideal","F","IF",62.2,55.0,2783.0,5.14,5.18,3.21],[0.72,"Very Good","F","VS2",63.0,54.0,2784.0,5.69,5.73,3.6],[0.79,"Very Good","H","VS1",63.7,56.0,2784.0,5.85,5.92,3.75],[0.72,"Very Good","F","VS2",63.6,58.0,2787.0,5.66,5.69,3.61],[0.51,"Ideal","F","VVS1",62.0,57.0,2787.0,5.11,5.15,3.18],[0.64,"Ideal","D","VS1",61.5,56.0,2787.0,5.54,5.55,3.41],[0.7,"Very Good","H","VVS1",60.5,60.0,2788.0,5.74,5.77,3.48],[0.83,"Very Good","I","VS1",61.1,60.0,2788.0,6.07,6.1,3.72],[0.76,"Ideal","I","VVS2",61.8,56.0,2788.0,5.85,5.87,3.62],[0.71,"Good","D","VS2",63.3,56.0,2788.0,5.64,5.68,3.58],[0.77,"Good","G","VS1",59.4,64.0,2788.0,5.97,5.92,3.53],[0.71,"Ideal","F","SI1",62.5,55.0,2788.0,5.71,5.65,3.55],[1.01,"Fair","E","I1",64.5,58.0,2788.0,6.29,6.21,4.03],[1.01,"Premium","H","SI2",62.7,59.0,2788.0,6.31,6.22,3.93],[0.77,"Good","F","SI1",64.2,52.0,2789.0,5.81,5.77,3.72],[0.76,"Good","E","SI1",63.7,54.0,2789.0,5.76,5.85,3.7],[0.76,"Premium","E","SI1",60.4,58.0,2789.0,5.92,5.94,3.58],[0.76,"Premium","E","SI1",61.8,58.0,2789.0,5.82,5.86,3.61],[1.05,"Very Good","J","SI2",63.2,56.0,2789.0,6.49,6.45,4.09],[0.81,"Ideal","G","SI2",61.6,56.0,2789.0,5.97,6.01,3.69],[0.7,"Ideal","E","SI1",61.6,56.0,2789.0,5.72,5.75,3.53],[0.55,"Ideal","G","IF",60.9,57.0,2789.0,5.28,5.3,3.22],[0.81,"Good","G","SI2",61.0,61.0,2789.0,5.94,5.99,3.64],[0.63,"Premium","E","VVS2",62.1,57.0,2789.0,5.48,5.41,3.38],[0.63,"Premium","E","VVS1",60.9,60.0,2789.0,5.55,5.52,3.37],[0.77,"Premium","H","VS1",61.3,60.0,2789.0,5.9,5.88,3.61],[1.05,"Fair","J","SI2",65.8,59.0,2789.0,6.41,6.27,4.18],[0.64,"Ideal","G","IF",61.3,56.0,2790.0,5.54,5.58,3.41],[0.76,"Premium","I","VVS1",58.8,59.0,2790.0,6.0,5.94,3.51],[0.83,"Ideal","F","SI2",62.3,55.0,2790.0,6.02,6.05,3.76],[0.71,"Premium","F","VS1",60.1,62.0,2790.0,5.77,5.74,3.46],[0.71,"Premium","F","VS1",61.8,59.0,2790.0,5.73,5.69,3.53],[0.87,"Very Good","I","SI1",63.6,55.8,2791.0,6.07,6.1,3.87],[0.73,"Ideal","E","SI1",62.2,56.0,2791.0,5.74,5.78,3.58],[0.71,"Premium","E","SI1",59.2,59.0,2792.0,5.83,5.86,3.46],[0.71,"Premium","E","SI1",61.8,59.0,2792.0,5.7,5.75,3.54],[0.71,"Ideal","E","SI1",61.3,55.0,2792.0,5.72,5.77,3.52],[0.7,"Premium","F","VS1",62.1,60.0,2792.0,5.71,5.65,3.53],[0.7,"Premium","F","VS1",60.7,60.0,2792.0,5.78,5.75,3.5],[0.76,"Premium","H","VVS2",59.6,57.0,2792.0,5.91,5.86,3.51],[0.7,"Ideal","F","VS1",62.2,56.0,2792.0,5.73,5.68,3.55],[0.79,"Very Good","G","SI1",60.6,57.0,2793.0,5.98,6.06,3.65],[0.7,"Very Good","E","VS2",62.9,57.0,2793.0,5.66,5.69,3.57],[0.7,"Good","E","VS2",64.1,55.0,2793.0,5.6,5.66,3.61],[0.76,"Ideal","I","VS2",61.3,56.0,2793.0,5.87,5.91,3.61],[0.73,"Ideal","H","VS2",62.7,55.0,2793.0,5.72,5.76,3.6],[0.79,"Very Good","E","SI1",63.2,56.0,2794.0,5.91,5.86,3.72],[0.71,"Very Good","E","VS2",60.7,56.0,2795.0,5.81,5.82,3.53],[0.81,"Premium","I","VVS2",61.9,60.0,2795.0,5.91,5.86,3.64],[0.81,"Ideal","F","SI2",62.6,55.0,2795.0,5.92,5.96,3.72],[0.72,"Good","F","VS1",60.7,60.0,2795.0,5.74,5.72,3.48],[0.72,"Premium","D","SI2",62.0,60.0,2795.0,5.73,5.69,3.54],[0.72,"Premium","I","IF",63.0,57.0,2795.0,5.72,5.7,3.6],[0.81,"Premium","H","VS2",58.0,59.0,2795.0,6.17,6.13,3.57],[0.72,"Premium","G","VS2",62.9,57.0,2795.0,5.73,5.65,3.58],[1.0,"Premium","I","SI2",58.2,60.0,2795.0,6.61,6.55,3.83],[0.73,"Good","E","SI1",63.2,58.0,2796.0,5.7,5.76,3.62],[0.81,"Very Good","H","SI2",61.3,59.0,2797.0,5.94,6.01,3.66],[0.81,"Very Good","E","SI1",60.3,60.0,2797.0,6.07,6.1,3.67],[0.71,"Premium","D","SI1",62.7,60.0,2797.0,5.67,5.71,3.57],[0.71,"Premium","D","SI1",61.3,58.0,2797.0,5.73,5.75,3.52],[0.71,"Premium","D","SI1",61.6,60.0,2797.0,5.74,5.69,3.52],[0.57,"Ideal","F","VVS2",61.9,55.0,2797.0,5.34,5.35,3.31],[0.51,"Ideal","D","VVS1",61.7,56.0,2797.0,5.12,5.16,3.17],[0.72,"Ideal","G","VS2",61.9,58.0,2797.0,5.72,5.75,3.55],[0.74,"Ideal","H","VS1",61.8,58.0,2797.0,5.77,5.81,3.58],[0.74,"Ideal","H","VS1",61.6,56.0,2797.0,5.81,5.82,3.58],[0.7,"Fair","G","VVS1",58.8,66.0,2797.0,5.81,5.9,3.44],[0.8,"Premium","F","SI2",61.0,57.0,2797.0,6.03,6.01,3.67],[1.01,"Fair","E","SI2",67.4,60.0,2797.0,6.19,6.05,4.13],[0.8,"Very Good","H","VS2",63.4,60.0,2797.0,5.92,5.82,3.72],[0.77,"Ideal","I","VS1",61.5,59.0,2798.0,5.87,5.91,3.62],[0.83,"Very Good","E","SI2",58.0,62.0,2799.0,6.19,6.25,3.61],[0.82,"Ideal","F","SI2",62.4,54.0,2799.0,5.97,6.02,3.74],[0.78,"Ideal","D","SI1",61.9,57.0,2799.0,5.91,5.86,3.64],[0.6,"Very Good","G","IF",61.6,56.0,2800.0,5.43,5.46,3.35],[0.9,"Good","I","SI2",62.2,59.0,2800.0,6.07,6.11,3.79],[0.7,"Premium","E","VS1",62.2,58.0,2800.0,5.6,5.66,3.5],[0.9,"Very Good","I","SI2",61.3,56.0,2800.0,6.17,6.23,3.8],[0.83,"Ideal","G","SI1",62.3,57.0,2800.0,5.99,6.08,3.76],[0.83,"Ideal","G","SI1",61.8,57.0,2800.0,6.03,6.07,3.74],[0.83,"Very Good","H","SI1",62.5,59.0,2800.0,5.95,6.02,3.74],[0.74,"Premium","G","VS1",62.9,60.0,2800.0,5.74,5.68,3.59],[0.79,"Ideal","I","VS1",61.8,59.0,2800.0,5.92,5.95,3.67],[0.61,"Ideal","G","IF",62.3,56.0,2800.0,5.43,5.45,3.39],[0.76,"Fair","G","VS1",59.0,70.0,2800.0,5.89,5.8,3.46],[0.96,"Ideal","F","I1",60.7,55.0,2801.0,6.37,6.41,3.88],[0.73,"Ideal","F","VS2",62.5,55.0,2801.0,5.8,5.76,3.61],[0.73,"Premium","F","VS2",62.7,58.0,2801.0,5.76,5.7,3.59],[0.75,"Ideal","H","SI1",60.4,57.0,2801.0,5.93,5.96,3.59],[0.71,"Premium","F","VS2",62.1,58.0,2801.0,5.7,5.67,3.53],[0.71,"Good","F","VS2",57.8,60.0,2801.0,5.9,5.87,3.4],[0.71,"Good","F","VS2",63.8,58.0,2801.0,5.64,5.61,3.59],[0.71,"Premium","F","VS2",62.8,57.0,2801.0,5.69,5.64,3.56],[1.04,"Premium","G","I1",62.2,58.0,2801.0,6.46,6.41,4.0],[1.0,"Premium","J","SI2",62.3,58.0,2801.0,6.45,6.34,3.98],[0.87,"Very Good","G","SI2",59.9,58.0,2802.0,6.19,6.23,3.72],[0.53,"Ideal","F","IF",61.9,54.0,2802.0,5.22,5.25,3.24],[0.72,"Premium","E","VS2",63.0,55.0,2802.0,5.79,5.61,3.59],[0.72,"Premium","F","VS1",62.4,58.0,2802.0,5.83,5.7,3.6],[0.7,"Very Good","F","VS2",62.9,58.0,2803.0,5.63,5.65,3.55],[0.74,"Very Good","E","SI1",63.5,56.0,2803.0,5.74,5.79,3.66],[0.71,"Ideal","G","VS2",61.3,56.0,2803.0,5.75,5.71,3.51],[0.73,"Ideal","E","SI1",60.6,54.0,2803.0,5.84,5.89,3.55],[0.7,"Good","G","VS1",65.1,58.0,2803.0,5.56,5.59,3.63],[0.71,"Premium","F","VS2",62.6,58.0,2803.0,5.7,5.67,3.56],[0.71,"Premium","F","VS2",58.0,62.0,2803.0,5.85,5.81,3.38],[0.71,"Premium","G","VS1",62.4,61.0,2803.0,5.7,5.65,3.54],[0.77,"Premium","G","VS2",61.3,57.0,2803.0,5.93,5.88,3.62],[0.71,"Premium","G","VS2",59.9,60.0,2803.0,5.81,5.77,3.47],[0.78,"Premium","G","VS2",60.8,58.0,2803.0,6.03,5.95,3.64],[0.71,"Very Good","G","VS1",63.5,55.0,2803.0,5.66,5.64,3.59],[0.91,"Ideal","D","SI2",62.2,57.0,2803.0,6.21,6.15,3.85],[0.71,"Very Good","E","VS2",63.8,58.0,2804.0,5.62,5.66,3.6],[0.71,"Very Good","E","VS2",64.0,57.0,2804.0,5.66,5.68,3.63],[0.8,"Very Good","E","SI2",62.5,56.0,2804.0,5.88,5.96,3.7],[0.7,"Very Good","D","SI1",62.3,58.0,2804.0,5.69,5.73,3.56],[0.72,"Ideal","F","VS1",61.7,57.0,2804.0,5.74,5.77,3.55],[0.72,"Very Good","F","VS1",62.2,58.0,2804.0,5.75,5.7,3.56],[0.82,"Ideal","H","VS2",61.5,56.0,2804.0,6.01,6.08,3.72],[0.7,"Ideal","D","SI1",61.0,59.0,2804.0,5.68,5.7,3.47],[0.72,"Ideal","D","SI1",62.2,56.0,2804.0,5.74,5.77,3.58],[0.72,"Ideal","D","SI1",61.5,54.0,2804.0,5.77,5.8,3.56],[0.9,"Fair","I","SI1",67.3,59.0,2804.0,5.93,5.84,3.96],[0.74,"Premium","F","VS2",61.7,58.0,2805.0,5.85,5.78,3.59],[0.74,"Premium","F","VS2",61.9,56.0,2805.0,5.8,5.77,3.58],[0.73,"Ideal","E","SI2",61.8,58.0,2805.0,5.77,5.81,3.58],[0.57,"Fair","E","VVS1",58.7,66.0,2805.0,5.34,5.43,3.16],[0.73,"Premium","F","VS2",62.5,57.0,2805.0,5.75,5.7,3.58],[0.72,"Ideal","G","VS2",62.8,56.0,2805.0,5.74,5.7,3.59],[0.74,"Fair","F","VS2",61.1,68.0,2805.0,5.82,5.75,3.53],[0.82,"Good","G","VS2",64.0,57.0,2805.0,5.92,5.89,3.78],[0.81,"Very Good","G","SI1",62.5,60.0,2806.0,5.89,5.94,3.69],[0.75,"Very Good","H","VVS1",60.6,58.0,2806.0,5.85,5.9,3.56],[0.7,"Ideal","F","SI1",61.6,55.0,2806.0,5.72,5.74,3.53],[0.71,"Very Good","F","VS1",62.2,58.0,2807.0,5.66,5.72,3.54],[0.71,"Very Good","F","VS1",60.0,57.0,2807.0,5.84,5.9,3.52],[0.93,"Premium","J","SI2",61.9,57.0,2807.0,6.21,6.19,3.84],[0.8,"Very Good","H","VS2",62.8,57.0,2808.0,5.87,5.91,3.7],[0.7,"Very Good","F","VS1",62.0,57.0,2808.0,5.64,5.71,3.52],[1.0,"Fair","G","I1",66.4,59.0,2808.0,6.16,6.09,4.07],[0.75,"Very Good","G","VS2",63.4,56.0,2808.0,5.78,5.74,3.65],[0.58,"Ideal","E","VVS2",60.9,56.0,2808.0,5.41,5.43,3.3],[0.73,"Very Good","D","SI1",63.1,57.0,2808.0,5.74,5.7,3.61],[0.81,"Very Good","F","SI1",63.1,59.0,2809.0,5.85,5.79,3.67],[0.81,"Premium","D","SI2",59.2,57.0,2809.0,6.15,6.05,3.61],[0.71,"Premium","F","SI1",60.7,54.0,2809.0,5.84,5.8,3.53],[1.2,"Fair","F","I1",64.6,56.0,2809.0,6.73,6.66,4.33],[0.7,"Very Good","F","VS1",61.8,56.0,2810.0,5.63,5.7,3.5],[0.7,"Very Good","F","VS1",59.9,60.0,2810.0,5.77,5.84,3.48],[0.74,"Ideal","D","SI2",61.7,55.0,2810.0,5.81,5.85,3.6],[0.7,"Good","F","VS1",62.8,61.0,2810.0,5.57,5.61,3.51],[0.8,"Good","G","SI1",62.7,57.0,2810.0,5.84,5.93,3.69],[0.75,"Very Good","F","SI1",63.4,58.0,2811.0,5.72,5.76,3.64],[0.83,"Very Good","D","SI1",63.5,54.0,2811.0,5.98,5.95,3.79],[1.0,"Fair","J","VS2",65.7,59.0,2811.0,6.14,6.07,4.01],[0.99,"Fair","I","SI2",68.1,56.0,2811.0,6.21,6.06,4.18],[0.7,"Very Good","G","VS1",63.0,60.0,2812.0,5.57,5.64,3.53],[0.7,"Very Good","F","VS2",59.5,58.0,2812.0,5.75,5.85,3.45],[0.7,"Good","E","SI1",63.5,59.0,2812.0,5.49,5.53,3.5],[0.7,"Very Good","F","VS2",61.7,58.0,2812.0,5.63,5.69,3.49],[0.32,"Premium","I","SI1",62.7,58.0,554.0,4.37,4.34,2.73],[0.32,"Premium","I","SI1",62.8,58.0,554.0,4.39,4.34,2.74],[0.32,"Ideal","I","SI1",62.4,57.0,554.0,4.37,4.35,2.72],[0.32,"Premium","I","SI1",61.0,59.0,554.0,4.39,4.36,2.67],[0.32,"Very Good","I","SI1",63.1,56.0,554.0,4.39,4.36,2.76],[0.32,"Ideal","I","SI1",60.7,57.0,554.0,4.47,4.42,2.7],[0.3,"Premium","H","SI1",60.9,59.0,554.0,4.31,4.29,2.62],[0.3,"Premium","H","SI1",60.1,55.0,554.0,4.41,4.38,2.64],[0.3,"Premium","H","SI1",62.9,58.0,554.0,4.28,4.24,2.68],[0.3,"Very Good","H","SI1",63.3,56.0,554.0,4.29,4.27,2.71],[0.3,"Good","H","SI1",63.8,55.0,554.0,4.26,4.2,2.7],[0.3,"Ideal","H","SI1",62.9,57.0,554.0,4.27,4.22,2.67],[0.3,"Very Good","H","SI1",63.4,60.0,554.0,4.25,4.23,2.69],[0.32,"Good","I","SI1",63.9,55.0,554.0,4.36,4.34,2.78],[0.33,"Ideal","H","SI2",61.4,56.0,554.0,4.85,4.79,2.95],[0.29,"Very Good","E","VS1",61.9,55.0,555.0,4.28,4.33,2.66],[0.29,"Very Good","E","VS1",62.4,55.0,555.0,4.2,4.25,2.63],[0.31,"Very Good","F","SI1",61.8,58.0,555.0,4.32,4.35,2.68],[0.34,"Ideal","H","VS2",61.5,56.0,555.0,4.47,4.5,2.76],[0.34,"Ideal","H","VS2",60.4,57.0,555.0,4.54,4.57,2.75],[0.34,"Ideal","I","VS1",61.8,55.0,555.0,4.48,4.52,2.78],[0.34,"Ideal","I","VS1",62.0,56.0,555.0,4.5,4.53,2.8],[0.3,"Ideal","G","VS1",62.3,56.0,555.0,4.29,4.31,2.68],[0.29,"Ideal","F","VS1",61.6,56.0,555.0,4.26,4.31,2.64],[0.35,"Ideal","G","SI1",60.6,56.0,555.0,4.56,4.58,2.77],[0.43,"Very Good","E","I1",58.4,62.0,555.0,4.94,5.0,2.9],[0.32,"Very Good","F","VS2",61.4,58.0,556.0,4.37,4.42,2.7],[0.36,"Ideal","I","VS2",61.9,56.0,556.0,4.54,4.57,2.82],[0.3,"Ideal","G","VS2",62.0,56.0,556.0,4.28,4.3,2.66],[0.26,"Ideal","E","VS1",61.5,57.0,556.0,4.09,4.12,2.52],[0.7,"Very Good","F","VS2",62.3,58.0,2812.0,5.64,5.72,3.54],[0.7,"Very Good","F","VS2",60.9,61.0,2812.0,5.66,5.71,3.46],[0.71,"Ideal","D","SI1",62.4,57.0,2812.0,5.69,5.72,3.56],[0.99,"Fair","J","SI1",55.0,61.0,2812.0,6.72,6.67,3.68],[0.73,"Premium","E","VS2",58.6,60.0,2812.0,5.92,5.89,3.46],[0.51,"Ideal","F","VVS1",62.0,57.0,2812.0,5.15,5.11,3.18],[0.91,"Premium","G","SI2",59.8,58.0,2813.0,6.3,6.29,3.77],[0.84,"Very Good","E","SI1",63.4,55.0,2813.0,6.0,5.95,3.79],[0.91,"Good","I","VS2",64.3,58.0,2813.0,6.09,6.05,3.9],[0.76,"Premium","E","SI1",62.2,59.0,2814.0,5.86,5.81,3.63],[0.76,"Ideal","E","SI1",61.7,57.0,2814.0,5.88,5.85,3.62],[0.75,"Premium","E","SI1",61.1,59.0,2814.0,5.86,5.83,3.57],[0.55,"Very Good","D","VVS1",61.5,56.0,2815.0,5.23,5.27,3.23],[0.76,"Very Good","F","SI2",58.5,62.0,2815.0,5.93,6.01,3.49],[0.74,"Premium","G","VS1",61.7,58.0,2815.0,5.79,5.81,3.58],[0.7,"Ideal","H","SI1",60.4,56.0,2815.0,5.75,5.81,3.49],[0.7,"Ideal","H","SI1",61.4,56.0,2815.0,5.7,5.76,3.52],[0.7,"Ideal","H","SI1",61.5,55.0,2815.0,5.73,5.79,3.54],[0.7,"Ideal","H","SI1",61.4,56.0,2815.0,5.72,5.77,3.53],[0.9,"Fair","J","VS2",65.0,56.0,2815.0,6.08,6.04,3.94],[0.95,"Fair","F","SI2",56.0,60.0,2815.0,6.62,6.53,3.68],[0.89,"Premium","H","SI2",60.2,59.0,2815.0,6.26,6.23,3.76],[0.72,"Premium","E","VS2",58.3,58.0,2815.0,5.99,5.92,3.47],[0.96,"Fair","E","SI2",53.1,63.0,2815.0,6.73,6.65,3.55],[1.02,"Premium","G","I1",60.3,58.0,2815.0,6.55,6.5,3.94],[0.78,"Very Good","I","VVS2",61.4,56.0,2816.0,5.91,5.95,3.64],[0.61,"Ideal","G","VVS2",60.1,57.0,2816.0,5.52,5.54,3.32],[0.71,"Good","D","VS1",63.4,55.0,2816.0,5.61,5.69,3.58],[0.78,"Premium","F","SI1",61.5,59.0,2816.0,5.96,5.88,3.64],[0.87,"Ideal","H","SI2",62.7,56.0,2816.0,6.16,6.13,3.85],[0.83,"Ideal","H","SI1",62.5,55.0,2816.0,6.04,6.0,3.76],[0.71,"Premium","E","SI1",61.3,56.0,2817.0,5.78,5.73,3.53],[0.71,"Ideal","I","VVS2",60.2,56.0,2817.0,5.84,5.89,3.53],[0.71,"Ideal","E","VS2",62.7,57.0,2817.0,5.66,5.64,3.54],[0.71,"Premium","E","VS2",62.3,58.0,2817.0,5.69,5.65,3.53],[0.63,"Ideal","F","VVS2",61.5,56.0,2817.0,5.48,5.52,3.38],[0.71,"Premium","E","SI1",59.2,59.0,2817.0,5.86,5.83,3.46],[0.71,"Premium","E","SI1",61.8,59.0,2817.0,5.75,5.7,3.54],[0.71,"Ideal","E","SI1",61.3,55.0,2817.0,5.77,5.72,3.52],[0.71,"Premium","E","SI1",61.4,58.0,2817.0,5.77,5.73,3.53],[0.9,"Ideal","J","VS2",62.8,55.0,2817.0,6.2,6.16,3.88],[0.71,"Good","E","SI1",62.8,64.0,2817.0,5.6,5.54,3.5],[0.7,"Premium","E","VS2",62.4,61.0,2818.0,5.66,5.63,3.52],[0.7,"Premium","E","VS2",59.3,60.0,2818.0,5.78,5.73,3.41],[0.7,"Premium","E","VS2",63.0,60.0,2818.0,5.64,5.6,3.54],[1.0,"Premium","H","I1",61.3,60.0,2818.0,6.43,6.39,3.93],[0.86,"Premium","F","SI2",59.3,62.0,2818.0,6.36,6.22,3.73],[0.8,"Ideal","H","SI1",61.0,57.0,2818.0,6.07,6.0,3.68],[0.7,"Ideal","E","VS1",62.9,57.0,2818.0,5.66,5.61,3.54],[0.7,"Premium","E","VS1",59.6,57.0,2818.0,5.91,5.83,3.5],[0.7,"Premium","F","VS2",61.8,60.0,2818.0,5.69,5.64,3.5],[0.7,"Premium","E","VS1",62.7,57.0,2818.0,5.68,5.64,3.55],[1.0,"Fair","H","SI2",65.3,62.0,2818.0,6.34,6.12,4.08],[0.72,"Very Good","G","VS1",63.8,58.0,2819.0,5.64,5.68,3.61],[0.72,"Ideal","H","VS1",62.3,56.0,2819.0,5.73,5.77,3.58],[0.7,"Good","F","VS1",59.7,63.0,2819.0,5.76,5.79,3.45],[0.86,"Good","F","SI2",64.3,60.0,2819.0,5.97,5.95,3.83],[0.71,"Ideal","G","VS1",62.9,58.0,2820.0,5.66,5.69,3.57],[0.75,"Ideal","E","SI1",62.0,57.0,2821.0,5.8,5.78,3.59],[0.73,"Premium","E","VS2",61.6,59.0,2821.0,5.77,5.73,3.54],[0.53,"Ideal","E","VVS1",61.9,55.0,2821.0,5.2,5.21,3.22],[0.73,"Premium","E","SI1",61.3,58.0,2821.0,5.83,5.76,3.55],[0.73,"Good","E","SI1",63.6,57.0,2821.0,5.72,5.7,3.63],[0.73,"Premium","E","SI1",59.6,61.0,2821.0,5.92,5.85,3.51],[0.73,"Premium","E","SI1",62.2,59.0,2821.0,5.77,5.68,3.56],[0.73,"Premium","D","SI1",61.7,55.0,2821.0,5.84,5.82,3.6],[0.73,"Very Good","E","SI1",63.2,58.0,2821.0,5.76,5.7,3.62],[0.7,"Premium","E","VS1",60.8,60.0,2822.0,5.74,5.71,3.48],[0.72,"Premium","E","VS2",60.3,59.0,2822.0,5.84,5.8,3.51],[0.72,"Premium","E","VS2",60.9,60.0,2822.0,5.8,5.76,3.52],[0.72,"Premium","E","VS2",62.4,59.0,2822.0,5.77,5.7,3.58],[0.7,"Premium","E","VS2",60.2,60.0,2822.0,5.73,5.7,3.44],[0.6,"Ideal","F","VVS2",62.0,55.0,2822.0,5.37,5.4,3.34],[0.74,"Ideal","I","VVS1",60.8,57.0,2822.0,5.85,5.89,3.57],[0.73,"Ideal","F","SI1",62.1,55.0,2822.0,5.75,5.78,3.58],[0.71,"Premium","D","SI1",62.7,60.0,2822.0,5.71,5.67,3.57],[0.71,"Premium","D","SI1",61.3,58.0,2822.0,5.75,5.73,3.52],[0.7,"Premium","D","SI1",60.2,60.0,2822.0,5.82,5.75,3.48],[0.7,"Ideal","D","SI1",60.7,56.0,2822.0,5.75,5.72,3.48],[0.9,"Good","J","VS2",64.0,61.0,2822.0,6.04,6.03,3.86],[0.71,"Ideal","D","SI1",60.2,56.0,2822.0,5.86,5.83,3.52],[0.7,"Premium","E","VS2",61.5,59.0,2822.0,5.73,5.68,3.51],[0.7,"Premium","E","VS2",62.6,56.0,2822.0,5.71,5.66,3.56],[0.7,"Ideal","D","SI1",59.7,58.0,2822.0,5.82,5.77,3.46],[0.7,"Good","E","SI1",61.4,64.0,2822.0,5.71,5.66,3.49],[0.7,"Ideal","D","SI1",62.5,57.0,2822.0,5.62,5.59,3.51],[0.7,"Ideal","D","SI1",61.8,56.0,2822.0,5.73,5.63,3.51],[0.7,"Premium","E","VS2",60.7,62.0,2822.0,5.72,5.68,3.46],[0.7,"Premium","F","VS2",60.6,58.0,2822.0,5.8,5.72,3.49],[0.7,"Ideal","D","SI1",61.4,54.0,2822.0,5.75,5.71,3.52],[0.79,"Very Good","D","SI2",62.8,59.0,2823.0,5.86,5.9,3.69],[0.9,"Good","I","SI1",63.8,57.0,2823.0,6.06,6.13,3.89],[0.71,"Premium","E","VS2",62.3,58.0,2823.0,5.71,5.66,3.54],[0.61,"Ideal","E","VVS2",61.3,54.0,2823.0,5.51,5.59,3.4],[0.9,"Fair","H","SI2",65.8,54.0,2823.0,6.05,5.98,3.96],[0.71,"Ideal","E","SI1",60.5,56.0,2823.0,5.77,5.73,3.47],[0.71,"Premium","D","VS2",61.2,59.0,2824.0,5.74,5.69,3.5],[0.77,"Ideal","I","VVS2",62.1,57.0,2824.0,5.84,5.86,3.63],[0.74,"Good","E","VS1",63.1,58.0,2824.0,5.73,5.75,3.62],[0.82,"Ideal","F","SI2",62.4,54.0,2824.0,6.02,5.97,3.74],[0.82,"Premium","E","SI2",60.8,60.0,2824.0,6.05,6.03,3.67],[0.71,"Premium","G","VS1",62.2,59.0,2825.0,5.73,5.66,3.54],[0.83,"Premium","H","SI1",60.0,59.0,2825.0,6.08,6.05,3.64],[0.73,"Very Good","G","VS1",62.0,57.0,2825.0,5.75,5.8,3.58],[0.83,"Premium","H","SI1",62.5,59.0,2825.0,6.02,5.95,3.74],[1.17,"Premium","J","I1",60.2,61.0,2825.0,6.9,6.83,4.13],[0.91,"Fair","H","SI2",61.3,67.0,2825.0,6.24,6.19,3.81],[0.73,"Premium","E","VS1",62.6,60.0,2826.0,5.75,5.68,3.58],[0.7,"Good","E","VS1",57.2,59.0,2826.0,5.94,5.88,3.38],[0.9,"Premium","I","SI2",62.2,59.0,2826.0,6.11,6.07,3.79],[0.7,"Premium","E","VS1",62.2,58.0,2826.0,5.66,5.6,3.5],[0.7,"Very Good","D","VS2",63.3,56.0,2826.0,5.6,5.58,3.54],[0.7,"Premium","E","VS1",59.4,61.0,2826.0,5.78,5.74,3.42],[0.9,"Very Good","I","SI2",63.5,56.0,2826.0,6.17,6.07,3.88],[0.78,"Premium","F","SI1",60.8,60.0,2826.0,5.97,5.94,3.62],[0.96,"Ideal","F","I1",60.7,55.0,2826.0,6.41,6.37,3.88],[0.7,"Very Good","D","SI1",62.3,59.0,2827.0,5.67,5.7,3.54],[0.72,"Good","D","VS2",64.0,54.0,2827.0,5.68,5.7,3.64],[0.79,"Premium","H","VVS2",62.6,58.0,2827.0,5.96,5.9,3.71],[0.7,"Ideal","H","VVS1",61.6,57.0,2827.0,5.69,5.74,3.52],[0.7,"Ideal","H","VVS1",62.3,55.0,2827.0,5.66,5.7,3.54],[0.7,"Ideal","D","SI2",60.6,57.0,2828.0,5.74,5.77,3.49],[1.01,"Premium","H","SI2",61.6,61.0,2828.0,6.39,6.31,3.91],[0.72,"Premium","F","VS1",62.2,58.0,2829.0,5.75,5.7,3.56],[0.8,"Good","E","SI2",63.7,54.0,2829.0,5.91,5.87,3.75],[0.59,"Ideal","E","VVS1",62.0,56.0,2829.0,5.36,5.38,3.33],[0.72,"Ideal","F","VS1",61.7,57.0,2829.0,5.77,5.74,3.55],[0.75,"Premium","E","SI2",61.9,57.0,2829.0,5.88,5.82,3.62],[0.8,"Premium","E","SI2",60.2,57.0,2829.0,6.05,6.01,3.63],[0.71,"Very Good","E","VS2",62.7,59.0,2830.0,5.65,5.7,3.56],[0.77,"Very Good","H","SI1",61.7,56.0,2830.0,5.84,5.89,3.62],[0.97,"Ideal","F","I1",60.7,56.0,2830.0,6.41,6.43,3.9],[0.53,"Ideal","F","VVS1",60.9,57.0,2830.0,5.23,5.29,3.19],[0.53,"Ideal","F","VVS1",61.8,57.0,2830.0,5.16,5.19,3.2],[0.8,"Ideal","I","VS2",62.1,54.4,2830.0,5.94,5.99,3.7],[0.9,"Premium","G","SI1",60.6,62.0,2830.0,6.21,6.13,3.74],[0.76,"Very Good","E","SI2",60.8,60.0,2831.0,5.89,5.98,3.61],[0.72,"Ideal","E","SI1",62.3,57.0,2831.0,5.7,5.76,3.57],[0.75,"Ideal","E","SI1",61.4,57.0,2831.0,5.82,5.87,3.59],[0.72,"Premium","E","SI1",62.1,58.0,2831.0,5.73,5.76,3.57],[0.79,"Ideal","G","SI1",61.8,56.0,2831.0,5.93,5.91,3.66],[0.72,"Very Good","F","VS2",62.5,58.0,2832.0,5.71,5.75,3.58],[0.91,"Very Good","I","SI2",62.8,61.0,2832.0,6.15,6.18,3.87],[0.71,"Premium","G","VVS2",62.1,57.0,2832.0,5.75,5.65,3.54],[0.81,"Premium","G","SI1",63.0,60.0,2832.0,5.87,5.81,3.68],[0.82,"Ideal","H","SI1",62.5,57.0,2832.0,5.91,5.97,3.71],[0.71,"Premium","F","VS1",62.2,58.0,2832.0,5.72,5.66,3.54],[0.9,"Good","J","SI1",64.3,63.0,2832.0,6.05,6.01,3.88],[0.8,"Very Good","I","VS2",62.0,58.0,2833.0,5.86,5.95,3.66],[0.56,"Very Good","E","IF",61.0,59.0,2833.0,5.28,5.34,3.24],[0.7,"Very Good","D","VS2",59.6,61.0,2833.0,5.77,5.8,3.45],[0.7,"Ideal","D","VS2",61.0,57.0,2833.0,5.74,5.76,3.51],[0.61,"Ideal","F","VVS2",61.7,55.0,2833.0,5.45,5.48,3.37],[0.85,"Ideal","H","SI2",62.5,57.0,2833.0,6.02,6.07,3.78],[0.7,"Ideal","F","SI1",60.7,57.0,2833.0,5.73,5.75,3.49],[0.8,"Ideal","G","VS2",62.2,56.0,2834.0,5.94,5.87,3.67],[0.8,"Ideal","H","VS2",62.8,57.0,2834.0,5.91,5.87,3.7],[0.51,"Very Good","D","VVS1",59.9,58.0,2834.0,5.16,5.19,3.1],[0.53,"Ideal","F","VVS1",61.4,57.0,2834.0,5.2,5.23,3.2],[0.78,"Ideal","I","VS2",61.8,55.0,2834.0,5.92,5.95,3.67],[0.9,"Very Good","J","SI1",63.4,54.0,2834.0,6.17,6.14,3.9],[0.9,"Fair","G","SI2",65.3,59.0,2834.0,6.07,6.0,3.94],[0.77,"Ideal","E","SI2",60.7,55.0,2834.0,6.01,5.95,3.63],[0.73,"Ideal","F","VS1",61.2,56.0,2835.0,5.89,5.81,3.58],[0.63,"Ideal","F","VVS2",61.9,57.0,2835.0,5.47,5.51,3.4],[0.7,"Ideal","E","VS2",61.5,54.0,2835.0,5.7,5.75,3.52],[0.72,"Ideal","E","VS2",62.8,57.0,2835.0,5.71,5.73,3.59],[0.72,"Ideal","E","SI1",61.0,57.0,2835.0,5.78,5.8,3.53],[0.75,"Premium","F","VS2",59.6,59.0,2835.0,6.04,5.94,3.57],[0.82,"Very Good","H","SI1",60.7,56.0,2836.0,6.04,6.06,3.67],[0.71,"Good","E","VS2",62.8,60.0,2836.0,5.6,5.65,3.53],[0.7,"Premium","E","VS1",62.6,59.0,2837.0,5.69,5.66,3.55],[0.7,"Ideal","E","VS1",61.8,56.0,2837.0,5.74,5.69,3.53],[0.71,"Ideal","F","SI1",59.8,53.0,2838.0,5.86,5.82,3.49],[0.76,"Very Good","H","SI1",60.9,55.0,2838.0,5.92,5.94,3.61],[0.82,"Fair","F","SI1",64.9,58.0,2838.0,5.83,5.79,3.77],[0.72,"Premium","F","VS1",58.8,60.0,2838.0,5.91,5.89,3.47],[0.7,"Premium","F","VS2",62.3,58.0,2838.0,5.72,5.64,3.54],[0.7,"Premium","F","VS2",61.7,58.0,2838.0,5.69,5.63,3.49],[0.7,"Premium","G","VS1",62.6,55.0,2838.0,5.73,5.64,3.56],[0.7,"Premium","F","VS2",59.4,61.0,2838.0,5.83,5.79,3.45],[0.7,"Very Good","E","SI1",63.5,59.0,2838.0,5.53,5.49,3.5],[0.7,"Premium","F","VS2",60.9,61.0,2838.0,5.71,5.66,3.46],[0.7,"Premium","F","VS2",59.5,58.0,2838.0,5.85,5.75,3.45],[0.7,"Premium","G","VS1",63.0,60.0,2838.0,5.64,5.57,3.53],[0.74,"Very Good","E","SI1",60.0,57.0,2839.0,5.85,5.89,3.52],[0.71,"Ideal","F","VS1",61.5,57.0,2839.0,5.74,5.71,3.52],[0.7,"Ideal","F","VS1",61.6,54.0,2839.0,5.75,5.72,3.53],[0.71,"Ideal","F","VS1",62.1,55.0,2839.0,5.82,5.68,3.57],[0.71,"Premium","F","VS1",59.1,61.0,2839.0,5.84,5.81,3.44],[0.71,"Premium","F","VS1",59.0,60.0,2839.0,5.82,5.8,3.43],[0.71,"Premium","F","VS1",60.5,58.0,2839.0,5.75,5.72,3.47],[0.7,"Ideal","F","VS1",62.4,53.0,2839.0,5.73,5.71,3.57],[0.73,"Ideal","G","VS2",61.8,54.0,2839.0,5.8,5.82,3.59],[0.7,"Ideal","E","VS2",62.1,54.0,2839.0,5.69,5.72,3.54],[0.7,"Ideal","G","VS1",61.3,57.0,2839.0,5.71,5.74,3.51],[0.71,"Premium","G","VVS2",60.3,58.0,2839.0,5.82,5.78,3.5],[0.71,"Premium","F","VS1",59.2,58.0,2839.0,5.87,5.82,3.46],[0.79,"Premium","G","VS2",59.3,62.0,2839.0,6.09,6.01,3.59],[0.71,"Premium","F","VS1",62.7,59.0,2839.0,5.7,5.62,3.55],[0.77,"Very Good","H","VS1",61.0,60.0,2840.0,5.9,5.87,3.59],[0.75,"Very Good","F","SI2",59.8,56.0,2840.0,5.85,5.92,3.52],[0.7,"Ideal","F","SI1",61.0,56.0,2840.0,5.75,5.8,3.52],[0.71,"Premium","F","VS2",59.3,56.0,2840.0,5.88,5.82,3.47],[0.92,"Ideal","D","SI2",61.9,56.0,2840.0,6.27,6.2,3.86],[0.83,"Premium","F","SI2",61.4,59.0,2840.0,6.08,6.04,3.72],[0.7,"Premium","H","VVS1",59.2,60.0,2840.0,5.87,5.78,3.45],[0.73,"Premium","F","VS2",60.3,59.0,2841.0,5.9,5.87,3.55],[0.71,"Very Good","D","VS1",63.4,55.0,2841.0,5.69,5.61,3.58],[0.73,"Very Good","D","SI1",63.9,57.0,2841.0,5.66,5.71,3.63],[0.82,"Ideal","F","SI2",61.7,53.0,2841.0,6.0,6.12,3.74],[0.82,"Ideal","F","SI2",62.3,56.0,2841.0,5.96,6.02,3.73],[0.82,"Very Good","F","SI2",59.7,57.0,2841.0,6.12,6.14,3.66],[0.52,"Ideal","F","VVS1",61.2,56.0,2841.0,5.19,5.21,3.18],[1.0,"Premium","F","I1",58.9,60.0,2841.0,6.6,6.55,3.87],[0.95,"Fair","G","SI1",66.7,56.0,2841.0,6.16,6.03,4.06],[0.73,"Ideal","D","SI1",61.4,57.0,2841.0,5.76,5.8,3.55],[0.73,"Premium","F","VS2",59.9,59.0,2841.0,5.87,5.77,3.5],[0.73,"Premium","G","VS1",61.4,58.0,2841.0,5.82,5.77,3.56],[0.8,"Ideal","I","VS1",62.6,54.0,2842.0,5.92,5.96,3.72],[0.7,"Premium","F","VS2",58.7,61.0,2842.0,5.8,5.72,3.38],[0.7,"Very Good","E","VS2",60.2,62.0,2843.0,5.71,5.75,3.45],[0.7,"Very Good","E","VS2",62.7,58.0,2843.0,5.65,5.67,3.55],[0.71,"Very Good","E","VS2",59.4,58.0,2843.0,5.76,5.82,3.44],[0.81,"Very Good","F","SI2",63.2,58.0,2843.0,5.91,5.92,3.74],[0.71,"Very Good","D","SI1",61.5,58.0,2843.0,5.73,5.79,3.54],[0.73,"Ideal","G","VVS2",61.3,57.0,2843.0,5.81,5.84,3.57],[0.73,"Very Good","F","VS1",61.8,59.0,2843.0,5.73,5.79,3.56],[0.72,"Ideal","E","VS2",62.0,57.0,2843.0,5.71,5.74,3.55],[0.81,"Ideal","F","SI2",62.1,57.0,2843.0,5.91,5.95,3.68],[0.71,"Ideal","G","VVS2",60.7,57.0,2843.0,5.81,5.78,3.52],[0.73,"Very Good","E","SI1",57.7,61.0,2844.0,5.92,5.96,3.43],[0.7,"Very Good","E","VS1",62.0,59.0,2844.0,5.65,5.68,3.51],[1.01,"Ideal","I","I1",61.5,57.0,2844.0,6.45,6.46,3.97],[1.01,"Good","I","I1",63.1,57.0,2844.0,6.35,6.39,4.02],[0.79,"Ideal","H","VS2",62.5,57.0,2844.0,5.91,5.93,3.7],[0.7,"Very Good","E","VS2",61.8,59.0,2845.0,5.65,5.68,3.5],[0.7,"Very Good","E","VS2",58.9,60.0,2845.0,5.83,5.85,3.44],[0.8,"Good","H","VS2",63.4,60.0,2845.0,5.92,5.82,3.72],[1.27,"Premium","H","SI2",59.3,61.0,2845.0,7.12,7.05,4.2],[0.79,"Ideal","D","SI1",61.5,56.0,2846.0,5.96,5.91,3.65],[0.72,"Very Good","F","VS1",60.2,59.0,2846.0,5.79,5.84,3.5],[0.73,"Ideal","H","VVS2",61.6,56.0,2846.0,5.79,5.84,3.58],[1.01,"Fair","H","SI2",65.4,59.0,2846.0,6.3,6.26,4.11],[1.01,"Good","H","I1",64.2,61.0,2846.0,6.25,6.18,3.99],[0.73,"Ideal","E","SI1",59.1,59.0,2846.0,5.92,5.95,3.51],[0.7,"Ideal","E","SI1",61.6,57.0,2846.0,5.71,5.76,3.53],[0.7,"Good","F","VS2",59.1,61.0,2846.0,5.76,5.84,3.43],[0.77,"Premium","E","SI1",62.9,59.0,2846.0,5.84,5.79,3.66],[0.77,"Premium","G","VS2",61.3,60.0,2846.0,5.91,5.81,3.59],[0.77,"Premium","G","VS1",61.4,58.0,2846.0,5.94,5.89,3.63],[0.84,"Very Good","H","SI1",61.2,57.0,2847.0,6.1,6.12,3.74],[0.72,"Ideal","E","SI1",60.3,57.0,2847.0,5.83,5.85,3.52],[0.76,"Premium","D","SI1",61.1,59.0,2847.0,5.93,5.88,3.61],[0.7,"Very Good","G","VVS2",62.9,59.0,2848.0,5.61,5.68,3.55],[0.54,"Ideal","D","VVS2",61.5,55.0,2848.0,5.25,5.29,3.24],[0.75,"Fair","D","SI2",64.6,57.0,2848.0,5.74,5.72,3.7],[0.79,"Good","E","SI1",64.1,54.0,2849.0,5.86,5.84,3.75],[0.74,"Very Good","E","VS1",63.1,58.0,2849.0,5.75,5.73,3.62],[0.7,"Very Good","E","VS2",61.0,60.0,2850.0,5.74,5.77,3.51],[0.7,"Ideal","F","VS2",60.8,59.0,2850.0,5.69,5.79,3.49],[0.75,"Ideal","J","SI1",61.5,56.0,2850.0,5.83,5.87,3.6],[1.2,"Very Good","H","I1",63.1,60.0,2850.0,6.75,6.67,4.23],[0.8,"Very Good","F","SI1",63.4,57.0,2851.0,5.89,5.82,3.71],[0.66,"Ideal","D","VS1",62.1,56.0,2851.0,5.54,5.57,3.45],[0.87,"Very Good","F","SI2",61.0,63.0,2851.0,6.22,6.07,3.75],[0.86,"Premium","H","SI1",62.7,59.0,2851.0,6.04,5.98,3.77],[0.74,"Ideal","F","SI1",61.0,57.0,2851.0,5.85,5.81,3.56],[0.58,"Very Good","E","IF",60.6,59.0,2852.0,5.37,5.43,3.27],[0.78,"Ideal","I","VS1",61.5,57.0,2852.0,5.88,5.92,3.63],[0.74,"Ideal","G","SI1",61.3,55.0,2852.0,5.85,5.86,3.59],[0.73,"Ideal","E","SI1",62.7,55.0,2852.0,5.7,5.79,3.6],[0.91,"Very Good","I","SI1",63.5,57.0,2852.0,6.12,6.07,3.87],[0.71,"Premium","F","VS2",62.6,58.0,2853.0,5.67,5.7,3.56],[0.71,"Good","G","VS1",63.5,55.0,2853.0,5.64,5.66,3.59],[0.79,"Ideal","D","SI2",62.8,57.0,2853.0,5.9,5.85,3.69],[0.79,"Premium","D","SI2",60.0,60.0,2853.0,6.07,6.03,3.63],[0.71,"Premium","E","SI1",62.7,58.0,2853.0,5.73,5.66,3.57],[0.82,"Premium","I","VS1",61.9,58.0,2853.0,5.99,5.97,3.7],[0.78,"Very Good","H","VS1",61.9,57.1,2854.0,5.87,5.95,3.66],[0.7,"Very Good","E","VS1",62.4,56.0,2854.0,5.64,5.7,3.54],[1.12,"Premium","H","I1",59.1,61.0,2854.0,6.78,6.75,4.0],[0.73,"Premium","E","VS2",62.0,57.0,2854.0,5.86,5.76,3.6],[0.91,"Fair","J","VS2",64.4,62.0,2854.0,6.06,6.03,3.89],[0.91,"Fair","J","VS2",65.4,60.0,2854.0,6.04,6.0,3.94],[0.91,"Good","J","VS2",64.2,58.0,2854.0,6.12,6.09,3.92],[0.91,"Fair","H","SI1",65.8,58.0,2854.0,6.04,6.01,3.96],[0.7,"Premium","E","VS1",58.4,59.0,2854.0,5.91,5.83,3.43],[0.68,"Premium","F","VVS2",61.7,57.0,2854.0,5.67,5.64,3.49],[0.73,"Very Good","F","VS2",62.5,57.0,2855.0,5.7,5.75,3.58],[1.03,"Good","J","SI1",63.6,57.0,2855.0,6.38,6.29,4.03],[0.74,"Premium","D","VS2",62.4,57.0,2855.0,5.8,5.74,3.6],[0.98,"Fair","E","SI2",53.3,67.0,2855.0,6.82,6.74,3.61],[1.02,"Fair","I","SI1",53.0,63.0,2856.0,6.84,6.77,3.66],[1.0,"Fair","G","SI2",67.8,61.0,2856.0,5.96,5.9,4.02],[1.02,"Ideal","H","SI2",61.6,55.0,2856.0,6.49,6.43,3.98],[0.6,"Ideal","F","VVS2",60.8,57.0,2856.0,5.44,5.49,3.32],[0.8,"Ideal","G","SI2",61.6,56.0,2856.0,5.97,6.01,3.69],[0.97,"Ideal","F","I1",60.7,56.0,2856.0,6.43,6.41,3.9],[1.0,"Fair","I","SI1",67.9,62.0,2856.0,6.19,6.03,4.15],[0.26,"Ideal","E","VS1",62.3,57.0,556.0,4.05,4.08,2.53],[0.26,"Ideal","E","VS1",62.1,56.0,556.0,4.09,4.12,2.55],[0.36,"Ideal","H","SI1",61.9,55.0,556.0,4.57,4.59,2.83],[0.34,"Good","G","VS2",57.5,61.0,556.0,4.6,4.66,2.66],[0.34,"Good","E","SI1",63.3,57.0,556.0,4.44,4.47,2.82],[0.34,"Good","E","SI1",63.5,55.0,556.0,4.44,4.47,2.83],[0.34,"Good","E","SI1",63.4,55.0,556.0,4.44,4.46,2.82],[0.34,"Very Good","G","VS2",59.6,62.0,556.0,4.54,4.56,2.71],[0.34,"Ideal","E","SI1",62.2,54.0,556.0,4.47,4.5,2.79],[0.32,"Good","E","VS2",64.1,54.0,556.0,4.34,4.37,2.79],[0.31,"Ideal","I","VVS1",61.6,55.0,557.0,4.36,4.41,2.7],[0.31,"Ideal","I","VVS1",61.3,56.0,557.0,4.36,4.38,2.68],[0.31,"Ideal","I","VVS1",62.3,54.0,557.0,4.37,4.4,2.73],[0.31,"Ideal","I","VVS1",62.0,54.0,557.0,4.37,4.4,2.72],[0.31,"Ideal","I","VVS1",62.7,53.0,557.0,4.33,4.35,2.72],[0.31,"Ideal","I","VVS1",62.2,53.0,557.0,4.36,4.38,2.72],[0.31,"Ideal","G","VS2",62.2,53.6,557.0,4.32,4.35,2.7],[0.31,"Ideal","H","VS1",61.6,54.8,557.0,4.35,4.37,2.69],[0.31,"Ideal","H","VS1",61.8,54.2,557.0,4.33,4.37,2.69],[0.33,"Premium","G","SI2",59.4,59.0,557.0,4.52,4.5,2.68],[0.33,"Premium","F","SI2",62.3,58.0,557.0,4.43,4.4,2.75],[0.33,"Premium","G","SI2",62.6,58.0,557.0,4.42,4.4,2.76],[0.33,"Ideal","G","SI2",61.9,56.0,557.0,4.45,4.41,2.74],[0.33,"Premium","F","SI2",63.0,58.0,557.0,4.42,4.4,2.78],[0.33,"Premium","J","VS1",62.8,58.0,557.0,4.41,4.38,2.76],[0.33,"Premium","J","VS1",61.5,61.0,557.0,4.46,4.39,2.72],[0.33,"Ideal","J","VS1",62.1,55.0,557.0,4.44,4.41,2.75],[0.33,"Ideal","I","SI1",63.0,57.0,557.0,4.39,4.37,2.76],[0.33,"Good","I","SI1",63.6,53.0,557.0,4.43,4.4,2.81],[0.33,"Premium","I","SI1",60.4,59.0,557.0,4.54,4.5,2.73],[1.0,"Fair","H","SI2",66.1,56.0,2856.0,6.21,5.97,4.04],[0.77,"Premium","F","SI1",60.8,59.0,2856.0,5.92,5.86,3.58],[0.77,"Premium","F","SI1",61.0,58.0,2856.0,5.94,5.9,3.61],[0.7,"Good","E","VVS2",60.1,63.0,2857.0,5.68,5.71,3.42],[0.9,"Very Good","G","SI2",63.1,58.0,2857.0,6.08,6.02,3.82],[0.72,"Ideal","E","SI1",62.3,57.0,2857.0,5.76,5.7,3.57],[0.9,"Premium","I","VS2",61.9,59.0,2857.0,6.2,6.14,3.82],[0.72,"Premium","E","SI1",62.1,58.0,2857.0,5.76,5.73,3.57],[0.7,"Ideal","G","VVS2",62.1,56.0,2858.0,5.63,5.71,3.52],[0.81,"Very Good","F","SI1",61.3,57.0,2858.0,6.02,6.05,3.7],[0.81,"Very Good","F","SI1",61.7,57.0,2858.0,6.0,6.05,3.72],[0.71,"Premium","E","VS2",61.0,60.0,2858.0,5.76,5.69,3.49],[0.7,"Premium","E","VS2",61.4,59.0,2858.0,5.73,5.7,3.51],[0.71,"Premium","E","VS2",61.5,60.0,2858.0,5.76,5.68,3.52],[0.71,"Very Good","E","VS2",63.5,59.0,2858.0,5.68,5.59,3.58],[0.92,"Premium","J","SI1",62.9,58.0,2858.0,6.22,6.18,3.9],[0.76,"Ideal","E","SI1",62.7,54.0,2858.0,5.88,5.83,3.67],[0.73,"Ideal","D","SI1",61.5,56.0,2858.0,5.84,5.8,3.58],[0.71,"Premium","D","VS2",60.4,62.0,2858.0,5.74,5.72,3.46],[0.7,"Good","E","VVS2",63.6,62.0,2858.0,5.61,5.58,3.56],[0.9,"Fair","G","SI2",64.5,56.0,2858.0,6.06,6.0,3.89],[0.71,"Fair","D","VS2",56.9,65.0,2858.0,5.89,5.84,3.34],[0.7,"Ideal","D","VS2",61.0,57.0,2859.0,5.76,5.74,3.51],[0.7,"Premium","D","VS2",62.4,56.0,2859.0,5.72,5.66,3.55],[0.77,"Premium","F","VS1",60.9,60.0,2859.0,5.91,5.88,3.59],[0.71,"Ideal","G","VS1",61.5,56.0,2859.0,5.74,5.78,3.54],[0.7,"Premium","D","VS2",59.6,61.0,2859.0,5.8,5.77,3.45],[0.75,"Fair","F","VS1",55.8,70.0,2859.0,6.09,5.98,3.37],[0.83,"Premium","E","SI2",59.2,60.0,2859.0,6.17,6.12,3.64],[0.71,"Very Good","F","VS2",61.3,61.0,2860.0,5.68,5.73,3.5],[0.9,"Very Good","J","SI2",63.6,58.0,2860.0,6.07,6.1,3.87],[0.6,"Ideal","E","VVS2",61.9,54.9,2860.0,5.41,5.44,3.35],[0.71,"Premium","D","VS1",62.9,57.0,2860.0,5.66,5.6,3.54],[0.53,"Ideal","F","VVS1",61.4,57.0,2860.0,5.23,5.2,3.2],[0.71,"Premium","D","SI1",60.7,58.0,2861.0,5.95,5.78,3.56],[0.62,"Ideal","G","VVS2",61.6,56.0,2861.0,5.45,5.48,3.37],[0.62,"Ideal","G","VVS2",61.6,56.0,2861.0,5.48,5.51,3.38],[0.9,"Premium","I","SI1",63.0,58.0,2861.0,6.09,6.01,3.81],[0.62,"Fair","F","IF",60.1,61.0,2861.0,5.53,5.56,3.33],[0.82,"Premium","E","SI2",61.7,59.0,2861.0,6.01,5.98,3.7],[0.66,"Premium","D","VS1",61.0,58.0,2861.0,5.67,5.57,3.43],[0.7,"Very Good","D","SI1",62.5,55.0,2862.0,5.67,5.72,3.56],[0.8,"Very Good","F","SI1",62.6,58.0,2862.0,5.9,5.92,3.7],[0.8,"Very Good","D","SI2",62.5,59.0,2862.0,5.88,5.92,3.69],[0.79,"Premium","F","SI1",62.3,54.0,2862.0,5.97,5.91,3.7],[0.71,"Very Good","F","VVS1",63.2,60.0,2862.0,5.65,5.61,3.56],[0.7,"Ideal","H","VS2",61.1,57.0,2862.0,5.71,5.74,3.5],[0.7,"Very Good","E","VS2",58.7,63.0,2862.0,5.73,5.69,3.35],[0.79,"Premium","H","VS1",60.0,60.0,2862.0,6.07,5.99,3.64],[0.7,"Premium","E","VS2",59.5,59.0,2862.0,5.82,5.77,3.45],[1.22,"Premium","E","I1",60.9,57.0,2862.0,6.93,6.88,4.21],[1.01,"Fair","E","SI2",67.6,57.0,2862.0,6.21,6.11,4.18],[0.73,"Premium","E","VS2",62.5,61.0,2862.0,5.78,5.64,3.59],[0.91,"Good","I","VS2",64.3,58.0,2863.0,6.05,6.09,3.9],[0.71,"Ideal","D","SI1",60.8,56.0,2863.0,5.8,5.77,3.52],[0.83,"Premium","G","SI1",62.3,58.0,2863.0,6.01,5.97,3.73],[0.84,"Premium","F","SI2",62.3,59.0,2863.0,6.06,6.01,3.76],[0.71,"Premium","D","SI1",61.0,61.0,2863.0,5.82,5.75,3.53],[0.71,"Premium","D","SI1",59.7,59.0,2863.0,5.82,5.8,3.47],[0.71,"Premium","D","SI1",61.7,56.0,2863.0,5.8,5.68,3.54],[0.71,"Ideal","D","SI1",61.7,57.0,2863.0,5.75,5.7,3.53],[0.71,"Premium","D","SI1",61.4,58.0,2863.0,5.79,5.75,3.54],[0.71,"Premium","D","SI1",60.6,58.0,2863.0,5.79,5.77,3.5],[0.91,"Premium","J","SI1",59.5,62.0,2863.0,6.4,6.18,3.74],[0.9,"Premium","J","VS2",59.8,62.0,2863.0,6.24,6.21,3.72],[0.71,"Premium","H","VVS2",61.5,62.0,2863.0,5.74,5.68,3.51],[0.71,"Premium","E","SI1",59.1,61.0,2863.0,5.84,5.8,3.44],[0.72,"Ideal","F","VS2",59.5,57.0,2863.0,5.91,5.86,3.5],[0.72,"Premium","E","SI1",60.9,60.0,2863.0,5.78,5.74,3.51],[0.71,"Ideal","E","VS2",61.0,55.0,2863.0,5.79,5.75,3.52],[0.81,"Ideal","E","SI2",60.3,57.0,2864.0,6.07,6.04,3.65],[0.83,"Very Good","I","VS2",61.6,58.0,2865.0,6.05,6.07,3.73],[0.73,"Premium","D","SI1",60.8,55.0,2865.0,5.87,5.81,3.55],[0.56,"Very Good","D","VVS1",62.0,56.0,2866.0,5.25,5.3,3.27],[0.56,"Very Good","D","VVS1",61.8,55.0,2866.0,5.27,5.31,3.27],[0.71,"Ideal","E","VS1",62.2,55.0,2866.0,5.74,5.7,3.56],[0.7,"Ideal","H","VVS1",62.3,58.0,2866.0,5.66,5.7,3.54],[0.96,"Premium","I","SI1",61.3,58.0,2866.0,6.39,6.3,3.89],[0.71,"Very Good","H","VVS1",62.9,57.0,2867.0,5.67,5.69,3.57],[0.7,"Ideal","D","VS2",62.4,57.0,2867.0,5.68,5.61,3.52],[0.71,"Ideal","H","VVS1",60.4,57.0,2867.0,5.78,5.81,3.5],[0.8,"Premium","H","VS2",61.2,53.0,2867.0,6.05,5.98,3.68],[0.95,"Premium","F","SI2",58.4,57.0,2867.0,6.49,6.41,3.77],[0.82,"Ideal","F","SI2",62.3,56.0,2867.0,5.99,5.95,3.72],[0.52,"Ideal","F","VVS1",61.2,56.0,2867.0,5.21,5.19,3.18],[0.82,"Ideal","F","SI2",61.7,53.0,2867.0,6.12,6.0,3.74],[0.82,"Ideal","F","SI2",62.3,56.0,2867.0,6.02,5.96,3.73],[0.82,"Premium","F","SI2",59.7,57.0,2867.0,6.14,6.12,3.66],[0.8,"Ideal","G","SI1",61.3,57.0,2867.0,5.96,5.91,3.64],[0.96,"Fair","F","SI2",68.2,61.0,2867.0,6.07,5.88,4.1],[0.72,"Ideal","I","VS1",62.4,55.0,2868.0,5.72,5.75,3.58],[0.62,"Ideal","G","IF",60.5,57.0,2868.0,5.52,5.56,3.35],[0.79,"Premium","E","SI2",61.0,58.0,2868.0,5.96,5.9,3.62],[0.75,"Very Good","E","SI1",63.1,56.0,2868.0,5.78,5.7,3.62],[1.08,"Premium","D","I1",61.9,60.0,2869.0,6.55,6.48,4.03],[0.72,"Ideal","E","SI1",60.8,55.0,2869.0,5.77,5.84,3.53],[0.62,"Ideal","G","IF",61.8,56.0,2869.0,5.43,5.47,3.37],[0.73,"Ideal","G","VVS2",61.3,57.0,2869.0,5.84,5.81,3.57],[0.72,"Ideal","H","VVS2",60.9,57.0,2869.0,5.79,5.77,3.52],[0.52,"Premium","F","VVS2",61.8,60.0,2870.0,5.16,5.13,3.18],[0.83,"Ideal","E","SI2",62.2,57.0,2870.0,6.0,6.05,3.75],[0.64,"Premium","E","VVS2",62.1,58.0,2870.0,5.56,5.51,3.44],[0.8,"Ideal","G","SI1",62.5,57.0,2870.0,5.94,5.9,3.7],[0.74,"Ideal","H","SI1",62.1,56.0,2870.0,5.77,5.83,3.6],[0.72,"Ideal","F","SI1",61.5,56.0,2870.0,5.72,5.79,3.54],[0.82,"Ideal","H","VS2",59.5,57.0,2870.0,6.12,6.09,3.63],[0.73,"Premium","E","VS1",61.3,59.0,2870.0,5.81,5.78,3.55],[1.04,"Premium","I","I1",61.6,61.0,2870.0,6.47,6.45,3.98],[0.73,"Very Good","E","SI1",61.3,58.0,2871.0,5.76,5.83,3.55],[0.73,"Good","E","SI1",63.6,57.0,2871.0,5.7,5.72,3.63],[0.9,"Premium","J","SI1",62.8,59.0,2871.0,6.13,6.03,3.82],[0.75,"Ideal","I","SI1",61.8,55.0,2871.0,5.83,5.85,3.61],[0.79,"Ideal","G","SI1",62.6,55.0,2871.0,5.91,5.95,3.71],[0.7,"Good","D","SI1",62.5,56.7,2872.0,5.59,5.62,3.51],[0.75,"Very Good","D","SI1",60.7,55.0,2872.0,5.87,5.92,3.58],[1.02,"Ideal","I","I1",61.7,56.0,2872.0,6.44,6.49,3.99],[0.7,"Very Good","G","SI2",59.0,62.0,2872.0,5.79,5.81,3.42],[0.7,"Ideal","D","SI1",61.8,56.0,2872.0,5.63,5.73,3.51],[0.7,"Good","E","SI1",61.4,64.0,2872.0,5.66,5.71,3.49],[0.7,"Ideal","D","SI1",61.4,54.0,2872.0,5.71,5.75,3.52],[0.7,"Ideal","D","SI1",60.7,56.0,2872.0,5.72,5.75,3.48],[0.7,"Very Good","D","SI1",60.2,60.0,2872.0,5.75,5.82,3.48],[0.72,"Very Good","E","VS2",58.3,57.0,2872.0,5.89,5.94,3.45],[0.74,"Ideal","E","SI1",62.3,58.0,2872.0,5.74,5.78,3.59],[0.84,"Good","G","SI1",65.1,55.0,2872.0,5.88,5.97,3.86],[0.76,"Very Good","F","VS2",62.0,58.0,2873.0,5.8,5.86,3.62],[0.77,"Very Good","E","SI1",63.2,58.0,2873.0,5.8,5.84,3.68],[0.76,"Ideal","E","SI2",62.8,56.0,2873.0,5.78,5.82,3.64],[1.0,"Ideal","I","SI2",61.7,56.0,2873.0,6.45,6.41,3.97],[1.0,"Fair","H","SI1",65.5,62.0,2873.0,6.14,6.07,4.0],[0.9,"Fair","I","SI1",65.7,58.0,2873.0,6.03,6.0,3.95],[0.9,"Premium","J","SI1",61.8,58.0,2873.0,6.16,6.13,3.8],[0.9,"Good","J","SI1",64.0,61.0,2873.0,6.0,5.96,3.83],[0.9,"Fair","I","SI1",65.3,61.0,2873.0,5.98,5.94,3.89],[0.9,"Fair","I","SI1",65.8,56.0,2873.0,6.01,5.96,3.94],[0.9,"Premium","J","SI1",60.9,61.0,2873.0,6.26,6.22,3.8],[0.78,"Premium","F","VS2",62.6,58.0,2874.0,5.91,5.82,3.67],[0.71,"Premium","D","VS2",61.2,59.0,2874.0,5.69,5.74,3.5],[0.7,"Premium","F","VS1",59.0,59.0,2874.0,5.79,5.77,3.41],[0.7,"Premium","F","VS1",60.8,62.0,2874.0,5.71,5.67,3.46],[0.7,"Premium","G","VVS2",61.8,58.0,2874.0,5.67,5.63,3.49],[0.7,"Ideal","F","VS1",61.0,55.0,2874.0,5.77,5.73,3.51],[0.7,"Ideal","F","VS1",61.6,55.0,2874.0,5.75,5.71,3.53],[0.7,"Ideal","F","VS1",62.4,56.0,2874.0,5.69,5.65,3.54],[0.7,"Premium","G","VVS2",62.9,59.0,2874.0,5.68,5.61,3.55],[1.0,"Fair","H","SI2",67.7,60.0,2875.0,6.11,5.98,4.09],[0.77,"Ideal","H","SI1",62.4,56.0,2875.0,5.84,5.9,3.66],[1.0,"Fair","J","VS1",65.5,55.0,2875.0,6.3,6.25,4.11],[1.0,"Fair","I","SI1",66.3,61.0,2875.0,6.08,6.03,4.01],[1.0,"Fair","H","SI2",69.5,55.0,2875.0,6.17,6.1,4.26],[0.73,"Premium","E","VS1",62.6,60.0,2876.0,5.68,5.75,3.58],[0.79,"Premium","E","VS2",60.6,53.0,2876.0,6.04,5.98,3.64],[0.72,"Very Good","H","VS1",62.2,54.0,2877.0,5.74,5.76,3.57],[0.71,"Ideal","E","VS1",62.4,56.0,2877.0,5.75,5.7,3.57],[0.74,"Ideal","G","VS2",62.3,55.0,2877.0,5.8,5.83,3.62],[0.7,"Good","H","VVS1",62.7,56.0,2877.0,5.6,5.66,3.53],[0.7,"Good","F","VS1",59.1,62.0,2877.0,5.82,5.86,3.44],[0.79,"Very Good","F","SI1",62.8,59.0,2878.0,5.86,5.89,3.69],[0.79,"Very Good","F","SI1",62.7,60.0,2878.0,5.82,5.89,3.67],[0.79,"Very Good","D","SI2",59.7,58.0,2878.0,6.0,6.07,3.6],[0.71,"Ideal","I","VS2",61.5,55.0,2878.0,5.76,5.78,3.55],[0.79,"Ideal","F","SI1",62.8,56.0,2878.0,5.88,5.9,3.7],[0.73,"Very Good","F","SI1",61.4,56.0,2879.0,5.81,5.86,3.58],[0.63,"Premium","E","IF",60.3,62.0,2879.0,5.55,5.53,3.34],[0.7,"Premium","F","VS1",60.4,60.0,2879.0,5.73,5.7,3.45],[0.71,"Premium","F","VS1",62.7,58.0,2879.0,5.71,5.67,3.57],[0.84,"Ideal","G","SI2",61.0,56.0,2879.0,6.13,6.1,3.73],[0.84,"Ideal","G","SI2",62.3,55.0,2879.0,6.08,6.03,3.77],[1.02,"Ideal","J","SI2",60.3,54.0,2879.0,6.53,6.5,3.93],[0.72,"Fair","F","VS1",56.9,69.0,2879.0,5.93,5.77,3.33],[0.72,"Ideal","F","VS1",62.0,56.0,2879.0,5.76,5.73,3.56],[0.92,"Very Good","J","SI2",58.7,61.0,2880.0,6.34,6.43,3.75],[0.74,"Very Good","D","SI1",63.9,57.0,2880.0,5.72,5.74,3.66],[0.7,"Ideal","H","VVS1",62.0,55.0,2881.0,5.74,5.71,3.55],[0.71,"Very Good","E","VS2",60.0,59.0,2881.0,5.84,5.83,3.5],[1.05,"Premium","H","I1",62.0,59.0,2881.0,6.5,6.47,4.02],[0.7,"Very Good","H","IF",62.8,56.0,2882.0,5.62,5.65,3.54],[0.54,"Ideal","F","VVS1",61.8,56.0,2882.0,5.23,5.26,3.24],[0.73,"Premium","F","VS2",59.9,58.0,2882.0,5.87,5.84,3.51],[0.88,"Fair","F","SI1",56.6,65.0,2882.0,6.39,6.32,3.6],[0.73,"Premium","F","VS2",58.7,57.0,2882.0,5.97,5.92,3.49],[0.72,"Ideal","D","SI1",61.8,56.0,2883.0,5.75,5.81,3.57],[0.9,"Good","H","SI2",62.7,64.0,2883.0,6.09,6.0,3.79],[0.9,"Fair","H","SI2",65.0,61.0,2883.0,6.01,5.96,3.89],[1.03,"Fair","I","SI2",65.3,55.0,2884.0,6.32,6.27,4.11],[0.84,"Very Good","F","SI1",63.8,57.0,2885.0,5.95,6.0,3.81],[1.01,"Premium","I","SI1",62.7,60.0,2885.0,6.36,6.27,3.96],[0.77,"Ideal","D","SI2",61.5,55.0,2885.0,5.9,5.93,3.64],[0.8,"Fair","E","SI1",56.3,63.0,2885.0,6.22,6.14,3.48],[0.9,"Fair","D","SI2",66.9,57.0,2885.0,6.02,5.9,3.99],[0.73,"Ideal","E","SI1",61.4,56.0,2886.0,5.79,5.81,3.56],[0.72,"Ideal","E","SI1",62.7,55.0,2886.0,5.64,5.69,3.55],[0.71,"Very Good","D","SI1",62.4,54.0,2887.0,5.71,5.79,3.59],[0.7,"Premium","E","VS1",62.6,59.0,2887.0,5.66,5.69,3.55],[0.79,"Ideal","I","VS1",61.7,59.0,2888.0,5.93,5.96,3.67],[0.72,"Very Good","G","VVS2",62.5,58.0,2889.0,5.68,5.72,3.56],[0.7,"Very Good","E","VS2",63.5,54.0,2889.0,5.62,5.66,3.58],[0.7,"Very Good","F","VS1",62.2,58.0,2889.0,5.64,5.75,3.54],[0.9,"Good","H","SI2",63.5,58.0,2889.0,6.09,6.14,3.88],[0.71,"Very Good","F","VS1",62.8,56.0,2889.0,5.69,5.72,3.58],[0.5,"Ideal","E","VVS2",62.2,54.0,2889.0,5.08,5.12,3.17],[0.5,"Ideal","E","VVS2",62.2,54.0,2889.0,5.09,5.11,3.17],[0.74,"Ideal","F","SI1",61.2,56.0,2889.0,5.83,5.87,3.58],[0.77,"Premium","F","VS2",61.8,56.0,2889.0,5.94,5.9,3.66],[0.77,"Premium","E","SI1",59.8,61.0,2889.0,5.99,5.95,3.57],[0.8,"Ideal","F","SI1",61.5,54.0,2890.0,6.07,6.0,3.71],[0.8,"Ideal","F","SI1",62.4,57.0,2890.0,5.9,5.87,3.67],[0.8,"Premium","F","SI1",61.5,60.0,2890.0,5.97,5.94,3.66],[0.8,"Good","F","SI1",63.8,59.0,2890.0,5.87,5.83,3.73],[0.66,"Ideal","G","VVS1",61.5,56.0,2890.0,5.61,5.58,3.44],[0.71,"Very Good","E","VS2",61.2,58.0,2891.0,5.71,5.79,3.52],[0.71,"Ideal","F","VS2",61.2,56.0,2891.0,5.73,5.77,3.52],[0.71,"Ideal","E","VS2",61.6,56.0,2891.0,5.74,5.76,3.54],[0.71,"Ideal","E","VS2",62.7,56.0,2891.0,5.71,5.75,3.59],[0.72,"Ideal","D","SI1",61.1,56.0,2891.0,5.78,5.81,3.54],[0.71,"Good","D","VS2",62.3,61.0,2891.0,5.7,5.73,3.56],[0.86,"Ideal","H","SI2",61.8,55.0,2892.0,6.12,6.14,3.79],[1.19,"Fair","H","I1",65.1,59.0,2892.0,6.62,6.55,4.29],[0.71,"Very Good","F","VS1",62.6,55.0,2893.0,5.66,5.71,3.56],[0.82,"Very Good","G","SI2",62.5,56.0,2893.0,5.99,6.04,3.76],[0.71,"Ideal","G","VVS2",61.5,57.0,2893.0,5.73,5.75,3.53],[0.75,"Ideal","F","VS2",62.5,57.0,2893.0,5.78,5.83,3.63],[0.7,"Very Good","H","VVS1",59.2,60.0,2893.0,5.87,5.78,3.45],[0.8,"Ideal","G","SI2",62.5,55.0,2893.0,5.89,5.92,3.69],[0.82,"Good","G","SI2",59.9,62.0,2893.0,6.02,6.04,3.61],[0.82,"Very Good","G","SI1",63.4,55.0,2893.0,6.0,5.93,3.78],[0.82,"Premium","G","SI1",59.9,59.0,2893.0,6.09,6.06,3.64],[0.81,"Very Good","E","SI2",62.4,57.0,2894.0,5.91,5.99,3.71],[0.81,"Ideal","G","SI2",62.2,57.0,2894.0,5.96,6.0,3.72],[0.76,"Ideal","F","SI1",61.4,56.0,2894.0,5.88,5.92,3.62],[0.71,"Very Good","G","VS2",60.9,56.0,2895.0,5.75,5.78,3.51],[0.7,"Very Good","F","VS1",61.8,59.0,2895.0,5.66,5.76,3.53],[0.7,"Ideal","G","VVS2",62.1,53.0,2895.0,5.71,5.75,3.56],[0.74,"Very Good","G","VS1",59.8,58.0,2896.0,5.85,5.89,3.51],[0.77,"Very Good","G","VS2",61.3,60.0,2896.0,5.81,5.91,3.59],[0.77,"Very Good","G","VS2",58.3,63.0,2896.0,6.0,6.05,3.51],[0.53,"Ideal","F","VVS1",61.6,56.0,2896.0,5.18,5.24,3.21],[0.79,"Ideal","D","SI1",61.5,56.0,2896.0,5.91,5.96,3.65],[0.73,"Ideal","E","SI2",61.5,55.0,2896.0,5.82,5.86,3.59],[0.77,"Ideal","D","SI2",62.1,56.0,2896.0,5.83,5.89,3.64],[0.77,"Premium","E","SI1",60.9,58.0,2896.0,5.94,5.88,3.6],[1.01,"Very Good","I","I1",63.1,57.0,2896.0,6.39,6.35,4.02],[1.01,"Ideal","I","I1",61.5,57.0,2896.0,6.46,6.45,3.97],[0.6,"Very Good","D","VVS2",60.6,57.0,2897.0,5.48,5.51,3.33],[0.76,"Premium","E","SI1",61.1,58.0,2897.0,5.91,5.85,3.59],[0.54,"Ideal","D","VVS2",61.4,52.0,2897.0,5.3,5.34,3.26],[0.72,"Ideal","E","SI1",62.5,55.0,2897.0,5.69,5.74,3.57],[0.72,"Good","F","VS1",59.4,61.0,2897.0,5.82,5.89,3.48],[0.74,"Premium","D","VS2",61.8,58.0,2897.0,5.81,5.77,3.58],[1.12,"Premium","J","SI2",60.6,59.0,2898.0,6.68,6.61,4.03]],"arguments":{},"schema":[{"type":"double","name":"carat"},{"type":"string","name":"cut"},{"type":"string","name":"color"},{"type":"string","name":"clarity"},{"type":"double","name":"depth"},{"type":"double","name":"table"},{"type":"bigint","name":"price"},{"type":"double","name":"x"},{"type":"double","name":"y"},{"type":"double","name":"z"}],"overflow":true,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.435806407271E12,"submitTime":1.435806401767E12,"finishTime":1.435806408853E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"a61409cf-7e31-4ea2-a7da-a61fa80ef185"},{"version":"CommandV1","origId":2400,"guid":"f07b32ff-6631-4417-8e44-723dc977dacf","subtype":"command","commandType":"auto","position":13.0,"command":"%md ### Transform features\n\nSome of our features are text, and we want them to be numerical so we can train a linear model.  We use the Pandas and scikit-learn APIs for these transformations.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401776E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"3f7a3710-d8db-4a4f-94a3-8c0f8067fd1f"},{"version":"CommandV1","origId":2401,"guid":"095dbc94-ed79-49ab-8fd5-ec0d486988f6","subtype":"command","commandType":"auto","position":14.0,"command":"%md First, we convert the features to numerical values, in the correct order based on the feature meanings.  Higher indices are \"better.\"  This ordering will help us interpret model weights later on.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401785E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"510d407b-ae1c-4b54-bc85-4d7cbfe03131"},{"version":"CommandV1","origId":2402,"guid":"709ac0a2-32c1-4fd8-872d-7b1ed008f5d8","subtype":"command","commandType":"auto","position":15.0,"command":"pandasData['cut'] = pandasData['cut'].replace({'Fair':0, 'Good':1, 'Very Good':2, 'Premium':3, 'Ideal':4})\npandasData['color'] = pandasData['color'].replace({'J':0, 'I':1, 'H':2, 'G':3, 'F':4, 'E':5, 'D':6})\npandasData['clarity'] = pandasData['clarity'].replace({'I1':0, 'SI1':1, 'SI2':2, 'VS1':3, 'VS2':4, 'VVS1':5, 'VVS2':6, 'IF':7})\npandasData","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\n       carat  cut  color  clarity  depth  table  price     x     y     z\n0       0.23    4      5        2   61.5     55    326  3.95  3.98  2.43\n1       0.21    3      5        1   59.8     61    326  3.89  3.84  2.31\n2       0.23    1      5        3   56.9     65    327  4.05  4.07  2.31\n3       0.29    3      1        4   62.4     58    334  4.20  4.23  2.63\n4       0.31    1      0        2   63.3     58    335  4.34  4.35  2.75\n5       0.24    2      0        6   62.8     57    336  3.94  3.96  2.48\n6       0.24    2      1        5   62.3     57    336  3.95  3.98  2.47\n7       0.26    2      2        1   61.9     55    337  4.07  4.11  2.53\n8       0.22    0      5        4   65.1     61    337  3.87  3.78  2.49\n9       0.23    2      2        3   59.4     61    338  4.00  4.05  2.39\n10      0.30    1      0        1   64.0     55    339  4.25  4.28  2.73\n11      0.23    4      0        3   62.8     56    340  3.93  3.90  2.46\n12      0.22    3      4        1   60.4     61    342  3.88  3.84  2.33\n13      0.31    4      0        2   62.2     54    344  4.35  4.37  2.71\n14      0.20    3      5        2   60.2     62    345  3.79  3.75  2.27\n15      0.32    3      5        0   60.9     58    345  4.38  4.42  2.68\n16      0.30    4      1        2   62.0     54    348  4.31  4.34  2.68\n17      0.30    1      0        1   63.4     54    351  4.23  4.29  2.70\n18      0.30    1      0        1   63.8     56    351  4.23  4.26  2.71\n19      0.30    2      0        1   62.7     59    351  4.21  4.27  2.66\n20      0.30    1      1        2   63.3     56    351  4.26  4.30  2.71\n21      0.23    2      5        4   63.8     55    352  3.85  3.92  2.48\n22      0.23    2      2        3   61.0     57    353  3.94  3.96  2.41\n23      0.31    2      0        1   59.4     62    353  4.39  4.43  2.62\n24      0.31    2      0        1   58.1     62    353  4.44  4.47  2.59\n25      0.23    2      3        6   60.4     58    354  3.97  4.01  2.41\n26      0.24    3      1        3   62.5     57    355  3.97  3.94  2.47\n27      0.30    2      0        4   62.2     57    357  4.28  4.30  2.67\n28      0.23    2      6        4   60.5     61    357  3.96  3.97  2.40\n29      0.23    2      4        3   60.9     57    357  3.96  3.99  2.42\n...      ...  ...    ...      ...    ...    ...    ...   ...   ...   ...\n53910   0.70    3      5        1   60.5     58   2753  5.74  5.77  3.48\n53911   0.57    3      5        7   59.8     60   2753  5.43  5.38  3.23\n53912   0.61    3      4        5   61.8     59   2753  5.48  5.40  3.36\n53913   0.80    1      3        4   64.2     58   2753  5.84  5.81  3.74\n53914   0.84    1      1        3   63.7     59   2753  5.94  5.90  3.77\n53915   0.77    4      5        2   62.1     56   2753  5.84  5.86  3.63\n53916   0.74    1      6        1   63.1     59   2753  5.71  5.74  3.61\n53917   0.90    2      0        1   63.2     60   2753  6.12  6.09  3.86\n53918   0.76    3      1        3   59.3     62   2753  5.93  5.85  3.49\n53919   0.76    4      1        5   62.2     55   2753  5.89  5.87  3.66\n53920   0.70    2      5        4   62.4     60   2755  5.57  5.61  3.49\n53921   0.70    2      5        4   62.8     60   2755  5.59  5.65  3.53\n53922   0.70    2      6        3   63.1     59   2755  5.67  5.58  3.55\n53923   0.73    4      1        4   61.3     56   2756  5.80  5.84  3.57\n53924   0.73    4      1        4   61.6     55   2756  5.82  5.84  3.59\n53925   0.79    4      1        1   61.6     56   2756  5.95  5.97  3.67\n53926   0.71    4      5        1   61.9     56   2756  5.71  5.73  3.54\n53927   0.79    1      4        1   58.1     59   2756  6.06  6.13  3.54\n53928   0.79    3      5        2   61.4     58   2756  6.03  5.96  3.68\n53929   0.71    4      3        3   61.4     56   2756  5.76  5.73  3.53\n53930   0.71    3      5        1   60.5     55   2756  5.79  5.74  3.49\n53931   0.71    3      4        1   59.8     62   2756  5.74  5.73  3.43\n53932   0.70    2      5        4   60.5     59   2757  5.71  5.76  3.47\n53933   0.70    2      5        4   61.2     59   2757  5.69  5.72  3.49\n53934   0.72    3      6        1   62.7     59   2757  5.69  5.73  3.58\n53935   0.72    4      6        1   60.8     57   2757  5.75  5.76  3.50\n53936   0.72    1      6        1   63.1     55   2757  5.69  5.75  3.61\n53937   0.70    2      6        1   62.8     60   2757  5.66  5.68  3.56\n53938   0.86    3      2        2   61.0     58   2757  6.15  6.12  3.74\n53939   0.75    4      6        2   62.2     55   2757  5.83  5.87  3.64\n\n[53940 rows x 10 columns]\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806408921E12,"submitTime":1.435806401793E12,"finishTime":1.435806409101E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"e7d3bf3d-30e2-4287-9025-407d9a2c4c7a"},{"version":"CommandV1","origId":2403,"guid":"8e130ea5-3cd4-4444-b599-5a0e8a411677","subtype":"command","commandType":"auto","position":16.0,"command":"%md Now, we normalize each feature (column) to have unit variance.  (This normalization or standardization often improves performance. See [Wikipedia](http://en.wikipedia.org/wiki/Feature_scaling#Standardization) for more info.)","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401801E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"ed833542-1ddd-4bad-b4ef-226e8836764f"},{"version":"CommandV1","origId":2404,"guid":"6773c489-5c18-4869-a5ab-3feb75e8658c","subtype":"command","commandType":"auto","position":17.0,"command":"%md ### Utility for R datasets hosted on DBC\n\nThis provides helper methods and statistics about the R datasets hosted on DBC.\nRun this notebook to import helper data and utility methods into another notebook:\n```\n%run \"#workspace/databricks_guide/09 Spark MLlib/util/RDatasetUtil\"\n```","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401809E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"fac26e1c-1d37-43dd-ad38-3f79161f9f83"},{"version":"CommandV1","origId":2405,"guid":"da61d443-923b-471e-8a29-ad52471271bf","subtype":"command","commandType":"auto","position":18.0,"command":"import pandas\nimport cStringIO\nfrom pyspark.sql import *\n\ndef _getRDatasetStats(path_text, rDatasetsMetadataBc):#g_d_s_data):\n  \"\"\"Read an R dataset as text, and parse it using pandas.  Extract metadata.\n  \"\"\"\n  (path, text) = path_text\n  rDatasetsMetadata = rDatasetsMetadataBc.value\n  output = cStringIO.StringIO(text)\n  df = pandas.read_csv(output)\n  df = df.rename(columns={\"Unnamed: 0\" : \"recordIndex\"})\n  (nRows, nCols) = df.shape\n  features = list(df.columns)\n  (package, dataset, fileSize) = rDatasetsMetadata[path]\n  return (package, dataset, fileSize, nRows, nCols, features)\n  \"\"\"\n  output = cStringIO.StringIO(g_d_s_data[3])\n  df = pandas.read_csv(output)\n  df = df.rename(columns={\"Unnamed: 0\" : \"recordIndex\"})\n  (nRows, nCols) = df.shape\n  features = list(df.columns)\n  return (g_d_s_data[0], g_d_s_data[1], g_d_s_data[2], nRows, nCols, features)\n  \"\"\"\n\nclass RDatasetUtil(object):\n  \"\"\"\n  Helper class for working with R datasets hosted on DBC\n  \"\"\"\n  def __init__(self):\n    # rDataBaseDirectory: base directory where R datasets are stored\n    self.rDataBaseDirectory = \"/databricks-datasets/Rdatasets/data-001\"\n    # rDataPackages: list of datasets in different R packages\n    self.rDataPackages = map(lambda x: str(x.name)[:-1], dbutils.fs.ls(self.rDataBaseDirectory + \"/csv\"))\n    # rDatasets is a map: package -> list of datasets in package\n    self._rDatasets = dict(map(lambda package: (package, self._getDatasetsInPackage(package)), self.rDataPackages))\n\n  @property\n  def datasets(self):\n    \"\"\"datasets is a map: package -> list of datasets in package\"\"\"\n    return self._rDatasets\n\n  @property\n  def stats(self):\n    \"\"\"stats is a Spark DataFrame with statistics about each R dataset.\n    It has fields: 'package', 'dataset', 'fileSize_MB', 'nRows', 'nCols', 'features'.\n    It is only available after getAllStats() has been run; beforehand, this property has value None.\n    \"\"\"\n    if hasattr(self, \"_allDatasetStats\"):\n      return self._allDatasetStats\n    else:\n      print 'WARNING: RDatasetUtil: stats is not available until getAllStats has been run'\n      return None\n\n  def getRDataPackagePath(self, package):\n    \"\"\"returns the path to a package of datasets in DBFS\"\"\"\n    return self.rDataBaseDirectory + \"/csv/\" + package\n\n  def getRDataPath(self, package, dataset):\n    \"\"\"returns the path to a dataset in DBFS\"\"\"\n    return self.getRDataPackagePath(package) + \"/\" + dataset + \".csv\"\n\n  def getRDocPath(self, package, dataset):\n    \"\"\"Returns the path to a dataset documentation in DBFS\n    E.g.:  dbutils.fs.ls(getRDataPath('ggplot2', 'diamonds'))\n    \"\"\"\n    return self.rDataBaseDirectory + \"/doc/\" + package + \"/\" + dataset + \".html\"\n\n  def displayRDatasetDoc(self, package, dataset):\n    \"\"\" Helper method for displaying the HTML doc for an R dataset. \"\"\"\n    displayHTML(sc.wholeTextFiles(self.getRDocPath(package, dataset)).take(1)[0][1])\n\n  def getAllStats(self):\n    \"\"\"Get metadata for all R datasets.\n    This is SLOW since it loads all of the R datasets via pandas on the driver.\n    It must be called before stats is accessible.\n    \"\"\"\n    # rDatasetsMetadata: map: package -> dataset -> fileSize\n    rDatasetsMetadata = self._getDatasetsMetadata()\n    allPackagePaths = [] # list of paths to dataset packages\n    for package in self.rDataPackages:\n      allPackagePaths += [self.getRDataPackagePath(package)]\n    allDatasets = sc.wholeTextFiles(allPackagePaths[0])\n    for packagePath in allPackagePaths[1:]:\n      allDatasets = allDatasets.union(sc.wholeTextFiles(packagePath))\n    rDatasetsMetadataBc = sc.broadcast(rDatasetsMetadata)\n    self._allDatasetStats = allDatasets.map(lambda path_text: _getRDatasetStats(path_text, rDatasetsMetadataBc)).toDF(['package', 'dataset', 'fileSize_MB', 'nRows', 'nCols', 'features'])\n    \"\"\"\n    allDatasetNames = [] # list of paths to datasets\n    for package in self.rDataPackages:\n      for dsMeta in rDatasetsMetadata[package]:\n        allDatasetNames += [(package, dsMeta[0], dsMeta[1])] # (package, dataset, fileSize)\n    allDatasets = sc.parallelize(map(lambda g_d_s: (g_d_s[0], g_d_s[1], g_d_s[2], sc.wholeTextFiles(self.getRDataPath(g_d_s[0], g_d_s[1])).collect()[0][1]), allDatasetNames))\n    self._allDatasetStats = allDatasets.map(lambda g_d_s_data: _getRDatasetStats(g_d_s_data)).toDF(['package', 'dataset', 'fileSize_MB', 'nRows', 'nCols', 'features'])\n    \"\"\"\n    self._allDatasetStats.cache()\n\n  def loadDataset(self, package, dataset):\n    \"\"\"Load an R dataset and return it as a Spark DataFrame.\n    The first column is named \"recordIndex\" (i.e., line number).\n    Any columns with commas \",\" or periods \".\" have those characters replaced with underscores \"_\".\n    WARNING: This fails for R datasets which have missing (NaN) values.\n    \"\"\"\n    localData = sc.wholeTextFiles(self.getRDataPath(package, dataset)).collect()[0][1]\n    output = cStringIO.StringIO(localData)\n    pandasDF = pandas.read_csv(output)\n    pandasDF = pandasDF.rename(columns={\"Unnamed: 0\" : \"recordIndex\"}) # rename line number column\n    # change periods to underscores to make dataframe Spark SQL-friendly\n    renameColumns = {}\n    for col in pandasDF.columns:\n      if '.' in col or ',' in col:\n        renameColumns[col] = col.replace('.', '_').replace(',', '_')\n    pandasDF = pandasDF.rename(columns=renameColumns)\n    df = sqlContext.createDataFrame(pandasDF)\n    return df\n\n  def _getDatasetsInPackage(self, package):\n    return map(lambda x: str(x.name)[:-4], dbutils.fs.ls(self.getRDataPackagePath(package)))\n\n  def _getDatasetsMetadata(self):\n    \"\"\"Return map: path -> (package, dataset, fileSize in MB)\"\"\"\n    metadata = {}\n    for package in self.rDataPackages:\n      packageFileInfo = dbutils.fs.ls(self.getRDataPackagePath(package))\n      for info in packageFileInfo:\n        dataset = str(info.name)[:-4]\n        datasetSize = info.size / 1e6\n        metadata['dbfs:' + self.getRDataPath(package, dataset)] = (package, dataset, datasetSize)\n    return metadata","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806409116E12,"submitTime":1.435806401818E12,"finishTime":1.435806409304E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"d2a0d65f-4604-402a-8bbf-0be9c812c57a"},{"version":"CommandV1","origId":2406,"guid":"d7806418-38d6-46d4-9597-9696ccf2db27","subtype":"command","commandType":"auto","position":19.0,"command":"rDatasetUtil = RDatasetUtil()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806409306E12,"submitTime":1.435806401829E12,"finishTime":1.435806415642E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"d8dc256e-bf24-4df0-b424-b1e70fee1028"},{"version":"CommandV1","origId":2407,"guid":"b8eaccd3-4749-4d7f-816d-f2ea17a61d8d","subtype":"command","commandType":"auto","position":20.0,"command":"help(rDatasetUtil)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Help on RDatasetUtil in module __main__ object:\n\nclass RDatasetUtil(__builtin__.object)\n |  Helper class for working with R datasets hosted on DBC\n |  \n |  Methods defined here:\n |  \n |  __init__(self)\n |  \n |  displayRDatasetDoc(self, package, dataset)\n |      Helper method for displaying the HTML doc for an R dataset.\n |  \n |  getAllStats(self)\n |      Get metadata for all R datasets.\n |      This is SLOW since it loads all of the R datasets via pandas on the driver.\n |      It must be called before stats is accessible.\n |  \n |  getRDataPackagePath(self, package)\n |      returns the path to a package of datasets in DBFS\n |  \n |  getRDataPath(self, package, dataset)\n |      returns the path to a dataset in DBFS\n |  \n |  getRDocPath(self, package, dataset)\n |      Returns the path to a dataset documentation in DBFS\n |      E.g.:  dbutils.fs.ls(getRDataPath(&apos;ggplot2&apos;, &apos;diamonds&apos;))\n |  \n |  loadDataset(self, package, dataset)\n |      Load an R dataset and return it as a Spark DataFrame.\n |      The first column is named &quot;recordIndex&quot; (i.e., line number).\n |      Any columns with commas &quot;,&quot; or periods &quot;.&quot; have those characters replaced with underscores &quot;_&quot;.\n |      WARNING: This fails for R datasets which have missing (NaN) values.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  datasets\n |      datasets is a map: package -&gt; list of datasets in package\n |  \n |  stats\n |      stats is a Spark DataFrame with statistics about each R dataset.\n |      It has fields: &apos;package&apos;, &apos;dataset&apos;, &apos;fileSize_MB&apos;, &apos;nRows&apos;, &apos;nCols&apos;, &apos;features&apos;.\n |      It is only available after getAllStats() has been run; beforehand, this property has value None.\n\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806415645E12,"submitTime":1.435806401837E12,"finishTime":1.43580641572E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"cc3c2b1e-6a79-4257-adaa-eecdb3e7fe9a"},{"version":"CommandV1","origId":2408,"guid":"7fa5543f-df1c-4a36-a9f6-93800501cf4a","subtype":"command","commandType":"auto","position":21.0,"command":"%md #### \"rDatasetUtil\" is now available.\nRun rDatasetUtil.getAllStats() to compute stats for all R datasets, which will then be accessible via rDatasetUtil.stats.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401845E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"6639d2d1-2099-4881-8445-a24dceb6c271"},{"version":"CommandV1","origId":2409,"guid":"e7322294-2062-431d-9075-5756b4b8149f","subtype":"command","commandType":"auto","position":22.0,"command":"# Split data into a labels dataframe and a features dataframe\nlabels = pandasData['price']\nfeatureNames = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z']\nfeatures = pandasData[featureNames]","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806415729E12,"submitTime":1.435806401853E12,"finishTime":1.435806415773E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"1799be63-25a2-43e8-adf8-063d762c2400"},{"version":"CommandV1","origId":2410,"guid":"662b7a06-af66-458c-8fce-2c2af9180ac0","subtype":"command","commandType":"auto","position":23.0,"command":"# Normalize features (columns) to have unit variance\nfrom sklearn.preprocessing import normalize\nfeatures = normalize(features, axis=0)\nfeatures","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\narray([[ 0.00106702,  0.00553547,  0.005655  , ...,  0.0029123 ,\n         0.00293078,  0.00289958],\n       [ 0.00097424,  0.0041516 ,  0.005655  , ...,  0.00286806,\n         0.00282769,  0.00275639],\n       [ 0.00106702,  0.00138387,  0.005655  , ...,  0.00298603,\n         0.00299705,  0.00275639],\n       ..., \n       [ 0.00324745,  0.00276773,  0.006786  , ...,  0.00417307,\n         0.00418262,  0.00424794],\n       [ 0.00398973,  0.0041516 ,  0.002262  , ...,  0.00453434,\n         0.00450662,  0.00446272],\n       [ 0.00347941,  0.00553547,  0.006786  , ...,  0.0042984 ,\n         0.00432253,  0.0043434 ]])\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806415775E12,"submitTime":1.435806401861E12,"finishTime":1.435806416405E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"c6703a4f-7a1c-4e3c-bbb9-281f18a06d92"},{"version":"CommandV1","origId":2411,"guid":"f2f5834b-734b-48e6-82a8-f61569080c94","subtype":"command","commandType":"auto","position":24.0,"command":"%md ### Hold out a random test set\n\nWe hold out a random sample of the data for testing.  Note that this randomness can cause this notebook to produce different results each time it is run.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.43580640187E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"8a47bb81-91f3-4440-88e3-d8cbddb31279"},{"version":"CommandV1","origId":2412,"guid":"8ab903fa-09bb-4d6e-8e0b-ba59dc25ed73","subtype":"command","commandType":"auto","position":25.0,"command":"# Hold out 30% of the data for testing.  We will use the rest for training.\nfrom sklearn.cross_validation import train_test_split\ntrainingLabels, testLabels, trainingFeatures, testFeatures = train_test_split(labels, features, test_size=0.3)\nntrain, ntest = len(trainingLabels), len(testLabels)\nprint 'Split data randomly into 2 sets: %d training and %d test instances.' % (ntrain, ntest)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Split data randomly into 2 sets: 37758 training and 16182 test instances.\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806416414E12,"submitTime":1.435806401878E12,"finishTime":1.435806416561E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"e49174cc-1d5a-43bf-8157-4f8940b1c8f0"},{"version":"CommandV1","origId":2413,"guid":"7434286a-9b77-484b-a5ba-eba047dc534b","subtype":"command","commandType":"auto","position":26.0,"command":"%md ### Learn an initial model\n\nHere, we train a single model using fixed hyperparameters on the driver.  Later, we will do model tuning by training models in a distributed fashion.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401887E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"eadd756f-d979-494c-a37e-0c4f820f23ef"},{"version":"CommandV1","origId":2414,"guid":"d315ecce-644d-410b-a32b-1fbc0af28b1e","subtype":"command","commandType":"auto","position":27.0,"command":"# Train a model with fixed hyperparameters, and print out the intercept and coefficients.\nfrom sklearn import linear_model\norigAlpha = 0.5 # \"alpha\" is the regularization hyperparameter\norigClf = linear_model.Ridge(alpha=origAlpha)\norigClf.fit(features, labels)\nprint 'Trained model with fixed alpha = %g' % origAlpha\nprint '  Model intercept: %g' % origClf.intercept_\nprint '  Model coefficients:'\nfor i in range(len(featureNames)):\n  print '    %g\\t%s' % (origClf.coef_[i], featureNames[i])","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Trained model with fixed alpha = 0.5\n  Model intercept: -57.6952\n  Model coefficients:\n    503932\tcarat\n    -668.814\tcut\n    -36580.6\tcolor\n    4104.09\tclarity\n    -887.179\tdepth\n    4074.86\ttable\n    178054\tx\n    176814\ty\n    175385\tz\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.43580641657E12,"submitTime":1.435806401895E12,"finishTime":1.435806416773E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"eb1c005a-5da7-4873-a6ce-8aad8be5547e"},{"version":"CommandV1","origId":2415,"guid":"5e506773-e3f7-447e-97bf-273947c2c7cc","subtype":"command","commandType":"auto","position":28.0,"command":"%md One can draw conclusions about the model coefficients and the affect of features.  However, be wary of several issues:\n* Feature meaning: Especially if you index or transform features, be careful about how those transformations can change the meaning.  E.g., reversing an index order or negating a numerical feature can \"flip\" the meaning.\n* Model assumptions: The model may not fit the data, in which case interpreting coefficients may be difficult.  E.g., if the data do not correspond to a linear model, the model may learn non-intuitive weights for some features (in its attempt to fit the data as well as possible).","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401903E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"46756aff-bcbd-43c0-8585-ca1c6ab64074"},{"version":"CommandV1","origId":2416,"guid":"f37191cc-156b-4f43-a5f0-fc12cad3d0ea","subtype":"command","commandType":"auto","position":29.0,"command":"%md ### Evaluate the initial model\n\nWe will evaluate this and other models using [scikit-learn's score function](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge.score), which computes a value indicating the quality of the model's predictions on data.  A value closer to `1` is better.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401913E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"c2d69f2a-277a-469d-955e-3781c38e3eef"},{"version":"CommandV1","origId":2417,"guid":"e9e70efc-b5c2-4dc9-8d52-3946e53303bd","subtype":"command","commandType":"auto","position":30.0,"command":"# Score the initial model.  It does not do that well.\norigScore = origClf.score(trainingFeatures, trainingLabels)\norigScore","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">15</span><span class=\"ansired\">]: </span>0.55967055924291742\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806416788E12,"submitTime":1.435806401921E12,"finishTime":1.435806416818E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"d770c97e-64f4-4e46-a57a-29d7364cf885"},{"version":"CommandV1","origId":2418,"guid":"74214b0a-d029-40fa-9b30-48444c7ea3e8","subtype":"command","commandType":"auto","position":31.0,"command":"%md ## 2. Distributing scikit-learn jobs\n\nNow that we have a basic scikit-learn workflow in DBC, we can start distributing tasks.  There are several types of tasks one might distribute, such as ETL, parameter tuning, and evaluation.  We demonstrate using Spark to distribute *parameter tuning* below.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401929E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"2480d1cd-c7d4-4db3-a11f-19b30fa4687c"},{"version":"CommandV1","origId":2419,"guid":"560c21e9-1802-4281-9728-f4d353843068","subtype":"command","commandType":"auto","position":32.0,"command":"%md ### Parameter tuning using Spark\n\n[Parameter tuning](http://en.wikipedia.org/wiki/Hyperparameter_optimization) is the task of tuning (hyper)parameters of a learning or prediction system in order to improve the results.  It is commonly done by training multiple models (each using different parameters) on one set of data and then testing those models on another held-out set of data (and maybe repeating).  By testing on a held-out set not seen during training, we can tune the parameters in a data-driven way while limiting the risk of [overfitting](http://en.wikipedia.org/wiki/Overfitting).\n\nIn this section, we will use [k-fold cross validation](http://en.wikipedia.org/wiki/Cross-validation_&#40;statistics&#41;), which works as follows:\n* Randomly split the data into k equal-sized subsets (\"folds\").\n* For ```i = 1, 2, ..., k```,\n  * Hold out fold ```i``` as a validation set.\n  * Create a training set by combining all folds except for ```i```.\n  * For each set of parameters,\n    * Train a model with that set of parameters.\n    * Test the model on the validation set to compute a validation error.\n* For each set of parameters,\n  * Compute the average validation error (averaging over the ```k``` models for this set of parameters).\n* Choose the best set of parameters, based on the average validation error.\n* Re-train on the entire dataset, using this best set of parameters.\n\nNote that for each (fold, parameter set) pair, the task of training a model can be done independently of other folds and parameter sets.  We will parallelize these tasks: scikit-learn will be used on each worker to do the training.  This parallelization is especially helpful since training is the most computationally costly part of this workflow.  If you use `k` folds of cross validation to test `P` different parameter settings, then distributing the task to train 1 model per worker can make it run close to `k*P` times faster!\n\nWe will also hold out some additional data for testing.  We will use it to demonstrate the worth of careful parameter tuning by comparing:\n* Our initial model (with poorly chosen parameters)\n* The final model (with carefully tuned parameters)","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401943E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"1a0a18da-1c50-4b82-843a-e8bfe365659a"},{"version":"CommandV1","origId":2420,"guid":"3446e3a9-c92c-4e3f-8bcd-267e84876c80","subtype":"command","commandType":"auto","position":33.0,"command":"%md #### Split data and define tasks to distribute\n\nEach distributed task will be a (fold, parameter set) pair.  It will correspond to 1 model we train.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401954E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"4e07b7df-3b9f-417d-98d0-6cbb704bfb57"},{"version":"CommandV1","origId":2421,"guid":"ffbf6c06-7b05-4142-b741-363fab09f3de","subtype":"command","commandType":"auto","position":34.0,"command":"# We use scikit-learn's cross_validation module, which helps split our data randomly into k equal-size parts (\"folds\").\nfrom sklearn import cross_validation\nnumFolds = 3 # You may want to use more (10 or so) in practice\nkf = cross_validation.KFold(ntrain, n_folds=numFolds)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806416838E12,"submitTime":1.435806401962E12,"finishTime":1.435806416913E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"49706401-5cb5-48c7-a05c-e917b7d210d0"},{"version":"CommandV1","origId":2422,"guid":"ca90bd78-790c-4d69-b388-cd5adf886d27","subtype":"command","commandType":"auto","position":35.0,"command":"# \"alphas\" is a list of hyperparameter values to test\nalphas = [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n# Create a list of tasks to distribute\ntasks = []\nfor alpha in alphas:\n  for fold in range(numFolds):\n    tasks = tasks + [(alpha, fold)]","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806416915E12,"submitTime":1.435806401971E12,"finishTime":1.435806416959E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"a950959a-aeca-4712-902f-f8c2cefa86d8"},{"version":"CommandV1","origId":2423,"guid":"59315971-b108-4e75-8164-7600000774f7","subtype":"command","commandType":"auto","position":36.0,"command":"# Create an RDD of tasks.  We set the number of partitions equal to the number of tasks to ensure maximum parallelism.\ntasksRDD = sc.parallelize(tasks, numSlices = len(tasks))","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806416961E12,"submitTime":1.435806401979E12,"finishTime":1.435806417004E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"b626c760-1cdb-4882-bc2a-1677f2942e60"},{"version":"CommandV1","origId":2424,"guid":"d0949542-ba9a-4113-906b-47de90608141","subtype":"command","commandType":"auto","position":37.0,"command":"%md #### Broadcast dataset\n\nIf we use a variable in a function (a \"closure\") run on each worker, Spark will automatically send the dataset to the workers.  This is fine for variables with small values, but for our dataset, we can send it to workers more efficiently by *broadcasting* it.  We now create a *broadcast variable* for our data, which we will use later when running tasks on workers.  For more info on broadcast variables, see the [Spark programming guide](https://spark.apache.org/docs/latest/programming-guide.html#broadcast-variables).","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806401988E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"675a116e-3501-4839-bb36-10bafaf4ba70"},{"version":"CommandV1","origId":2425,"guid":"78e582c5-76ad-4c98-8b0b-5f28d61fecbd","subtype":"command","commandType":"auto","position":38.0,"command":"trainingFeaturesBroadcast = sc.broadcast(trainingFeatures)\ntrainingLabelsBroadcast = sc.broadcast(trainingLabels)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806417012E12,"submitTime":1.435806401997E12,"finishTime":1.435806417137E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"784da997-b252-4d03-a15d-3bcf156475d0"},{"version":"CommandV1","origId":2426,"guid":"97665383-6c09-4ea2-be17-0b05384da5ba","subtype":"command","commandType":"auto","position":39.0,"command":"%md #### Run cross-validation in parallel\n\nWe define a function which will run on each worker.  This function takes 1 task (1 hyperparameter alpha value + 1 fold index) and trains the corresponding model.  We then use `RDD.map` to run these tasks in parallel.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402006E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"7f64cbb4-98f0-41ff-a216-9be4d1334f6a"},{"version":"CommandV1","origId":2427,"guid":"8ebd24af-b2c1-4b9d-90d0-c0b583084d73","subtype":"command","commandType":"auto","position":40.0,"command":"def trainOneModel(alpha, fold):\n  \"\"\"\n  Given 1 task (1 hyperparameter alpha value + 1 fold index), train the corresponding model.\n  Return: model, score on the fold's test data, task info.\n  \"\"\"\n  # Extract indices for this fold\n  trainIndex, valIndex = [], []\n  fold_ = 0 # index into folds 'kf'\n  for trainIndex_, valIndex_ in kf:\n    if fold_ == fold:\n      trainIndex, valIndex = trainIndex_, valIndex_\n      break\n    fold_ += 1\n  # Get training data from the broadcast variables\n  localTrainingFeatures = trainingFeaturesBroadcast.value\n  localTrainingLabels = trainingLabelsBroadcast.value\n  X_train, X_val = localTrainingFeatures[trainIndex], localTrainingFeatures[valIndex]\n  Y_train, Y_val = localTrainingLabels[trainIndex], localTrainingLabels[valIndex]\n  # Train the model, and score it\n  clf = linear_model.Ridge(alpha=alpha)\n  clf.fit(X_train, Y_train)\n  score = clf.score(X_val, Y_val)\n  return clf, score, alpha, fold","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806417152E12,"submitTime":1.435806402016E12,"finishTime":1.43580641723E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"df50e515-5079-49cb-a737-f8a6823c0ee3"},{"version":"CommandV1","origId":2428,"guid":"22ca6767-8336-40d8-82ad-97cbdf6248d8","subtype":"command","commandType":"auto","position":41.0,"command":"# LEARN!  We now map our tasks RDD and apply the training function to each task.\n# After we call an action (\"count\") on the results, the actual training is executed.\ntrainedModelAndScores = tasksRDD.map(lambda alpha_fold: trainOneModel(alpha_fold[0], alpha_fold[1]))\ntrainedModelAndScores.cache()\ntrainedModelAndScores.count()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">21</span><span class=\"ansired\">]: </span>27\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806417232E12,"submitTime":1.435806402025E12,"finishTime":1.435806419147E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"c2d46ea2-2b9e-4cb6-8ebf-e487b534d0b8"},{"version":"CommandV1","origId":2429,"guid":"ae19a783-4e78-41a5-9ade-bf3fbcb98664","subtype":"command","commandType":"auto","position":42.0,"command":"# Since we are done with our broadcast variables, we can clean them up.\n# (This will happen automatically, but we can make it happen earlier by explicitly unpersisting the broadcast variables.\ntrainingFeaturesBroadcast.unpersist()\ntrainingLabelsBroadcast.unpersist()","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.43580641915E12,"submitTime":1.435806402037E12,"finishTime":1.43580641917E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"2366b64b-d970-4b30-8d4a-faa9449d5736"},{"version":"CommandV1","origId":2430,"guid":"cf5190d1-5459-4d50-9e68-6a7700d10150","subtype":"command","commandType":"auto","position":43.0,"command":"%md #### Collect results to get the best hyperparameter alpha","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402047E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"d761dac4-277f-4fa6-b3bd-0c414c438e8e"},{"version":"CommandV1","origId":2431,"guid":"d2dbcba9-10b6-4b05-9d95-c7c03d906a0a","subtype":"command","commandType":"auto","position":44.0,"command":"# Collect the results.\nallScores = trainedModelAndScores.map(lambda x: (x[1], x[2], x[3])).collect()\n# Average scores over folds\navgScores = dict(map(lambda alpha: (alpha, 0.0), alphas))\nfor score, alpha, fold in allScores:\n  avgScores[alpha] += score\nfor alpha in alphas:\n  avgScores[alpha] /= numFolds\navgScores","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">23</span><span class=\"ansired\">]: </span>\n{0.0: 0.89471235725055409,\n 0.0001: 0.89445787236435503,\n 0.001: 0.89237909912422708,\n 0.01: 0.87932474711566611,\n 0.1: 0.73180437372159002,\n 1.0: 0.22941084822704316,\n 10.0: 0.028488579031199206,\n 100.0: 0.0027218910086152701,\n 1000.0: 7.3408586526343037e-05}\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806419179E12,"submitTime":1.435806402055E12,"finishTime":1.435806419304E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"82426765-9312-434e-8849-e260788204ee"},{"version":"CommandV1","origId":2432,"guid":"3ce617cc-bfdc-4b43-a8da-38d3f665fb0b","subtype":"command","commandType":"auto","position":45.0,"command":"%md We now have a list of alpha values paired with the corresponding average scores (averaged over the k folds).  Let's identify the best score to discover the best value for alpha.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402067E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"e98b2e9d-02ec-4504-8c7b-c80163e7d1ca"},{"version":"CommandV1","origId":2433,"guid":"5b46a8d6-b9ae-41c4-91c6-73ad26dd9899","subtype":"command","commandType":"auto","position":46.0,"command":"# Find best score\nbestAlpha = -1\nbestScore = -1\nfor alpha in alphas:\n  if avgScores[alpha] > bestScore:\n    bestAlpha = alpha\n    bestScore = avgScores[alpha]\nprint 'Found best alpha: %g, which gives score: %g' % (bestAlpha, bestScore)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Found best alpha: 0, which gives score: 0.894712\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806419313E12,"submitTime":1.435806402077E12,"finishTime":1.43580641934E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"a431bfb5-0d2a-4932-a114-0e3ec714a6a3"},{"version":"CommandV1","origId":2434,"guid":"5958aa17-29ed-4c78-a9a3-12c45abdf9e0","subtype":"command","commandType":"auto","position":47.0,"command":"%md We can also use plotting to examine how the hyperparameter affects performance.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402086E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"294319d4-19af-44db-8674-8a39dba9f7e5"},{"version":"CommandV1","origId":2435,"guid":"4665b593-fede-4da0-965a-dd66129a160c","subtype":"command","commandType":"auto","position":48.0,"command":"# Use DBC's display() function to plot the scores vs. alpha.  We use a namedtuple to tell DBC names for the columns (alpha and the score).\nimport numpy\nfrom collections import namedtuple\nScore = namedtuple('Score', 'log_alpha score')\ndisplay(map(lambda alpha: Score(float(numpy.log(alpha + 0.00000001)), float(avgScores[alpha])), avgScores))","commandVersion":1,"state":"finished","results":{"type":"table","data":[[-18.420680743952367,0.8947123572505541],[9.999999889225291E-9,0.22941084822704316],[4.605170186088091,0.00272189100861527],[-2.3025849929940505,0.73180437372159],[6.907755278992137,7.340858652634304E-5],[2.302585093994046,0.028488579031199206],[-6.907745279032137,0.8923790991242271],[-9.21024037697585,0.894457872364355],[-4.605169185988592,0.8793247471156661]],"arguments":{},"schema":[{"type":"double","name":"log_alpha"},{"type":"double","name":"score"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.435806419349E12,"submitTime":1.435806402094E12,"finishTime":1.435806419915E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"49fc3535-24a5-4385-9d45-49556f31398a"},{"version":"CommandV1","origId":2436,"guid":"fed1bfff-28bb-4dc1-8531-4deadd178e5f","subtype":"command","commandType":"auto","position":49.0,"command":"%md For this dataset, the best alpha is generally small but not the smallest value.  (Remember that the results of this notebook can vary because of randomness in splitting the data.)\n\nThis demonstrates how parameter tuning can help *a lot*; our score can vary from 0 (terrible) to 0.9 (quite good).","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402102E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"0a79b591-6eb9-4508-816f-34805dbf0db0"},{"version":"CommandV1","origId":2437,"guid":"de3e15f7-33bc-40f0-86d1-0178430d81d1","subtype":"command","commandType":"auto","position":50.0,"command":"%md #### Train a final model using the best hyperparameter\n\nWe use our chosen value of alpha to train a model on the entire training dataset.  Since this is a single training task, we execute it on the driver.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402111E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"58a70bca-bb73-4ffa-b77e-71c37ef8226c"},{"version":"CommandV1","origId":2438,"guid":"6ed4e12f-a048-4f0e-aeb0-c2b09d0f3d48","subtype":"command","commandType":"auto","position":51.0,"command":"# Use bestAlpha, and train a final model.\ntunedClf = linear_model.Ridge(alpha=bestAlpha)\ntunedClf.fit(trainingFeatures, trainingLabels)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">26</span><span class=\"ansired\">]: </span>\nRidge(alpha=0.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, solver=&apos;auto&apos;, tol=0.001)\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806419934E12,"submitTime":1.435806402119E12,"finishTime":1.43580642001E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"162d8ba9-3184-4157-a423-222a6d012d5e"},{"version":"CommandV1","origId":2439,"guid":"c51190a4-30a6-4a01-9328-bf4d94d575f8","subtype":"command","commandType":"auto","position":52.0,"command":"%md Let's compare our original model vs. the final model with tuned hyperparameters.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402127E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"12cb02ba-49b0-4eb2-ae86-67f0662b2a0f"},{"version":"CommandV1","origId":2440,"guid":"c437f0ee-0753-4445-93f0-f03cc88562e9","subtype":"command","commandType":"auto","position":53.0,"command":"origTrainingScore, origTestScore = origClf.score(trainingFeatures, trainingLabels), origClf.score(testFeatures, testLabels)\ntunedTrainingScore, tunedTestScore = tunedClf.score(trainingFeatures, trainingLabels), tunedClf.score(testFeatures, testLabels)\nprint 'Compare original model (without hyperparameter tuning) and final model (with tuning) on test data\\n'\nprint 'Model   \\tAlpha\\tTraining   \\tTest'\nprint 'Original\\t%g\\t%g\\t%g' % (origAlpha, origTrainingScore, origTestScore)\nprint 'Tuned   \\t%g\\t%g\\t%g' % (bestAlpha, tunedTrainingScore, tunedTestScore)","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Compare original model (without hyperparameter tuning) and final model (with tuning) on test data\n\nModel   \tAlpha\tTraining   \tTest\nOriginal\t0.5\t0.559671\t0.557173\nTuned   \t0\t0.895544\t0.879091\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.43580642002E12,"submitTime":1.435806402135E12,"finishTime":1.435806420064E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"fcbbb733-1815-4679-a3b0-8ff7a26eef49"},{"version":"CommandV1","origId":2441,"guid":"09c97ceb-1556-4d28-ba45-7fa47bd6dd39","subtype":"command","commandType":"auto","position":54.0,"command":"%md The tuned model does better! (Note: Performance can vary because of randomness, but it should be better.)","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402143E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"b2613819-d19f-470c-93fa-01e53f2418b2"},{"version":"CommandV1","origId":2442,"guid":"352da49a-5d80-4694-b224-8c10aa4e8ea6","subtype":"command","commandType":"auto","position":55.0,"command":"print 'Tuned model with best alpha = %g' % bestAlpha\nprint '  Model intercept: %g' % tunedClf.intercept_\nprint '  Model coefficients:'\nfor i in range(len(featureNames)):\n  print '    %g\\t%s' % (tunedClf.coef_[i], featureNames[i])","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Tuned model with best alpha = 0\n  Model intercept: 5110.19\n  Model coefficients:\n    2.30528e+06\tcarat\n    101428\tcut\n    254332\tcolor\n    296920\tclarity\n    -1.21567e+06\tdepth\n    -372504\ttable\n    -2.70834e+06\tx\n    1.46028e+06\ty\n    -22601.6\tz\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806420072E12,"submitTime":1.435806402152E12,"finishTime":1.435806420147E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"9758ca71-3ecf-4b23-9a1c-e03dcf91861e"},{"version":"CommandV1","origId":2443,"guid":"f9f1d90b-bda7-4971-903c-44270792e720","subtype":"command","commandType":"auto","position":56.0,"command":"%md ## 3. Converting between scikit-learn and MLlib models\n\nIt is often possible to convert between scikit-learn and MLlib models.  There is not built-in functionality yet, but we show how to do the conversion for linear models.  This can be useful to take advantage of each library's different sets of functionality.","commandVersion":1,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.435806402162E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"83c20fa4-30d5-4303-a7a9-bdb454a5c409"},{"version":"CommandV1","origId":2444,"guid":"8c6e4887-1630-4a80-806b-3ff0386c9bcc","subtype":"command","commandType":"auto","position":57.0,"command":"# Convert the scikit-learn model into an equivalent MLlib model\nfrom pyspark.mllib.regression import LinearRegressionModel\nmllibModel = LinearRegressionModel(tunedClf.coef_, tunedClf.intercept_)\nmllibModel","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">29</span><span class=\"ansired\">]: </span>(weights=[2305280.96163,101428.48903,254331.830024,296920.257461,-1215671.65231,-372504.205117,-2708338.17271,1460280.82116,-22601.5856309], intercept=5110.185649283759)\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806420156E12,"submitTime":1.43580640217E12,"finishTime":1.435806420236E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"dd05a29b-ea88-4d56-8de4-a701880d7049"},{"version":"CommandV1","origId":2445,"guid":"1f3666b8-b1d0-405c-94de-c4382f6c1e1b","subtype":"command","commandType":"auto","position":58.0,"command":"# Demonstrate that the models compute the same predictions\nsklearnPredictions = tunedClf.predict(testFeatures)\nmllibPredictions = numpy.array(map(lambda x: mllibModel.predict(x), testFeatures))\ndifferences = sklearnPredictions - mllibPredictions\nsumSquaredDifferences = sum(differences * differences)\nprint 'Total difference between scikit-learn and MLlib model predictions: %g' % sumSquaredDifferences","commandVersion":1,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Total difference between scikit-learn and MLlib model predictions: 0\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.435806420239E12,"submitTime":1.435806402178E12,"finishTime":1.435806420464E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"dbadmin","iPythonMetadata":null,"nuid":"d677e57c-56f3-4b9e-beb2-1838ba1d071f"}],"guid":"e3e50659-7ce4-4a93-91d0-607dac777c20","globalVars":{},"iPythonMetadata":null};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":-1,"guid":"569e8425-1da6-48b2-bd48-30d44f494414","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](../../index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>