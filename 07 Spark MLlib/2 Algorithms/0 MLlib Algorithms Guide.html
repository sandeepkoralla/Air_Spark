<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Spark MLlib / Algorithms / MLlib Algorithms Guide - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/img/favicon.ico"/>
<script>window.settings = {"sparkDocsSearchGoogleCx":"004588677886978090460:_rj0wilqwdm","dbcForumURL":"http://forums.databricks.com/","dbfsS3Host":"https://databricks-prod-storage-oregon.s3.amazonaws.com","enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"isAdmin":false,"enablePresentationTimerConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"clusters":false,"hideOffHeapCache":false,"applications":false,"useStaticGuide":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"sparkVersions":[{"key":"1.3.x","displayName":"Spark 1.3.0","packageLabel":"spark-1.3-jenkins-ip-10-2-0-138-U094163cf51-S47b89c350f-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.4.x","displayName":"Spark 1.4.1","packageLabel":"spark-1.4-jenkins-ip-10-2-0-138-U094163cf51-S2f95f6c227-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x","displayName":"Spark 1.6 Branch Preview","packageLabel":"spark-1.6-jenkins-ip-10-2-0-138-U094163cf51-S3436f2ea50-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.8.1","local":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":false,"enableStaticNotebooks":true,"dbcGuideURL":"#workspace/databricks_guide/00 Welcome to Databricks","enableClusterAclsConfig":false,"orgId":0,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":false,"driverLog4jFilePrefix":"log4j","enableMavenLibraries":true,"defaultSparkVersion":{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},"clusterPublisherRootId":5,"enableLatestJobRunResultPermalink":true,"enableSparkConfUI":true,"enableJdbcImport":true,"logfiles":"logfiles/","enableClusterDeltaUpdates":true,"csrfToken":"d3dde7ae-fd45-4989-86b8-e91415a5ebcf","useFixedStaticNotebookVersionForDevelopment":false,"enableBasicReactDialogBoxes":true,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableWorkspaceAclService":true,"enableWorkspaceAcls":true,"gitHash":"094163cf51fcd4717c3ea96799d1008723ae8985","userFullname":"Suresh Jayaram","enableImportFromUrl":true,"enableMiniClusters":false,"enableWebSocketDeltaUpdates":true,"enableDebugUI":false,"showHiddenSparkVersions":false,"allowNonAdminUsers":true,"userId":100017,"dbcSupportURL":"","staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/","enableSparkPackages":true,"enableNotebookHistoryUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"databricksGuideStaticUrl":"","notebookLoadingBackground":"#fff","enableNewJobRunDetailsPage":true,"enableDashboardExport":true,"user":"surjayaram@paypal.com","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"tablesPublisherRootId":7,"accounts":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":2615,"name":"Spark MLlib / Algorithms / MLlib Algorithms Guide","language":"python","commands":[{"version":"CommandV1","origId":2616,"guid":"ce2ec09a-31f3-4f9f-ac16-88c1a0138b16","subtype":"command","commandType":"auto","position":1.0,"command":"%md # Machine Learning Library Algorithms Guide","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427834313812E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"59ba70e6-39ef-4995-9da2-df318565d641"},{"version":"CommandV1","origId":2617,"guid":"87fe2b3f-f889-46aa-bcf5-1993df589799","subtype":"command","commandType":"auto","position":1.25,"command":"%md\n\n### Databricks Notebook Examples\n* [Binary Classification Algorithms](../../07 Spark MLlib/2 Algorithms/3 Binary Classification Algorithms.html)\n* [Logistic Regression](../../07 Spark MLlib/2 Algorithms/1 Logistic Regression.html)\n* [Naive Bayes](../../07 Spark MLlib/2 Algorithms/2 Naive Bayes.html)\n* [LDA Topic Modeling](../../07 Spark MLlib/2 Algorithms/4 LDA - Topic Modeling.html)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"9a0b52c4-2bf1-40ba-a131-9f2b60d86971"},{"version":"CommandV1","origId":2618,"guid":"cd1f8535-d809-410f-ad8b-9e37f78861d4","subtype":"command","commandType":"auto","position":1.5,"command":"%md\n\n### Overview\n\n**Categories of MLlib algorithms** (with links to the Spark Programming Guide):\n* [Classification](http://spark.apache.org/docs/latest/mllib-classification-regression.html) *(also see [Wikipedia](http://en.wikipedia.org/wiki/Statistical_classification))*\n* [Regression](http://spark.apache.org/docs/latest/mllib-classification-regression.html) *(also see [Wikipedia](http://en.wikipedia.org/wiki/Regression_analysis)*\n* [Recommendation (collaborative filtering)](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) *(also see [Wikipedia](http://en.wikipedia.org/wiki/Recommender_system))*\n* [Clustering](http://spark.apache.org/docs/latest/mllib-clustering.html) *(also see [Wikipedia](http://en.wikipedia.org/wiki/Cluster_analysis))*\n* [Feature extraction and transformation](http://spark.apache.org/docs/latest/mllib-feature-extraction.html) *(also see [Wikipedia](http://en.wikipedia.org/wiki/Feature_extraction))*\n* [Dimensionality reduction](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html) *(also see [Wikipedia](http://en.wikipedia.org/wiki/Dimensionality_reduction))*\n* [Frequent pattern mining (association rule learning)](http://spark.apache.org/docs/latest/mllib-frequent-pattern-mining.html) *(also see [Wikipedia](http://en.wikipedia.org/wiki/Association_rule_learning))*\n* [Statistics](http://spark.apache.org/docs/latest/mllib-statistics.html)\n\nBelow, for each algorithm, we provide links for references:\n* Notebook Example (if available)\n* Python & Scala API\n* MLlib Programming Guide\n* Wikipedia","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"b3fec7b0-26fd-4f14-a668-ed43ba1aa723"},{"version":"CommandV1","origId":2619,"guid":"16951b6a-d374-42cb-b9b1-db8b445760b1","subtype":"command","commandType":"auto","position":2.0,"command":"%md ## Classification and Regression\n\nClassification and Regression are two major prediction tasks, where we want to predict a *label* from a *feature vector*.\n* In Classification, the label is categorical (e.g., states of the US).\n* In Regression, the label is real-valued (e.g., inches of rainfall).\n\nClassification and regression algorithms are generally run using one of two optimization algorithms: [Stochastic Gradient Descent (SGD)](http://en.wikipedia.org/wiki/Stochastic_gradient_descent) or [Limited-Memory BFGS (LBFGS)](http://en.wikipedia.org/wiki/Limited-memory_BFGS).  Algorithm names sometimes have a suffix *WithSGD* or *WithLBFGS* to denote this.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427822842149E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"c741c5dd-7ed1-46a1-bb34-a631c5d75b1b"},{"version":"CommandV1","origId":2620,"guid":"1d6f2db3-7f2c-4e8c-a600-b049cb8e1475","subtype":"command","commandType":"auto","position":2.25,"command":"%md ### Classification\n\n[**Binary Classification Algorithms Notebook Example**](../../07 Spark MLlib/2 Algorithms/3 Binary Classification Algorithms.html)\n\nClassification algorithms (with links to the Spark Programming Guide):\n* [Linear models](http://spark.apache.org/docs/latest/mllib-linear-methods.html)\n  * Logistic regression\n  * Linear Support Vector Machines (SVMs)\n* [Naive Bayes](http://spark.apache.org/docs/latest/mllib-naive-bayes.html)\n* [Decision trees](http://spark.apache.org/docs/latest/mllib-decision-tree.html)\n* [Ensembles of trees](http://spark.apache.org/docs/latest/mllib-ensembles.html) (Random Forests and Gradient-Boosted Trees)\n\nNote that SVMs and Gradient-Boosted Trees only support binary (0/1) labels currently.  The other algorithms support multiclass labels.\n\nAPI references for classification package:\n* [Python](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#module-pyspark.mllib.classification)\n* [Scala](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.package)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427833106083E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"8a24a5c2-2ace-4259-a89f-d1372566bc97"},{"version":"CommandV1","origId":2621,"guid":"be6112ad-72fa-473a-ba58-286ae31ece96","subtype":"command","commandType":"auto","position":2.296875,"command":"%md #### **Logistic Regression**\n**Task**: classification with binary or multiclass labels, using continuous features\n\n[**Logistic Regression Notebook Example**](../../07 Spark MLlib/2 Algorithms/1 Logistic Regression.html)\n\n**Documentation**\n* API\n  * Python: [LogisticRegressionWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithSGD), [LogisticRegressionWithLBFGS](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithLBFGS), [LogisticRegressionModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionModel)\n  * Scala: [LogisticRegressionWithSGD](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.LogisticRegressionWithSGD), [LogisticRegressionWithLBFGS](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS), [LogisticRegressionModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.LogisticRegressionModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression)\n\n**Other resources**\n* [Wikipedia: Logistic regression](http://en.wikipedia.org/wiki/Logistic_regression)\n* Example datasets: LIBSVM datasets for [binary classification](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) and [multiclass classification](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.433995480607E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"369ee21b-205b-435b-ba1d-2e6e62b32f3a"},{"version":"CommandV1","origId":2622,"guid":"ca07703d-5511-4c7d-a037-7e07bf17386a","subtype":"command","commandType":"auto","position":2.31640625,"command":"%md #### **Linear Support Vector Machines (SVMs)**\n**Task**: classification with binary labels, using continuous features\n\n**Documentation**\n* API\n  * Python: [SVMWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.SVMWithSGD), [SVMModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.SVMModel)\n  * Scala: [SVMWithSGD](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.SVMWithSGD), [SVMModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.SVMModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-linear-methods.html#linear-support-vector-machines-svms)\n\n**Other resources**\n* [Wikipedia: Support vector machine](http://en.wikipedia.org/wiki/Support_vector_machine)\n* [A Practical Guide to Support Vector Classification](http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf)\n* Example datasets: [LIBSVM datasets](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427833204265E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"d964a5f9-7d2a-4305-b47f-4d2cd3eb4ef6"},{"version":"CommandV1","origId":2623,"guid":"73d8c178-94e3-49c2-943f-50226ee7b583","subtype":"command","commandType":"auto","position":2.3359375,"command":"%md #### **Naive Bayes**\n**Task**: classification with binary or multiclass labels, using categorical features\n\n[**Naive Bayes Notebook Example**](../../07 Spark MLlib/2 Algorithms/2 Naive Bayes.html)\n\n**Documentation**\n* API\n  * Python: [NaiveBayes](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.NaiveBayes), [NaiveBayesModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.NaiveBayesModel)\n  * Scala: [NaiveBayes](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.NaiveBayes), [NaiveBayesModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.NaiveBayesModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-naive-bayes.html)\n\n**Other resources**\n* [Wikipedia: Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n* Example datasets: LIBSVM datasets for [binary classification](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) and [multiclass classification](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427823781848E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"3e706812-6bc8-4d66-a434-7d9f60de7eeb"},{"version":"CommandV1","origId":2624,"guid":"f6e035b2-bc78-4843-bfe4-f28509c44b01","subtype":"command","commandType":"auto","position":2.35546875,"command":"%md #### **Decision Tree**\n**Task**: regression or classification with binary or multiclass labels, using continuous and/or categorical features\n\n**Documentation**\n* API\n  * Python: [DecisionTree](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.DecisionTree), [DecisionTreeModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.DecisionTreeModel)\n  * Scala: [DecisionTree](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree), [DecisionTreeModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.DecisionTreeModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-decision-tree.html)\n\n**Other resources**\n* [Wikipedia: Decision tree](http://en.wikipedia.org/wiki/Decision_tree_learning)\n* Example datasets: [LIBSVM datasets](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets) for classification and regression","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427824145704E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"27e27c85-4442-468b-aaa0-f2299ec997d0"},{"version":"CommandV1","origId":2625,"guid":"0ec850d1-3114-4a08-b904-3a3f4f52a863","subtype":"command","commandType":"auto","position":2.365234375,"command":"%md #### **Random Forest**\n**Task**: regression or classification with binary or multiclass labels, using continuous and/or categorical features\n\n**Documentation**\n* API\n  * Python: [RandomForest](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.RandomForest), [RandomForestModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.RandomForestModel)\n  * Scala: [RandomForest](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.RandomForest$), [RandomForestModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.RandomForestModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-ensembles.html)\n\n**Other resources**\n* [Wikipedia: Random forest](http://en.wikipedia.org/wiki/Random_forest)\n* Example datasets: [LIBSVM datasets](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets) for classification and regression","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.428085394006E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"joseph","iPythonMetadata":null,"nuid":"3cbe782c-dda9-49f4-94a1-da3cc5ecd9ea"},{"version":"CommandV1","origId":2626,"guid":"292cd769-60af-49a2-9c81-0d7fbc587310","subtype":"command","commandType":"auto","position":2.3701171875,"command":"%md #### **Gradient-Boosted Decision Trees**\n**Task**: regression or classification with binary labels, using continuous and/or categorical features\n\n**Documentation**\n* API\n  * Python: [GradientBoostedTrees](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.GradientBoostedTrees), [GradientBoostedTreesModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.GradientBoostedTreesModel)\n  * Scala: [GradientBoostedTrees](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.GradientBoostedTrees), [GradientBoostedTreesModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.tree.model.GradientBoostedTreesModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-ensembles.html)\n\n**Other resources**\n* [Wikipedia: Gradient boosting](http://en.wikipedia.org/wiki/Gradient_boosting)\n* Example datasets: LIBSVM datasets for [binary classification](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) and [regression](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427824266509E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"joseph","iPythonMetadata":null,"nuid":"c96fd4d0-acce-4449-862f-82af03bacf6b"},{"version":"CommandV1","origId":2627,"guid":"f66d00b8-d121-4c43-a960-bceaa26fe9a5","subtype":"command","commandType":"auto","position":2.375,"command":"%md ### Regression\n\nRegression algorithms (with links to the Spark Programming Guide):\n* [Linear models](http://spark.apache.org/docs/latest/mllib-linear-methods.html)\n  * Linear regression (including Ridge Regression and Lasso)\n* [Decision trees](http://spark.apache.org/docs/latest/mllib-decision-tree.html)\n* [Ensembles of trees](http://spark.apache.org/docs/latest/mllib-ensembles.html) (Random Forests and Gradient-Boosted Trees)\n* [Isotonic regression](http://spark.apache.org/docs/latest/mllib-isotonic-regression.html)\n\nAPI references for regression package:\n* [Python](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#module-pyspark.mllib.regression)\n* [Scala](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.package)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427824379023E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"8dbed2dc-639e-4534-9612-9485b8b6881d"},{"version":"CommandV1","origId":2628,"guid":"a1c75313-b71f-44ee-8e3f-75382a771de1","subtype":"command","commandType":"auto","position":2.4375,"command":"%md #### **Linear Regression, Ridge Regression, and Lasso**\n**Task**: regression using continuous features\n\n**Documentation**\n* API\n  * Linear Regression (no regularization)\n    * Python: [LinearRegressionWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD), [LinearRegressionModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel)\n    * Scala: [LinearRegressionWithSGD](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.LinearRegressionWithSGD), [LinearRegressionModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.LinearRegressionModel)\n  * Ridge Regression (L2 regularization)\n    * Python: [RidgeRegressionWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.RidgeRegressionWithSGD), [RidgeRegressionModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.RidgeRegressionModel)\n    * Scala: [RidgeRegressionWithSGD](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.RidgeRegressionWithSGD), [RidgeRegressionModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.RidgeRegressionModel)\n  * Lasso (L1 regularization)\n    * Python: [LassoWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LassoWithSGD), [LassoModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LassoModel)\n    * Scala: [LassoWithSGD](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.LassoWithSGD), [LassoModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.LassoModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-linear-methods.html#regression)\n\n**Other resources**\n* Wikipedia\n  * [Linear regression](http://en.wikipedia.org/wiki/Simple_linear_regression) (a.k.a. [Ordinary least squares](http://en.wikipedia.org/wiki/Ordinary_least_squares) or [Linear least squares](http://en.wikipedia.org/wiki/Linear_least_squares_&#40;mathematics&#41;)\n  * [Ridge regression (a.k.a. L2-regularized regression, or Tikhonov regularization)](http://en.wikipedia.org/wiki/Tikhonov_regularization)\n  * [Lasso (a.k.a. L1-regularized regression)](http://en.wikipedia.org/wiki/Least_squares#Lasso_method)\n* Example datasets: [LIBSVM datasets for regression](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.428085516478E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"joseph","iPythonMetadata":null,"nuid":"633f6a34-fd59-4f4d-8969-6bd885743adc"},{"version":"CommandV1","origId":2629,"guid":"ad11aec1-6036-421b-84c0-68883f2360d4","subtype":"command","commandType":"auto","position":2.4453125,"command":"%md #### **Decision Trees and Ensembles of Trees (Random Forests and Gradient-Boosted Trees) **\n\n*See sections above under Classification.*  (These models are applicable to both classification and regression.)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427827784736E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"c8f5ea7d-f39c-472f-b0ca-5289c3f1d6f6"},{"version":"CommandV1","origId":2630,"guid":"f3a1ddc4-7764-40b7-8b1e-c7818c1f8d8e","subtype":"command","commandType":"auto","position":2.453125,"command":"%md #### **Isotonic Regression**\n**Task**: regression using one continuous feature (This is a specialized algorithm useful for calibrating outputs of other regression algorithms.)\n\n**Documentation**\n* API\n  * *No Python API yet*\n  * Scala: [IsotonicRegression](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.IsotonicRegression), [IsotonicRegressionModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.regression.IsotonicRegressionModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-isotonic-regression.html)\n\n**Other resources**\n* [Wikipedia: Isotonic regression](http://en.wikipedia.org/wiki/Isotonic_regression)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.428085582608E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"joseph","iPythonMetadata":null,"nuid":"99701152-8b11-42a1-a93d-6c983a5163dc"},{"version":"CommandV1","origId":2631,"guid":"9ac0f778-6c6d-4cc7-a9f5-2f61daf0e993","subtype":"command","commandType":"auto","position":2.5,"command":"%md ## Recommendation (Collaborative Filtering)\n\nRecommendation, also known as Collaborative Filtering, is the task of recommending *products* or *items* to *users*.  Given a set of *ratings* which users have given to some products, one can predict the rating each user would give to each product.\n\nIn MLlib, recommendation is supported via Alternating Least Squares (ALS), a *matrix completion* algorithm which can fill in missing ratings in a user x product matrix.\n\nWikipedia:\n* [Collaborative filtering](http://en.wikipedia.org/wiki/Collaborative_filtering)\n* [Recommender systems](http://en.wikipedia.org/wiki/Recommender_system)\n\nAPI for `Rating` type:\n* [Python API](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.Rating)\n* [Scala API](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.Rating)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427828977943E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"8cd88249-31c3-4786-bd55-bf86bfc90cdd"},{"version":"CommandV1","origId":2632,"guid":"e8c9975e-2e79-4b50-9777-be66c5ba0823","subtype":"command","commandType":"auto","position":2.625,"command":"%md #### **Alternating Least Squares (ALS)**\n**Task**: recommendation\n\n**Documentation**\n* API\n  * Python: [ALS](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS), [MatrixFactorizationModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel)\n  * Scala: [ALS](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.ALS), [MatrixFactorizationModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.MatrixFactorizationModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)\n\n**Other resources**\n* [Paper: Koren et al. \"Matrix Factorization Techniques for Recommender Systems.\" Computer 42(8): pages 30--37, 2009](http://dl.acm.org/citation.cfm?id=1608614)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427829168657E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"c4b744c6-8b9b-476e-9126-d725da13de1a"},{"version":"CommandV1","origId":2633,"guid":"b4ba2385-1854-4075-bdd0-23b0e62ecd8e","subtype":"command","commandType":"auto","position":2.75,"command":"%md ## Clustering\n\nClustering is the task of taking feature vectors and grouping them into clusters.  It is a form of *unsupervised learning*, where the goal is to find structure in a dataset without labels or supervision.  There are several clustering algorithms supported, several of which have specialized use cases.\n\nClustering algorithms (with links to the [Spark Programming Guide](http://spark.apache.org/docs/latest/mllib-clustering.html)):\n* [K-means](http://spark.apache.org/docs/latest/mllib-clustering.html#k-means)\n  * [Streaming K-means](http://spark.apache.org/docs/latest/mllib-clustering.html#streaming-k-means)\n* [Gaussian Mixture](http://spark.apache.org/docs/latest/mllib-clustering.html#gaussian-mixture)\n* [Power Iteration Clustering (PIC)](http://spark.apache.org/docs/latest/mllib-clustering.html#power-iteration-clustering-pic)\n* [Latent Dirichlet Allocation (LDA)](http://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda)\n\nAPI references for clustering package:\n* [Python](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#module-pyspark.mllib.clustering)\n* [Scala](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.package)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427833244023E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"2d62510c-2a2c-4d10-8f11-4df21da91294"},{"version":"CommandV1","origId":2634,"guid":"827d268d-25ea-45ea-af7d-2e9c64a7dcf7","subtype":"command","commandType":"auto","position":2.8125,"command":"%md #### **K-means**\n**Task**: clustering with continuous features\n\n**Documentation**\n* API\n  * Python: [KMeans](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.clustering.KMeans), [KMeansModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.clustering.KMeansModel)\n  * Scala: [KMeans](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.KMeans), [KMeansModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.KMeansModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-clustering.html#k-means)\n\n**Other resources**\n* [Wikipedia](http://en.wikipedia.org/wiki/K-means_clustering)\n\n#### **Streaming K-means**\n**Task**: clustering with continuous features, in the streaming (online) setting\n\n**Documentation**\n* API\n  * *(no Python API yet)*\n  * Scala: [StreamingKMeans](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.StreamingKMeans), [StreamingKMeansModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.StreamingKMeansModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-clustering.html#streaming-k-means)\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427833352506E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"2452e572-c773-4766-84ec-cb13b2f6be73"},{"version":"CommandV1","origId":2635,"guid":"157909fc-87a0-4ede-9daf-44e50539dd68","subtype":"command","commandType":"auto","position":2.84375,"command":"%md #### **Gaussian Mixture**\n**Task**: clustering with continuous features\n\n**Documentation**\n* API\n  * Python: [GaussianMixture](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.clustering.GaussianMixture), [GaussianMixtureModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.clustering.GaussianMixtureModel)\n  * Scala: [GaussianMixture](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.GaussianMixture), [GaussianMixtureModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.GaussianMixtureModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-clustering.html#gaussian-mixture)\n\n**Other resources**\n* [Wikipedia](http://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427832688209E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"e2665cee-d699-4d7a-8bbb-c0deee30ee3a"},{"version":"CommandV1","origId":2636,"guid":"7d4b4091-80ea-4ccd-bf52-8969e930bf06","subtype":"command","commandType":"auto","position":2.859375,"command":"%md #### **Power Iteration Clustering (PIC)**\n**Task**: clustering with continuous features\n\n**Documentation**\n* API\n  * *(no Python API yet)*\n  * Scala: [PowerIterationClustering](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.PowerIterationClustering), [PowerIterationClusteringModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.PowerIterationClusteringModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-clustering.html#power-iteration-clustering-pic)\n\n**Other resources**\n* [paper: Lin and Cohen. \"Power Iteration Clustering.\" ICML, 2010.](http://www.icml2010.org/papers/387.pdf)\n* PIC is related to spectral clustering: [Wikipedia on spectral clustering](http://en.wikipedia.org/wiki/Spectral_clustering)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427832893858E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"33f6333e-d905-4a8d-bf26-a434e55c854f"},{"version":"CommandV1","origId":2637,"guid":"4d5b30c4-b637-451c-b940-2eb73fbed17d","subtype":"command","commandType":"auto","position":2.8671875,"command":"%md #### **Latent Dirichlet Allocation (LDA)**\n\n**Task**: clustering text documents\n\n* [**LDA Topic Modeling Notebook Example**](../../07 Spark MLlib/2 Algorithms/4 LDA Topic Modeling.html)\n\n**Documentation**\n* API\n  * *(no Python API yet)*\n  * Scala: [LDA](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.LDA), [LDAModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.LDAModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda)\n\n**Other resources**\n* [Wikipedia](http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427832995097E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"ba65e64d-8614-49eb-a5a0-cb44d410b37b"},{"version":"CommandV1","origId":2638,"guid":"d2aa9cd3-8cc0-4fb5-aa10-cd7cd8054ad0","subtype":"command","commandType":"auto","position":2.87109375,"command":"%md ## Feature Extraction, Transformation, and Selection\n\nFeatures are a critical part of Machine Learning.  MLlib provides several algorithms for extracting, transforming, and selecting features:\n* Extraction for text data:\n  * TF-IDF (HashingTF and IDF)\n  * Word2Vec\n* Transformation for numerical feature vectors:\n  * StandardScaler\n  * Normalizer\n* Selection:\n  * ChiSqSelector (for labeled categorical data)\n\nSome of the above algorithms require training and produce corresponding models; others do not require training and can immediately transform data.\n\nResources:\n* [Spark Programming Guide](http://spark.apache.org/docs/latest/mllib-feature-extraction.html)\n* [Wikipedia on feature extraction](http://en.wikipedia.org/wiki/Feature_extraction)\n* [Wikipedia on feature selection](http://en.wikipedia.org/wiki/Feature_selection)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427835182279E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"dee7b1c3-db15-49a7-828e-4da662afe803"},{"version":"CommandV1","origId":2639,"guid":"dc5d8ee9-d528-4101-8318-5348c5dd3e16","subtype":"command","commandType":"auto","position":2.873046875,"command":"%md #### **TF-IDF (HashingTF and IDF)**\n**Task**: feature extraction from text data, using Term Frequency - Inverse Document Frequency transformations\n\nTF-IDF transformations are provided via 2 class: `HashingTF` and `IDF`.\n\n**Documentation**\n* API\n  * Python: [HashingTF](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.HashingTF), [IDF](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.IDF), [IDFModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.IDFModel)\n  * Scala: [HashingTF](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.HashingTF), [IDF](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.IDF), [IDFModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.IDFModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-feature-extraction.html#tf-idf)\n\n**Other resources**\n* [Wikipedia: TF-IDF](http://en.wikipedia.org/wiki/Tf%E2%80%93idf)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.42808577436E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"joseph","iPythonMetadata":null,"nuid":"cbdcbc72-2ae5-4c66-ba37-f439c6d38947"},{"version":"CommandV1","origId":2640,"guid":"c6fe299a-402f-4d34-a20e-c963b36a43bf","subtype":"command","commandType":"auto","position":2.8740234375,"command":"%md #### **Word2Vec**\n**Task**: feature extraction from text data\n\n**Documentation**\n* API\n  * Python: [Word2Vec](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.Word2Vec), [Word2VecModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.Word2VecModel)\n  * Scala: [Word2Vec](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.Word2Vec), [Word2VecModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.Word2VecModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec)\n\n**Other resources**\n* [paper: Mikolov et al. \"Efficient Estimation of Word Representations in Vector Space.\" Workshop at ICLR, 2013.](http://arxiv.org/pdf/1301.3781.pdf)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.42783514703E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"c9b28fea-ab4f-449c-8be9-59addde5497b"},{"version":"CommandV1","origId":2641,"guid":"99769a93-f28c-49c2-89cc-18b1a7551bea","subtype":"command","commandType":"auto","position":2.87451171875,"command":"%md #### **StandardScaler**\n**Task**: feature transformation for numerical feature vectors, operating per-feature (column)\n\n**Documentation**\n* API\n  * Python: [StandardScaler](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.StandardScaler), [StandardScalerModel](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.StandardScalerModel)\n  * Scala: [StandardScaler](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.StandardScaler), [StandardScalerModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.StandardScalerModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-feature-extraction.html#standardscaler)\n\n**Other resources**\n* Wikipedia: [Normalization](http://en.wikipedia.org/wiki/Normalization_&#40;statistics&#41;) using the \"standard score\"\n* Wikipedia: [Feature scaling via standardization](http://en.wikipedia.org/wiki/Feature_scaling#Standardization)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427835604931E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"c7bd6e91-0458-48c0-8750-c9e429c990a7"},{"version":"CommandV1","origId":2642,"guid":"811ebedc-37a9-4957-83ea-6ae03f15c3af","subtype":"command","commandType":"auto","position":2.874755859375,"command":"%md #### **Normalizer**\n**Task**: feature transformation for numerical feature vectors, operating per-instance (row)\n\n**Documentation**\n* API\n  * Python: [Normalizer](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.feature.Normalizer)\n  * Scala: [Normalizer](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.Normalizer)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-feature-extraction.html#normalizer)\n\n**Other resources**\n* Wikipedia: [Normalization](http://en.wikipedia.org/wiki/Normalization_&#40;statistics&#41;) using the \"standard score\"\n* Wikipedia: [Feature scaling via standardization](http://en.wikipedia.org/wiki/Feature_scaling#Standardization)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.42783559144E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"684d7fbf-5338-4ebe-82c8-5b97f08b2d3f"},{"version":"CommandV1","origId":2643,"guid":"73358f5d-c249-4610-9d93-1ee1b2250f90","subtype":"command","commandType":"auto","position":2.8748779296875,"command":"%md #### **ChiSqSelector**\n**Task**: feature selection for labeled categorical data\n\n**Documentation**\n* API\n  * *(no Python API yet)*\n  * Scala: [ChiSqSelector](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.ChiSqSelector), [ChiSqSelectorModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.ChiSqSelectorModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-feature-extraction.html#chisqselector)\n\n**Other resources**\n* [Wikipedia on Pearson's chi-squared test](http://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427835761676E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"fd412785-4b0f-415c-ae13-b51aefed0d1e"},{"version":"CommandV1","origId":2644,"guid":"63ac6962-9105-4aa8-a688-e9f4aa2cf0a5","subtype":"command","commandType":"auto","position":2.875,"command":"%md ## Dimensionality Reduction\n\nDimensionality reduction is a set of techniques for reducing high-dimensional feature vectors to lower-dimensional spaces.  Reducing a big feature vector (e.g., 1 million features) to a smaller vector (e.g., 100 features) can bring several benefits: reduced storage, more meaningful distances when comparing feature vectors, and faster learning when training models on these vectors.\n\nMLlib provides matrix decompositions for dimensionality reduction using the distributed matrix type `RowMatrix`:\n* Singular Value Decomposition (SVD)\n* Principal Component Analysis (PCA)\n\nResources:\n* [Spark Programming Guide](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html)\n* [Wikipedia](http://en.wikipedia.org/wiki/Dimensionality_reduction)\n\n**Documentation: RowMatrix**\n* API\n  * *(no Python API yet)*\n  * Scala: [RowMatrix](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.linalg.distributed.RowMatrix)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-data-types.html#rowmatrix)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427834214315E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"bd776b40-d470-414b-8151-1c7e086b694c"},{"version":"CommandV1","origId":2645,"guid":"75211a89-26cb-4c4a-a2d8-5f592834751b","subtype":"command","commandType":"auto","position":2.90625,"command":"%md #### **Singular Value Decomposition (SVD)**\n**Task**: matrix decomposition, dimensionality reduction\n\n**Documentation**\n* API: SVD is provided via the `RowMatrix` class. (See links above.)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html#singular-value-decomposition-svd)\n\n**Other resources**\n* [Wikipedia](http://en.wikipedia.org/wiki/Singular_value_decomposition)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427834247818E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"13bde6e7-3e92-4191-b9ed-ea85dcde7ff4"},{"version":"CommandV1","origId":2646,"guid":"37bb380c-0881-4324-a972-54099459c36b","subtype":"command","commandType":"auto","position":2.921875,"command":"%md #### **Principal Component Analysis (PCA)**\n**Task**: matrix decomposition, dimensionality reduction\n\n**Documentation: PCA**\n* API: PCA is provided via the `RowMatrix` class. (See links above.)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html#principal-component-analysis-pca)\n\n**Other resources**\n* [Wikipedia](http://en.wikipedia.org/wiki/Principal_component_analysis)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427834287018E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"2e0001ca-eba7-4945-976e-99232c13e0f6"},{"version":"CommandV1","origId":2647,"guid":"dda32017-77f3-4a1d-9b18-b498c415348e","subtype":"command","commandType":"auto","position":2.96875,"command":"%md ## Frequent Pattern Mining (Association Rule Learning)\n\nFrequent Pattern Mining refers to searching for frequent items, item sets, or other patterns within a dataset.  MLlib currently supports the FP-growth algorithm.\n\nResources:\n* [Spark Programming Guide](http://spark.apache.org/docs/latest/mllib-frequent-pattern-mining.html)\n* [Wikipedia on Association Rule Learning](http://en.wikipedia.org/wiki/Association_rule_learning)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427836460809E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"a83564e1-8eee-49be-a8f9-24d5c4916b2f"},{"version":"CommandV1","origId":2648,"guid":"717de1e9-6422-4778-ac42-26504203498a","subtype":"command","commandType":"auto","position":2.97265625,"command":"%md #### **FP-growth**\n**Task**: frequent pattern mining\n\n**Documentation**\n* API\n  * *(no Python API yet)*\n  * Scala: [FPGrowth](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.fpm.FPGrowth), [FPGrowthModel](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.fpm.FPGrowthModel)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-frequent-pattern-mining.html)\n\n**Other resources**\n* [paper: Han et al. \"Mining frequent patterns without candidate generation.\" SIGMOD '00 Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, pages 1--12.](http://dx.doi.org/10.1145/335191.335372)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427836467774E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"cc3b5042-4a6a-45e5-8999-c780679ec45d"},{"version":"CommandV1","origId":2649,"guid":"93370fd2-1f9c-4fa0-8d16-746dbe2bc60e","subtype":"command","commandType":"auto","position":2.984375,"command":"%md ## Statistics\n\nMLlib provides some basic statistical functionality.  This functionality is provided in several places:\n* `Statistics` class static methods (in `stat` module)\n  * Summary statistics\n  * Correlations\n  * Hypothesis testing\n* `RDD` methods\n  * Sampling\n  * Stratified sampling\n* `RandomRDDs` class static methods (in `random` module)\n  * Random data generation from various distributions\n\nAPI references for `stat` package:\n* [Python](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#module-pyspark.mllib.stat)\n* [Scala](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.stat.package)\n\nAPI references for `random` package:\n* [Python](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#module-pyspark.mllib.random)\n* [Scala](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.random.package)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427837097566E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"2535894d-ba7d-40ae-9c2b-17aeaf1b3bc4"},{"version":"CommandV1","origId":2650,"guid":"49bf6eb6-6152-4b38-bd89-f53c9eca6982","subtype":"command","commandType":"auto","position":3.984375,"command":"%md #### **Statistics**\n**Task**: summary statistics, correlations, hypothesis testing\n\n**Documentation**\n* API\n  * Python: [Statistics](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics)\n  * Scala: [Statistics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.stat.Statistics$)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-statistics.html)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427837212975E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"6a713120-5be6-4051-8f38-49033dfa8a69"},{"version":"CommandV1","origId":2651,"guid":"e5c57742-d3c5-4ba0-9a65-1e7b3c304ba1","subtype":"command","commandType":"auto","position":4.984375,"command":"%md #### **Sampling**\n**Task**: random sampling, stratified sampling\n\n**Documentation**\n* API\n  * Python: [RDD.sample](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sample), [RDD.sampleByKey](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sampleByKey)\n  * Scala: [RDD](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) *(See `sample` and `sampleByKey`.)*\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-statistics.html#stratified-sampling)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427837430347E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"071f6acf-0521-4000-b8cd-4ee19861c658"},{"version":"CommandV1","origId":2652,"guid":"5b88afce-c82e-41a5-b001-325d5517b433","subtype":"command","commandType":"auto","position":5.984375,"command":"%md #### **RandomRDDs**\n**Task**: random number generation from exponential, gamma, log-normal, normal, poisson, uniform distributions\n\n**Documentation**\n* API\n  * Python: [RandomRDDs](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.random.RandomRDDs)\n  * Scala: [RandomRDDs](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.random.RandomRDDs$)\n* [Programming Guide](http://spark.apache.org/docs/latest/mllib-statistics.html#random-data-generation)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.427837571514E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"fd5101ae-e2a5-45d7-ac88-967394fd2a52"}],"guid":"17e84cbd-d044-4554-aa15-fa6f970d18b3","globalVars":{},"iPythonMetadata":null};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":-1,"guid":"2980456a-34ea-491f-8b12-4274a955da80","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](../../index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>