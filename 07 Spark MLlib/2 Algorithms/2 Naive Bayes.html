<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Spark MLlib / Algorithms / Naive Bayes - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/img/favicon.ico"/>
<script>window.settings = {"sparkDocsSearchGoogleCx":"004588677886978090460:_rj0wilqwdm","dbcForumURL":"http://forums.databricks.com/","dbfsS3Host":"https://databricks-prod-storage-oregon.s3.amazonaws.com","enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"isAdmin":false,"enablePresentationTimerConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"clusters":false,"hideOffHeapCache":false,"applications":false,"useStaticGuide":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"sparkVersions":[{"key":"1.3.x","displayName":"Spark 1.3.0","packageLabel":"spark-1.3-jenkins-ip-10-2-0-138-U094163cf51-S47b89c350f-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.4.x","displayName":"Spark 1.4.1","packageLabel":"spark-1.4-jenkins-ip-10-2-0-138-U094163cf51-S2f95f6c227-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x","displayName":"Spark 1.6 Branch Preview","packageLabel":"spark-1.6-jenkins-ip-10-2-0-138-U094163cf51-S3436f2ea50-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.8.1","local":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":false,"enableStaticNotebooks":true,"dbcGuideURL":"#workspace/databricks_guide/00 Welcome to Databricks","enableClusterAclsConfig":false,"orgId":0,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":false,"driverLog4jFilePrefix":"log4j","enableMavenLibraries":true,"defaultSparkVersion":{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},"clusterPublisherRootId":5,"enableLatestJobRunResultPermalink":true,"enableSparkConfUI":true,"enableJdbcImport":true,"logfiles":"logfiles/","enableClusterDeltaUpdates":true,"csrfToken":"d3dde7ae-fd45-4989-86b8-e91415a5ebcf","useFixedStaticNotebookVersionForDevelopment":false,"enableBasicReactDialogBoxes":true,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableWorkspaceAclService":true,"enableWorkspaceAcls":true,"gitHash":"094163cf51fcd4717c3ea96799d1008723ae8985","userFullname":"Suresh Jayaram","enableImportFromUrl":true,"enableMiniClusters":false,"enableWebSocketDeltaUpdates":true,"enableDebugUI":false,"showHiddenSparkVersions":false,"allowNonAdminUsers":true,"userId":100017,"dbcSupportURL":"","staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/","enableSparkPackages":true,"enableNotebookHistoryUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"databricksGuideStaticUrl":"","notebookLoadingBackground":"#fff","enableNewJobRunDetailsPage":true,"enableDashboardExport":true,"user":"surjayaram@paypal.com","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"tablesPublisherRootId":7,"accounts":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":2572,"name":"Spark MLlib / Algorithms / Naive Bayes","language":"python","commands":[{"version":"CommandV1","origId":2573,"guid":"6575d2d7-14c4-43e8-988e-094618a8d5f8","subtype":"command","commandType":"auto","position":0.5,"command":"%md\n# Naive Bayes Classifier - ML Pipelines\n\nThis notebook will provide a brief algorithm summary, links for further reading, and a data analysis example of how to use the Naive Bayes algorithm with the ML Pipelines API.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"a83cf048-3a42-4f9e-873a-d95adba9e075"},{"version":"CommandV1","origId":2574,"guid":"aefa82d3-7c0e-4bb3-af81-7276c061d7c1","subtype":"command","commandType":"auto","position":0.75,"command":"%md\n#### Algorithm Summary\n- **Task**: classification with binary or multiclass labels\n- **Input**: labels (binary or multiclass, 0-based indexed), feature vectors (discrete)\n- **Smoothing**: [Additive smoothing](https://en.wikipedia.org/wiki/Additive_smoothing), default parameter is set to 1.0\n- **Model type**: Multinomial. Can also be used as Bernoulli if feature vectors are converted into 0-1 vectors and with modelType set to \"Bernoulli\"\n- **Assumptions**:\n  - Independence between every pair of features\n  - Feature values are nonnegative, such as counts","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"b27deb56-3faf-4ade-838d-262dff8962be"},{"version":"CommandV1","origId":2575,"guid":"bfb7c8ac-d11b-4532-8475-78bd29d6aaad","subtype":"command","commandType":"auto","position":0.78125,"command":"%md\n####Links\n- Spark API docs\n  - Python: [NaiveBayes](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.NaiveBayes)\n  - Scala: [NaiveBayes](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.classification.NaiveBayes)\n- [MLlib Programming Guide](https://spark.apache.org/docs/latest/mllib-naive-bayes.html)\n- [ML Pipelines Programming Guide](https://spark.apache.org/docs/latest/ml-guide.html#pipeline-components)\n- [Wikipedia: Naive Bayes Classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"3370bf16-23d8-49bc-a62b-c6f11c25641a"},{"version":"CommandV1","origId":2576,"guid":"5ce6ddb9-a17f-4643-8407-2e88be8d3014","subtype":"command","commandType":"auto","position":0.8125,"command":"%md\n#### Data Analysis Example\n- Dataset Review\n- Load Data & Data Preprocessing\n- Explore Data\n- Create a multiclass Naive Bayes Classifier and Evaluation\n- Experimenting with Various Smoothing Parameters\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"ccaeda56-b674-4d1c-84ab-9aaa1bed5522"},{"version":"CommandV1","origId":2577,"guid":"42593110-4c31-40fc-9551-dbc7027f898b","subtype":"command","commandType":"auto","position":0.9375,"command":"%md\n#### Dataset Review\n\nThe dataset contains 3 species of iris (Setosa, Versicolor and Virginica) with 50 instances of each. In this example, we are going to try to predict the species of iris from its features.\n\nFeature Information:\n1. Sepal Length in cm \n2. Sepal Width in cm \n3. Petal Length in cm \n4. Petal Width in cm \n\nTarget/Label:\n  - Species\n    - Setosa\n    - Versicolor\n    - Virginica","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"9a7db7a2-e89c-4054-ad19-0ca815ee4e82"},{"version":"CommandV1","origId":2578,"guid":"bd6f3c13-3722-4b49-988e-f3f74695d3da","subtype":"command","commandType":"auto","position":1.5,"command":"%md\n#### Load Data and Data Preprocessing\n\n\nIn this notebook, we will be using the iris dataset that is mounted on the DBFS. You can read more about free public hosted datasets [here](../../03 Accessing Data/5 DataSets/1 DBFS Hosted Datasets.html).","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"5ebe7293-8937-4ac1-b21a-258c8ab062a2"},{"version":"CommandV1","origId":2579,"guid":"90a0ba0f-46e2-4713-911e-a7c2b93f2427","subtype":"command","commandType":"auto","position":2.0,"command":"# Filepath for iris dataset in DBFS\ndisplay(dbutils.fs.ls(\"/databricks-datasets/Rdatasets/data-001/csv/datasets/iris.csv\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["dbfs:/databricks-datasets/Rdatasets/data-001/csv/datasets/iris.csv","iris.csv",4821.0]],"arguments":{},"schema":[{"type":"string","name":"path"},{"type":"string","name":"name"},{"type":"bigint","name":"size"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":"<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax","error":"<div class=\"ansiout\"><span class=\"ansicyan\">  File </span><span class=\"ansigreen\">&quot;&lt;ipython-input-6-a712e74b2dee&gt;&quot;</span><span class=\"ansicyan\">, line </span><span class=\"ansigreen\">1</span>\n<span class=\"ansiyellow\">    -- List of Available Datasets in DBFS</span>\n<span class=\"ansigrey\">             ^</span>\n<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax\n\n</div>","startTime":1.443119425509E12,"submitTime":1.443119425458E12,"finishTime":1.443119439418E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"6e69ca50-d866-4a43-adb1-3d52bb1f11a5"},{"version":"CommandV1","origId":2580,"guid":"066448e0-cb1c-4c5e-baa0-6ad85c5c6d05","subtype":"command","commandType":"auto","position":2.5,"command":"%md\nRead in the dataset using the spark-csv package. Note that the iris dataset has dots in column names by default, such as \"Sepal.Length\" and \"Sepal.Width\". Spark-csv doesn't support dots in column names because it's usually the notation used for nested queries. To get by this, we will have to rename the columns when we read the data in using SQL","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"5a85edb6-0961-4d9a-a144-ab1b782913f6"},{"version":"CommandV1","origId":2581,"guid":"4125ccea-9f16-450a-b8ae-f2b3658f548a","subtype":"command","commandType":"auto","position":2.6875,"command":"%sql DROP TABLE IF EXISTS iris","commandVersion":0,"state":"finished","results":{"type":"table","data":[],"arguments":{},"schema":[],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.443123497275E12,"submitTime":1.443123497211E12,"finishTime":1.443123499856E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"0298c943-e48c-4392-b236-41f10ab3a37f"},{"version":"CommandV1","origId":2582,"guid":"d2de394a-8a3e-4ba1-aa1f-35d95655e5d6","subtype":"command","commandType":"auto","position":2.875,"command":"%sql\nCREATE TABLE iris (rowNum int, SepalLength double, SepalWidth double, PetalLength double, PetalWidth double, Species string)\nUSING com.databricks.spark.csv\nOPTIONS (path \"/databricks-datasets/Rdatasets/data-001/csv/datasets/iris.csv\", header \"true\")","commandVersion":0,"state":"finished","results":{"type":"table","data":[],"arguments":{},"schema":[],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":"Error in SQL statement: AnalysisException: Table iris already exists.;","error":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table iris already exists.;\n\tat org.apache.spark.sql.hive.execution.CreateMetastoreDataSource.run(commands.scala:157)\n\tat org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:57)\n\tat org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:57)\n\tat org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:69)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:138)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:933)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:933)\n\tat org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:144)\n\tat org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:129)\n\tat org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:725)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$5.apply(DriverLocal.scala:310)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$5.apply(DriverLocal.scala:290)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:105)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:290)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:162)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$3.apply(DriverWrapper.scala:485)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$3.apply(DriverWrapper.scala:485)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:482)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:384)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:195)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:325)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:162)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$3.apply(DriverWrapper.scala:485)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$3.apply(DriverWrapper.scala:485)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:482)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:384)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:195)\n\tat java.lang.Thread.run(Thread.java:745)\n","startTime":1.443123501797E12,"submitTime":1.443123501742E12,"finishTime":1.443123502101E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"8f630aea-6bca-4f3b-b416-008fd3aea304"},{"version":"CommandV1","origId":2583,"guid":"75ba0182-3a67-45ed-b15e-abdf9e07f705","subtype":"command","commandType":"auto","position":2.90625,"command":"%sql SELECT * FROM iris","commandVersion":0,"state":"finished","results":{"type":"table","data":[[1.0,5.1,3.5,1.4,0.2,"setosa"],[2.0,4.9,3.0,1.4,0.2,"setosa"],[3.0,4.7,3.2,1.3,0.2,"setosa"],[4.0,4.6,3.1,1.5,0.2,"setosa"],[5.0,5.0,3.6,1.4,0.2,"setosa"],[6.0,5.4,3.9,1.7,0.4,"setosa"],[7.0,4.6,3.4,1.4,0.3,"setosa"],[8.0,5.0,3.4,1.5,0.2,"setosa"],[9.0,4.4,2.9,1.4,0.2,"setosa"],[10.0,4.9,3.1,1.5,0.1,"setosa"],[11.0,5.4,3.7,1.5,0.2,"setosa"],[12.0,4.8,3.4,1.6,0.2,"setosa"],[13.0,4.8,3.0,1.4,0.1,"setosa"],[14.0,4.3,3.0,1.1,0.1,"setosa"],[15.0,5.8,4.0,1.2,0.2,"setosa"],[16.0,5.7,4.4,1.5,0.4,"setosa"],[17.0,5.4,3.9,1.3,0.4,"setosa"],[18.0,5.1,3.5,1.4,0.3,"setosa"],[19.0,5.7,3.8,1.7,0.3,"setosa"],[20.0,5.1,3.8,1.5,0.3,"setosa"],[21.0,5.4,3.4,1.7,0.2,"setosa"],[22.0,5.1,3.7,1.5,0.4,"setosa"],[23.0,4.6,3.6,1.0,0.2,"setosa"],[24.0,5.1,3.3,1.7,0.5,"setosa"],[25.0,4.8,3.4,1.9,0.2,"setosa"],[26.0,5.0,3.0,1.6,0.2,"setosa"],[27.0,5.0,3.4,1.6,0.4,"setosa"],[28.0,5.2,3.5,1.5,0.2,"setosa"],[29.0,5.2,3.4,1.4,0.2,"setosa"],[30.0,4.7,3.2,1.6,0.2,"setosa"],[31.0,4.8,3.1,1.6,0.2,"setosa"],[32.0,5.4,3.4,1.5,0.4,"setosa"],[33.0,5.2,4.1,1.5,0.1,"setosa"],[34.0,5.5,4.2,1.4,0.2,"setosa"],[35.0,4.9,3.1,1.5,0.2,"setosa"],[36.0,5.0,3.2,1.2,0.2,"setosa"],[37.0,5.5,3.5,1.3,0.2,"setosa"],[38.0,4.9,3.6,1.4,0.1,"setosa"],[39.0,4.4,3.0,1.3,0.2,"setosa"],[40.0,5.1,3.4,1.5,0.2,"setosa"],[41.0,5.0,3.5,1.3,0.3,"setosa"],[42.0,4.5,2.3,1.3,0.3,"setosa"],[43.0,4.4,3.2,1.3,0.2,"setosa"],[44.0,5.0,3.5,1.6,0.6,"setosa"],[45.0,5.1,3.8,1.9,0.4,"setosa"],[46.0,4.8,3.0,1.4,0.3,"setosa"],[47.0,5.1,3.8,1.6,0.2,"setosa"],[48.0,4.6,3.2,1.4,0.2,"setosa"],[49.0,5.3,3.7,1.5,0.2,"setosa"],[50.0,5.0,3.3,1.4,0.2,"setosa"],[51.0,7.0,3.2,4.7,1.4,"versicolor"],[52.0,6.4,3.2,4.5,1.5,"versicolor"],[53.0,6.9,3.1,4.9,1.5,"versicolor"],[54.0,5.5,2.3,4.0,1.3,"versicolor"],[55.0,6.5,2.8,4.6,1.5,"versicolor"],[56.0,5.7,2.8,4.5,1.3,"versicolor"],[57.0,6.3,3.3,4.7,1.6,"versicolor"],[58.0,4.9,2.4,3.3,1.0,"versicolor"],[59.0,6.6,2.9,4.6,1.3,"versicolor"],[60.0,5.2,2.7,3.9,1.4,"versicolor"],[61.0,5.0,2.0,3.5,1.0,"versicolor"],[62.0,5.9,3.0,4.2,1.5,"versicolor"],[63.0,6.0,2.2,4.0,1.0,"versicolor"],[64.0,6.1,2.9,4.7,1.4,"versicolor"],[65.0,5.6,2.9,3.6,1.3,"versicolor"],[66.0,6.7,3.1,4.4,1.4,"versicolor"],[67.0,5.6,3.0,4.5,1.5,"versicolor"],[68.0,5.8,2.7,4.1,1.0,"versicolor"],[69.0,6.2,2.2,4.5,1.5,"versicolor"],[70.0,5.6,2.5,3.9,1.1,"versicolor"],[71.0,5.9,3.2,4.8,1.8,"versicolor"],[72.0,6.1,2.8,4.0,1.3,"versicolor"],[73.0,6.3,2.5,4.9,1.5,"versicolor"],[74.0,6.1,2.8,4.7,1.2,"versicolor"],[75.0,6.4,2.9,4.3,1.3,"versicolor"],[76.0,6.6,3.0,4.4,1.4,"versicolor"],[77.0,6.8,2.8,4.8,1.4,"versicolor"],[78.0,6.7,3.0,5.0,1.7,"versicolor"],[79.0,6.0,2.9,4.5,1.5,"versicolor"],[80.0,5.7,2.6,3.5,1.0,"versicolor"],[81.0,5.5,2.4,3.8,1.1,"versicolor"],[82.0,5.5,2.4,3.7,1.0,"versicolor"],[83.0,5.8,2.7,3.9,1.2,"versicolor"],[84.0,6.0,2.7,5.1,1.6,"versicolor"],[85.0,5.4,3.0,4.5,1.5,"versicolor"],[86.0,6.0,3.4,4.5,1.6,"versicolor"],[87.0,6.7,3.1,4.7,1.5,"versicolor"],[88.0,6.3,2.3,4.4,1.3,"versicolor"],[89.0,5.6,3.0,4.1,1.3,"versicolor"],[90.0,5.5,2.5,4.0,1.3,"versicolor"],[91.0,5.5,2.6,4.4,1.2,"versicolor"],[92.0,6.1,3.0,4.6,1.4,"versicolor"],[93.0,5.8,2.6,4.0,1.2,"versicolor"],[94.0,5.0,2.3,3.3,1.0,"versicolor"],[95.0,5.6,2.7,4.2,1.3,"versicolor"],[96.0,5.7,3.0,4.2,1.2,"versicolor"],[97.0,5.7,2.9,4.2,1.3,"versicolor"],[98.0,6.2,2.9,4.3,1.3,"versicolor"],[99.0,5.1,2.5,3.0,1.1,"versicolor"],[100.0,5.7,2.8,4.1,1.3,"versicolor"],[101.0,6.3,3.3,6.0,2.5,"virginica"],[102.0,5.8,2.7,5.1,1.9,"virginica"],[103.0,7.1,3.0,5.9,2.1,"virginica"],[104.0,6.3,2.9,5.6,1.8,"virginica"],[105.0,6.5,3.0,5.8,2.2,"virginica"],[106.0,7.6,3.0,6.6,2.1,"virginica"],[107.0,4.9,2.5,4.5,1.7,"virginica"],[108.0,7.3,2.9,6.3,1.8,"virginica"],[109.0,6.7,2.5,5.8,1.8,"virginica"],[110.0,7.2,3.6,6.1,2.5,"virginica"],[111.0,6.5,3.2,5.1,2.0,"virginica"],[112.0,6.4,2.7,5.3,1.9,"virginica"],[113.0,6.8,3.0,5.5,2.1,"virginica"],[114.0,5.7,2.5,5.0,2.0,"virginica"],[115.0,5.8,2.8,5.1,2.4,"virginica"],[116.0,6.4,3.2,5.3,2.3,"virginica"],[117.0,6.5,3.0,5.5,1.8,"virginica"],[118.0,7.7,3.8,6.7,2.2,"virginica"],[119.0,7.7,2.6,6.9,2.3,"virginica"],[120.0,6.0,2.2,5.0,1.5,"virginica"],[121.0,6.9,3.2,5.7,2.3,"virginica"],[122.0,5.6,2.8,4.9,2.0,"virginica"],[123.0,7.7,2.8,6.7,2.0,"virginica"],[124.0,6.3,2.7,4.9,1.8,"virginica"],[125.0,6.7,3.3,5.7,2.1,"virginica"],[126.0,7.2,3.2,6.0,1.8,"virginica"],[127.0,6.2,2.8,4.8,1.8,"virginica"],[128.0,6.1,3.0,4.9,1.8,"virginica"],[129.0,6.4,2.8,5.6,2.1,"virginica"],[130.0,7.2,3.0,5.8,1.6,"virginica"],[131.0,7.4,2.8,6.1,1.9,"virginica"],[132.0,7.9,3.8,6.4,2.0,"virginica"],[133.0,6.4,2.8,5.6,2.2,"virginica"],[134.0,6.3,2.8,5.1,1.5,"virginica"],[135.0,6.1,2.6,5.6,1.4,"virginica"],[136.0,7.7,3.0,6.1,2.3,"virginica"],[137.0,6.3,3.4,5.6,2.4,"virginica"],[138.0,6.4,3.1,5.5,1.8,"virginica"],[139.0,6.0,3.0,4.8,1.8,"virginica"],[140.0,6.9,3.1,5.4,2.1,"virginica"],[141.0,6.7,3.1,5.6,2.4,"virginica"],[142.0,6.9,3.1,5.1,2.3,"virginica"],[143.0,5.8,2.7,5.1,1.9,"virginica"],[144.0,6.8,3.2,5.9,2.3,"virginica"],[145.0,6.7,3.3,5.7,2.5,"virginica"],[146.0,6.7,3.0,5.2,2.3,"virginica"],[147.0,6.3,2.5,5.0,1.9,"virginica"],[148.0,6.5,3.0,5.2,2.0,"virginica"],[149.0,6.2,3.4,5.4,2.3,"virginica"],[150.0,5.9,3.0,5.1,1.8,"virginica"]],"arguments":{},"schema":[{"type":"int","name":"rowNum"},{"type":"double","name":"SepalLength"},{"type":"double","name":"SepalWidth"},{"type":"double","name":"PetalLength"},{"type":"double","name":"PetalWidth"},{"type":"string","name":"Species"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.443123503985E12,"submitTime":1.443123503852E12,"finishTime":1.443123507386E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"aec64ae7-4404-41fb-ae0b-26d98a8e16be"},{"version":"CommandV1","origId":2584,"guid":"63191cd7-baa7-4746-990e-81058b63c0dc","subtype":"command","commandType":"auto","position":2.921875,"command":"%md\nSince we do not need the first column of row indexes, we will only select the relevant columns that we need and convert it into a DataFrame","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"17af7fff-52bc-4376-ba4b-969cba38f108"},{"version":"CommandV1","origId":2585,"guid":"28290e88-66a2-4959-8ba3-8ef2ca88ccf7","subtype":"command","commandType":"auto","position":2.9375,"command":"irisdf = sqlContext.sql(\"SELECT SepalLength, SepalWidth, PetalLength, PetalWidth, Species FROM iris\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">TypeError</span>: sql() takes exactly 2 arguments (3 given)","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-11-f4a60a41801f&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>irisdf <span class=\"ansiyellow\">=</span> sql<span class=\"ansiyellow\">(</span>sqlContext<span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;SELECT SepalLength, SepalWidth, PetalLength, PetalWidth, Species FROM iris&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: sql() takes exactly 2 arguments (3 given)\n</div>","startTime":1.443123510299E12,"submitTime":1.443123510233E12,"finishTime":1.443123510436E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"5dbe8dce-0851-4604-8680-7d2e2fc6b135"},{"version":"CommandV1","origId":2586,"guid":"f4d7bbe6-81ff-4c2e-98d3-c4d67fce29b9","subtype":"command","commandType":"auto","position":2.96875,"command":"display(irisdf)","commandVersion":0,"state":"finished","results":{"type":"table","data":[[5.1,3.5,1.4,0.2,"setosa"],[4.9,3.0,1.4,0.2,"setosa"],[4.7,3.2,1.3,0.2,"setosa"],[4.6,3.1,1.5,0.2,"setosa"],[5.0,3.6,1.4,0.2,"setosa"],[5.4,3.9,1.7,0.4,"setosa"],[4.6,3.4,1.4,0.3,"setosa"],[5.0,3.4,1.5,0.2,"setosa"],[4.4,2.9,1.4,0.2,"setosa"],[4.9,3.1,1.5,0.1,"setosa"],[5.4,3.7,1.5,0.2,"setosa"],[4.8,3.4,1.6,0.2,"setosa"],[4.8,3.0,1.4,0.1,"setosa"],[4.3,3.0,1.1,0.1,"setosa"],[5.8,4.0,1.2,0.2,"setosa"],[5.7,4.4,1.5,0.4,"setosa"],[5.4,3.9,1.3,0.4,"setosa"],[5.1,3.5,1.4,0.3,"setosa"],[5.7,3.8,1.7,0.3,"setosa"],[5.1,3.8,1.5,0.3,"setosa"],[5.4,3.4,1.7,0.2,"setosa"],[5.1,3.7,1.5,0.4,"setosa"],[4.6,3.6,1.0,0.2,"setosa"],[5.1,3.3,1.7,0.5,"setosa"],[4.8,3.4,1.9,0.2,"setosa"],[5.0,3.0,1.6,0.2,"setosa"],[5.0,3.4,1.6,0.4,"setosa"],[5.2,3.5,1.5,0.2,"setosa"],[5.2,3.4,1.4,0.2,"setosa"],[4.7,3.2,1.6,0.2,"setosa"],[4.8,3.1,1.6,0.2,"setosa"],[5.4,3.4,1.5,0.4,"setosa"],[5.2,4.1,1.5,0.1,"setosa"],[5.5,4.2,1.4,0.2,"setosa"],[4.9,3.1,1.5,0.2,"setosa"],[5.0,3.2,1.2,0.2,"setosa"],[5.5,3.5,1.3,0.2,"setosa"],[4.9,3.6,1.4,0.1,"setosa"],[4.4,3.0,1.3,0.2,"setosa"],[5.1,3.4,1.5,0.2,"setosa"],[5.0,3.5,1.3,0.3,"setosa"],[4.5,2.3,1.3,0.3,"setosa"],[4.4,3.2,1.3,0.2,"setosa"],[5.0,3.5,1.6,0.6,"setosa"],[5.1,3.8,1.9,0.4,"setosa"],[4.8,3.0,1.4,0.3,"setosa"],[5.1,3.8,1.6,0.2,"setosa"],[4.6,3.2,1.4,0.2,"setosa"],[5.3,3.7,1.5,0.2,"setosa"],[5.0,3.3,1.4,0.2,"setosa"],[7.0,3.2,4.7,1.4,"versicolor"],[6.4,3.2,4.5,1.5,"versicolor"],[6.9,3.1,4.9,1.5,"versicolor"],[5.5,2.3,4.0,1.3,"versicolor"],[6.5,2.8,4.6,1.5,"versicolor"],[5.7,2.8,4.5,1.3,"versicolor"],[6.3,3.3,4.7,1.6,"versicolor"],[4.9,2.4,3.3,1.0,"versicolor"],[6.6,2.9,4.6,1.3,"versicolor"],[5.2,2.7,3.9,1.4,"versicolor"],[5.0,2.0,3.5,1.0,"versicolor"],[5.9,3.0,4.2,1.5,"versicolor"],[6.0,2.2,4.0,1.0,"versicolor"],[6.1,2.9,4.7,1.4,"versicolor"],[5.6,2.9,3.6,1.3,"versicolor"],[6.7,3.1,4.4,1.4,"versicolor"],[5.6,3.0,4.5,1.5,"versicolor"],[5.8,2.7,4.1,1.0,"versicolor"],[6.2,2.2,4.5,1.5,"versicolor"],[5.6,2.5,3.9,1.1,"versicolor"],[5.9,3.2,4.8,1.8,"versicolor"],[6.1,2.8,4.0,1.3,"versicolor"],[6.3,2.5,4.9,1.5,"versicolor"],[6.1,2.8,4.7,1.2,"versicolor"],[6.4,2.9,4.3,1.3,"versicolor"],[6.6,3.0,4.4,1.4,"versicolor"],[6.8,2.8,4.8,1.4,"versicolor"],[6.7,3.0,5.0,1.7,"versicolor"],[6.0,2.9,4.5,1.5,"versicolor"],[5.7,2.6,3.5,1.0,"versicolor"],[5.5,2.4,3.8,1.1,"versicolor"],[5.5,2.4,3.7,1.0,"versicolor"],[5.8,2.7,3.9,1.2,"versicolor"],[6.0,2.7,5.1,1.6,"versicolor"],[5.4,3.0,4.5,1.5,"versicolor"],[6.0,3.4,4.5,1.6,"versicolor"],[6.7,3.1,4.7,1.5,"versicolor"],[6.3,2.3,4.4,1.3,"versicolor"],[5.6,3.0,4.1,1.3,"versicolor"],[5.5,2.5,4.0,1.3,"versicolor"],[5.5,2.6,4.4,1.2,"versicolor"],[6.1,3.0,4.6,1.4,"versicolor"],[5.8,2.6,4.0,1.2,"versicolor"],[5.0,2.3,3.3,1.0,"versicolor"],[5.6,2.7,4.2,1.3,"versicolor"],[5.7,3.0,4.2,1.2,"versicolor"],[5.7,2.9,4.2,1.3,"versicolor"],[6.2,2.9,4.3,1.3,"versicolor"],[5.1,2.5,3.0,1.1,"versicolor"],[5.7,2.8,4.1,1.3,"versicolor"],[6.3,3.3,6.0,2.5,"virginica"],[5.8,2.7,5.1,1.9,"virginica"],[7.1,3.0,5.9,2.1,"virginica"],[6.3,2.9,5.6,1.8,"virginica"],[6.5,3.0,5.8,2.2,"virginica"],[7.6,3.0,6.6,2.1,"virginica"],[4.9,2.5,4.5,1.7,"virginica"],[7.3,2.9,6.3,1.8,"virginica"],[6.7,2.5,5.8,1.8,"virginica"],[7.2,3.6,6.1,2.5,"virginica"],[6.5,3.2,5.1,2.0,"virginica"],[6.4,2.7,5.3,1.9,"virginica"],[6.8,3.0,5.5,2.1,"virginica"],[5.7,2.5,5.0,2.0,"virginica"],[5.8,2.8,5.1,2.4,"virginica"],[6.4,3.2,5.3,2.3,"virginica"],[6.5,3.0,5.5,1.8,"virginica"],[7.7,3.8,6.7,2.2,"virginica"],[7.7,2.6,6.9,2.3,"virginica"],[6.0,2.2,5.0,1.5,"virginica"],[6.9,3.2,5.7,2.3,"virginica"],[5.6,2.8,4.9,2.0,"virginica"],[7.7,2.8,6.7,2.0,"virginica"],[6.3,2.7,4.9,1.8,"virginica"],[6.7,3.3,5.7,2.1,"virginica"],[7.2,3.2,6.0,1.8,"virginica"],[6.2,2.8,4.8,1.8,"virginica"],[6.1,3.0,4.9,1.8,"virginica"],[6.4,2.8,5.6,2.1,"virginica"],[7.2,3.0,5.8,1.6,"virginica"],[7.4,2.8,6.1,1.9,"virginica"],[7.9,3.8,6.4,2.0,"virginica"],[6.4,2.8,5.6,2.2,"virginica"],[6.3,2.8,5.1,1.5,"virginica"],[6.1,2.6,5.6,1.4,"virginica"],[7.7,3.0,6.1,2.3,"virginica"],[6.3,3.4,5.6,2.4,"virginica"],[6.4,3.1,5.5,1.8,"virginica"],[6.0,3.0,4.8,1.8,"virginica"],[6.9,3.1,5.4,2.1,"virginica"],[6.7,3.1,5.6,2.4,"virginica"],[6.9,3.1,5.1,2.3,"virginica"],[5.8,2.7,5.1,1.9,"virginica"],[6.8,3.2,5.9,2.3,"virginica"],[6.7,3.3,5.7,2.5,"virginica"],[6.7,3.0,5.2,2.3,"virginica"],[6.3,2.5,5.0,1.9,"virginica"],[6.5,3.0,5.2,2.0,"virginica"],[6.2,3.4,5.4,2.3,"virginica"],[5.9,3.0,5.1,1.8,"virginica"]],"arguments":{},"schema":[{"type":"double","name":"SepalLength"},{"type":"double","name":"SepalWidth"},{"type":"double","name":"PetalLength"},{"type":"double","name":"PetalWidth"},{"type":"string","name":"Species"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.443123512311E12,"submitTime":1.44312351218E12,"finishTime":1.443123514841E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"3e2d005a-2211-42cd-a017-b810f21f7d50"},{"version":"CommandV1","origId":2587,"guid":"0d2df1bd-f2e1-4427-ac98-1779f07294cf","subtype":"command","commandType":"auto","position":4.875,"command":"%md\nSince we have already removed the row index column and separated the header from the rest of the dataset, the next data preprocessing step we need to take is to convert our label into numerical categories. This can be easily done with the StringIndexer(). We won't transform the dataset just yet as we will pass the StringIndexer() into our ML Pipeline later.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"ebba19b6-f445-4b4b-91c9-070c69930dbc"},{"version":"CommandV1","origId":2588,"guid":"072694b8-a7db-4368-8916-508910e551d5","subtype":"command","commandType":"auto","position":5.0625,"command":"from pyspark.ml.feature import StringIndexer\n# Convert target into numerical categories\nlabelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.443123518171E12,"submitTime":1.443123518111E12,"finishTime":1.443123518301E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"97994792-9320-4eab-abe1-410c4f7e82bf"},{"version":"CommandV1","origId":2589,"guid":"a09ff397-2af0-4db2-afe0-657e9bf72f8e","subtype":"command","commandType":"auto","position":5.75,"command":"%md\n#### Explore Data\n\n\nWe can easily obtain some quick visualizations to better understand the data with the display() command.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.4422738185E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"a8e594f1-fb68-4f3b-b335-b4a3001e8ed7"},{"version":"CommandV1","origId":2590,"guid":"1be6559b-f78f-4963-b565-a26214acb90b","subtype":"command","commandType":"auto","position":5.875,"command":"irisdf.printSchema()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- SepalLength: double (nullable = true)\n |-- SepalWidth: double (nullable = true)\n |-- PetalLength: double (nullable = true)\n |-- PetalWidth: double (nullable = true)\n |-- Species: string (nullable = true)\n\n</div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax","error":"<div class=\"ansiout\"><span class=\"ansicyan\">  File </span><span class=\"ansigreen\">&quot;&lt;ipython-input-10-93aad4390328&gt;&quot;</span><span class=\"ansicyan\">, line </span><span class=\"ansigreen\">2</span>\n<span class=\"ansiyellow\">    ])</span>\n<span class=\"ansigrey\">    ^</span>\n<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax\n\n</div>","startTime":1.443119527784E12,"submitTime":1.443119527683E12,"finishTime":1.443119527863E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"895ad4fd-7daa-4d9a-9992-2e3c545f9408"},{"version":"CommandV1","origId":2591,"guid":"68e2be29-72f7-4987-94b6-8ad7d20d368b","subtype":"command","commandType":"auto","position":5.96875,"command":"# Click the chart icon on the bottom left to select chart type and set plot options\ndisplay(irisdf.select(\"SepalLength\", \"Species\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[[5.1,"setosa"],[4.9,"setosa"],[4.7,"setosa"],[4.6,"setosa"],[5.0,"setosa"],[5.4,"setosa"],[4.6,"setosa"],[5.0,"setosa"],[4.4,"setosa"],[4.9,"setosa"],[5.4,"setosa"],[4.8,"setosa"],[4.8,"setosa"],[4.3,"setosa"],[5.8,"setosa"],[5.7,"setosa"],[5.4,"setosa"],[5.1,"setosa"],[5.7,"setosa"],[5.1,"setosa"],[5.4,"setosa"],[5.1,"setosa"],[4.6,"setosa"],[5.1,"setosa"],[4.8,"setosa"],[5.0,"setosa"],[5.0,"setosa"],[5.2,"setosa"],[5.2,"setosa"],[4.7,"setosa"],[4.8,"setosa"],[5.4,"setosa"],[5.2,"setosa"],[5.5,"setosa"],[4.9,"setosa"],[5.0,"setosa"],[5.5,"setosa"],[4.9,"setosa"],[4.4,"setosa"],[5.1,"setosa"],[5.0,"setosa"],[4.5,"setosa"],[4.4,"setosa"],[5.0,"setosa"],[5.1,"setosa"],[4.8,"setosa"],[5.1,"setosa"],[4.6,"setosa"],[5.3,"setosa"],[5.0,"setosa"],[7.0,"versicolor"],[6.4,"versicolor"],[6.9,"versicolor"],[5.5,"versicolor"],[6.5,"versicolor"],[5.7,"versicolor"],[6.3,"versicolor"],[4.9,"versicolor"],[6.6,"versicolor"],[5.2,"versicolor"],[5.0,"versicolor"],[5.9,"versicolor"],[6.0,"versicolor"],[6.1,"versicolor"],[5.6,"versicolor"],[6.7,"versicolor"],[5.6,"versicolor"],[5.8,"versicolor"],[6.2,"versicolor"],[5.6,"versicolor"],[5.9,"versicolor"],[6.1,"versicolor"],[6.3,"versicolor"],[6.1,"versicolor"],[6.4,"versicolor"],[6.6,"versicolor"],[6.8,"versicolor"],[6.7,"versicolor"],[6.0,"versicolor"],[5.7,"versicolor"],[5.5,"versicolor"],[5.5,"versicolor"],[5.8,"versicolor"],[6.0,"versicolor"],[5.4,"versicolor"],[6.0,"versicolor"],[6.7,"versicolor"],[6.3,"versicolor"],[5.6,"versicolor"],[5.5,"versicolor"],[5.5,"versicolor"],[6.1,"versicolor"],[5.8,"versicolor"],[5.0,"versicolor"],[5.6,"versicolor"],[5.7,"versicolor"],[5.7,"versicolor"],[6.2,"versicolor"],[5.1,"versicolor"],[5.7,"versicolor"],[6.3,"virginica"],[5.8,"virginica"],[7.1,"virginica"],[6.3,"virginica"],[6.5,"virginica"],[7.6,"virginica"],[4.9,"virginica"],[7.3,"virginica"],[6.7,"virginica"],[7.2,"virginica"],[6.5,"virginica"],[6.4,"virginica"],[6.8,"virginica"],[5.7,"virginica"],[5.8,"virginica"],[6.4,"virginica"],[6.5,"virginica"],[7.7,"virginica"],[7.7,"virginica"],[6.0,"virginica"],[6.9,"virginica"],[5.6,"virginica"],[7.7,"virginica"],[6.3,"virginica"],[6.7,"virginica"],[7.2,"virginica"],[6.2,"virginica"],[6.1,"virginica"],[6.4,"virginica"],[7.2,"virginica"],[7.4,"virginica"],[7.9,"virginica"],[6.4,"virginica"],[6.3,"virginica"],[6.1,"virginica"],[7.7,"virginica"],[6.3,"virginica"],[6.4,"virginica"],[6.0,"virginica"],[6.9,"virginica"],[6.7,"virginica"],[6.9,"virginica"],[5.8,"virginica"],[6.8,"virginica"],[6.7,"virginica"],[6.7,"virginica"],[6.3,"virginica"],[6.5,"virginica"],[6.2,"virginica"],[5.9,"virginica"]],"arguments":{},"schema":[{"type":"double","name":"SepalLength"},{"type":"string","name":"Species"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":"<span class=\"ansired\">AnalysisException</span>: cannot resolve &apos;PetalLengthSpecies&apos; given input columns Species, SepalLength, PetalWidth, SepalWidth, PetalLength;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-19-72c3e9cc0ad8&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Click the chart icon on the bottom left to select chart type and set plot options</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>display<span class=\"ansiyellow\">(</span>irisdf<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;SepalLength&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;PetalLength&quot;</span> <span class=\"ansiblue\">&quot;Species&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/dataframe.pyc</span> in <span class=\"ansicyan\">select</span><span class=\"ansiblue\">(self, *cols)</span>\n<span class=\"ansigreen\">    764</span>         <span class=\"ansiyellow\">[</span>Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Alice&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">12</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Bob&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">15</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    765</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 766</span><span class=\"ansiyellow\">         </span>jdf <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jcols<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>cols<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    767</span>         <span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>jdf<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>sql_ctx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    768</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">    536</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    537</span>         return_value = get_return_value(answer, self.gateway_client,\n<span class=\"ansigreen\">--&gt; 538</span><span class=\"ansiyellow\">                 self.target_id, self.name)\n</span><span class=\"ansigreen\">    539</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    540</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/utils.pyc</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     38</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     39</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.AnalysisException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 40</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     41</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;java.lang.IllegalArgumentException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     42</span>                 <span class=\"ansigreen\">raise</span> IllegalArgumentException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: cannot resolve &apos;PetalLengthSpecies&apos; given input columns Species, SepalLength, PetalWidth, SepalWidth, PetalLength;\n</div>","startTime":1.443119534285E12,"submitTime":1.443119534223E12,"finishTime":1.443119535143E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"histogram","width":"889","height":"401","xColumns":["Species"],"yColumns":["SepalLength"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"206652f0-550d-44d9-925c-736dab68d6bf"},{"version":"CommandV1","origId":2592,"guid":"125adcfe-16a6-4cba-8ef7-28267b3e1cb3","subtype":"command","commandType":"auto","position":5.984375,"command":"%md\nThe above plot suggests that setosas have shorter sepal lengths, whereas the sepal lengths of versicolors and virginicas have similar ranges with the latter having slightly longer sepal lengths.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"6ce877ec-21bf-4872-b8c1-e5ad4f9b8c86"},{"version":"CommandV1","origId":2593,"guid":"5e2a7db0-a2b3-4b66-b1ad-75874f0d67ee","subtype":"command","commandType":"auto","position":7.5,"command":"%md\nIn this example, we will be demonstrating the use of the ML Pipeline API.\n\nTo proceed, we will first randomly split the dataset into training set (70%) and test set (30%). The training set will be used to build our models, and the test set will be used to evaluate models. We cache the datasets as we will be using them multiple times in this notebook.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"8ace8732-a87d-4cad-a110-8586b68a7b94"},{"version":"CommandV1","origId":2594,"guid":"0e7cad02-cac4-4c7f-85eb-2a325368522e","subtype":"command","commandType":"auto","position":7.75,"command":"# Split dataset randomly into Training and Test sets. Set seed for reproducibility\n(trainingData, testData) = irisdf.randomSplit([0.7, 0.3], seed = 100)\ntrainingData.cache()\ntestData.cache()\nprint trainingData.count()\nprint testData.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">105\n45\n</div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;iris_df&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-1-70631acecc0a&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Split dataset randomly into Training and Test sets. Set seed for reproducibility</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span><span class=\"ansiyellow\">(</span>trainingData<span class=\"ansiyellow\">,</span> testData<span class=\"ansiyellow\">)</span> <span class=\"ansiyellow\">=</span> iris_df<span class=\"ansiyellow\">.</span>randomSplit<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0.7</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.3</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> seed <span class=\"ansiyellow\">=</span> <span class=\"ansicyan\">100</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> trainingData<span class=\"ansiyellow\">.</span>cache<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> testData<span class=\"ansiyellow\">.</span>cache<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansigreen\">print</span> trainingData<span class=\"ansiyellow\">.</span>count<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;iris_df&apos; is not defined\n</div>","startTime":1.443123523246E12,"submitTime":1.44312352318E12,"finishTime":1.443123524865E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"b0cdf051-6f43-46e8-9cf2-c5dd08c4744d"},{"version":"CommandV1","origId":2595,"guid":"ac92b294-131d-4701-bd39-d66fa8988fae","subtype":"command","commandType":"auto","position":7.875,"command":"%md\nNext, we will use the VectorAssembler() to merge our feature columns into a single vector column, which we will be passing into our Naive Bayes model. Again, we will not transform the dataset just yet as we will be passing the VectorAssembler into our ML Pipeline.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"aaf4fc4a-a350-4436-a6f6-f00f20a0cc61"},{"version":"CommandV1","origId":2596,"guid":"105a1dff-438b-4af1-a962-aa9fc3f073be","subtype":"command","commandType":"auto","position":7.9375,"command":"from pyspark.ml.feature import VectorAssembler\nvecAssembler = VectorAssembler(inputCols=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"], outputCol=\"features\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.443123929231E12,"submitTime":1.443123929136E12,"finishTime":1.44312392931E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"45d7e248-98a3-45fc-8dec-c0b37f561d99"},{"version":"CommandV1","origId":2597,"guid":"ab0c0f56-0963-4d6c-b97a-1f9df688f197","subtype":"command","commandType":"auto","position":8.5,"command":"%md\n#### Create a Multiclass Naive Bayes Classifier\n\n\nWe will try to see how well Naive Bayes can predict the species of iris using its 4 features -- Sepal Length, Sepal Width, Petal Length, and Petal Width. This is a multiclass problem as we have 3 different species of irises in our dataset. Keep in mind that the Naive Bayes algorithm assumes independence between features, and requires your features to take on non-negative values.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"5a26ad9f-7179-4fd7-850b-f5988f22849d"},{"version":"CommandV1","origId":2598,"guid":"a6258118-b05c-4392-ba32-b2815907fa63","subtype":"command","commandType":"auto","position":8.75,"command":"from pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml import Pipeline\n\n# Train a NaiveBayes model\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n\n# Chain labelIndexer, vecAssembler and NBmodel in a \npipeline = Pipeline(stages=[labelIndexer, vecAssembler, nb])\n\n# Run stages in pipeline and train model\nmodel = pipeline.fit(trainingData)\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">IllegalArgumentException</span>: Field &quot;label&quot; does not exist.","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">IllegalArgumentException</span>                  Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-13-c601d1dc7f67&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      9</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     10</span> <span class=\"ansired\"># Run stages in pipeline and train model</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 11</span><span class=\"ansiyellow\"> </span>model <span class=\"ansiyellow\">=</span> pipeline<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>trainingData<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/pipeline.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">     63</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 65</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     66</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     67</span>             raise ValueError(&quot;Params must be either a param map or a list/tuple of param maps, &quot;\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/pipeline.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    197</span>                     dataset <span class=\"ansiyellow\">=</span> stage<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    198</span>                 <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span>  <span class=\"ansired\"># must be an Estimator</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 199</span><span class=\"ansiyellow\">                     </span>model <span class=\"ansiyellow\">=</span> stage<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    200</span>                     transformers<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    201</span>                     <span class=\"ansigreen\">if</span> i <span class=\"ansiyellow\">&lt;</span> indexOfLastEstimator<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/pipeline.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">     63</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 65</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     66</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     67</span>             raise ValueError(&quot;Params must be either a param map or a list/tuple of param maps, &quot;\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    130</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 132</span><span class=\"ansiyellow\">         </span>java_model <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_fit_java<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    133</span>         <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_create_model<span class=\"ansiyellow\">(</span>java_model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    134</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit_java</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    127</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    128</span>         self<span class=\"ansiyellow\">.</span>_transfer_params_to_java<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 129</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    130</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">    536</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    537</span>         return_value = get_return_value(answer, self.gateway_client,\n<span class=\"ansigreen\">--&gt; 538</span><span class=\"ansiyellow\">                 self.target_id, self.name)\n</span><span class=\"ansigreen\">    539</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    540</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/utils.pyc</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     40</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     41</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;java.lang.IllegalArgumentException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 42</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> IllegalArgumentException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     43</span>             <span class=\"ansigreen\">raise</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     44</span>     <span class=\"ansigreen\">return</span> deco<span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">IllegalArgumentException</span>: Field &quot;label&quot; does not exist.\n</div>","startTime":1.443123933895E12,"submitTime":1.443123933804E12,"finishTime":1.443123934229E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"b95919e9-47f2-440d-99a2-501faca53b71"},{"version":"CommandV1","origId":2599,"guid":"6fbae0c2-f0d2-4d89-9b6a-b8d2a44b5e22","subtype":"command","commandType":"auto","position":8.9375,"command":"%md\nWe can now make predictions from our model and view results.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"24e5d56f-2f03-4329-903f-a853a8e902f1"},{"version":"CommandV1","origId":2600,"guid":"50c2d347-d0ec-43b8-af55-6e04c39b14d0","subtype":"command","commandType":"auto","position":9.03125,"command":"# Make predictions on testData so we can measure the accuracy of our model on new data\npredictions = model.transform(testData)\n\n# Display what results we can view\npredictions.printSchema()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- SepalLength: double (nullable = true)\n |-- SepalWidth: double (nullable = true)\n |-- PetalLength: double (nullable = true)\n |-- PetalWidth: double (nullable = true)\n |-- Species: string (nullable = true)\n |-- label: double (nullable = true)\n |-- features: vector (nullable = true)\n |-- rawPrediction: vector (nullable = true)\n |-- probability: vector (nullable = true)\n |-- prediction: double (nullable = true)\n\n</div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;model&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-12-41a409538728&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>predictions <span class=\"ansiyellow\">=</span> model<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>testData<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;model&apos; is not defined\n</div>","startTime":1.443123936088E12,"submitTime":1.443123936026E12,"finishTime":1.44312393622E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"ed57a252-938f-45e3-b6e8-1f56dd27cdfb"},{"version":"CommandV1","origId":2601,"guid":"acfac787-b578-4aa0-9525-cefc3546b679","subtype":"command","commandType":"auto","position":9.078125,"command":"# Select results to view\ndisplay(predictions.select(\"label\", \"prediction\", \"probability\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[[0.0,0.0,[1.0,3.0,[],[0.6869022850626075,0.12717264831578992,0.1859250666216025]]],[0.0,0.0,[1.0,3.0,[],[0.6686541684917656,0.13673560227643775,0.19461022923179658]]],[0.0,0.0,[1.0,3.0,[],[0.7867803431527454,0.08052240312431798,0.13269725372293673]]],[0.0,0.0,[1.0,3.0,[],[0.7169257388165533,0.1125395946357187,0.170534666547728]]],[0.0,0.0,[1.0,3.0,[],[0.7515131213276974,0.09966022714930549,0.148826651522997]]],[0.0,0.0,[1.0,3.0,[],[0.7638029166675138,0.09144573505968695,0.14475134827279934]]],[0.0,0.0,[1.0,3.0,[],[0.6112587108285166,0.1606949017895996,0.22804638738188382]]],[0.0,0.0,[1.0,3.0,[],[0.6677932209511188,0.13388605919370572,0.1983207198551754]]],[0.0,0.0,[1.0,3.0,[],[0.6875905504211924,0.12616775294149563,0.1862416966373118]]],[0.0,0.0,[1.0,3.0,[],[0.8373004323770838,0.05976788030129552,0.10293168732162077]]],[0.0,0.0,[1.0,3.0,[],[0.6996544112570859,0.12020932125771179,0.18013626748520226]]],[0.0,0.0,[1.0,3.0,[],[0.5753260314554901,0.18173448023761515,0.2429394883068947]]],[0.0,0.0,[1.0,3.0,[],[0.7432446467600116,0.10068814437436666,0.1560672088656218]]],[2.0,2.0,[1.0,3.0,[],[0.06004540205686827,0.45849451099511035,0.48146008694802134]]],[2.0,1.0,[1.0,3.0,[],[0.054418978655203565,0.4751302735665671,0.4704507477782293]]],[2.0,1.0,[1.0,3.0,[],[0.05054318857745659,0.4931833434319637,0.45627346799057966]]],[2.0,2.0,[1.0,3.0,[],[0.09674963061784086,0.4483113638066414,0.45493900557551764]]],[2.0,1.0,[1.0,3.0,[],[0.04130160091059103,0.501787221729166,0.45691117736024295]]],[2.0,1.0,[1.0,3.0,[],[0.026560861743337532,0.5225445705432593,0.45089456771340314]]],[2.0,2.0,[1.0,3.0,[],[0.07570995781073593,0.4583307344951413,0.4659593076941228]]],[2.0,1.0,[1.0,3.0,[],[0.02618125807501527,0.5139897320879571,0.4598290098370276]]],[2.0,2.0,[1.0,3.0,[],[0.06836872027382897,0.4594255429720617,0.4722057367541094]]],[2.0,2.0,[1.0,3.0,[],[0.12864704044332637,0.4188616371288937,0.4524913224277799]]],[2.0,1.0,[1.0,3.0,[],[0.0208588013029921,0.5281136154478824,0.4510275832491254]]],[2.0,1.0,[1.0,3.0,[],[0.04965211592870574,0.4869085927386939,0.4634392913326003]]],[2.0,1.0,[1.0,3.0,[],[0.056756436920510016,0.48572261133802624,0.4575209517414637]]],[2.0,2.0,[1.0,3.0,[],[0.11051297566206508,0.4430008468057656,0.4464861775321693]]],[2.0,1.0,[1.0,3.0,[],[0.05609603281784451,0.4834588381713375,0.4604451290108181]]],[2.0,2.0,[1.0,3.0,[],[0.07704854057609804,0.45894134193260244,0.46401011749129945]]],[2.0,1.0,[1.0,3.0,[],[0.06417949059550856,0.47319083719727323,0.4626296722072181]]],[2.0,2.0,[1.0,3.0,[],[0.06577242583604892,0.4645484374650755,0.4696791366988755]]],[1.0,1.0,[1.0,3.0,[],[0.013046787271601005,0.5431884217515185,0.44376479097688065]]],[1.0,1.0,[1.0,3.0,[],[0.0072022137057132455,0.5679141534226647,0.424883632871622]]],[1.0,1.0,[1.0,3.0,[],[0.005593085773241297,0.5555343908358441,0.4388725233909145]]],[1.0,1.0,[1.0,3.0,[],[0.012993440320728591,0.54604414055214,0.4409624191271314]]],[1.0,1.0,[1.0,3.0,[],[0.01093330308781989,0.5660170115693547,0.4230496853428255]]],[1.0,1.0,[1.0,3.0,[],[0.019045494999007942,0.5322062343414454,0.44874827065954676]]],[1.0,1.0,[1.0,3.0,[],[0.005357297262857016,0.5538890318505943,0.4407536708865487]]],[1.0,1.0,[1.0,3.0,[],[0.011169869534417837,0.547261306432016,0.44156882403356623]]],[1.0,1.0,[1.0,3.0,[],[0.008349399601407927,0.563970989162599,0.4276796112359931]]],[1.0,1.0,[1.0,3.0,[],[0.016242228033397713,0.5331930813295181,0.4505646906370841]]],[1.0,1.0,[1.0,3.0,[],[0.007107645905827935,0.5700425917689934,0.4228497623251785]]],[1.0,1.0,[1.0,3.0,[],[0.0070053282585132125,0.5654707776570518,0.427523894084435]]],[1.0,1.0,[1.0,3.0,[],[0.010447653549741252,0.5569839103043815,0.43256843614587714]]],[1.0,1.0,[1.0,3.0,[],[0.015024983791169219,0.5404858350085282,0.4444891812003025]]]],"arguments":{},"schema":[{"type":"double","name":"label"},{"type":"double","name":"prediction"},{"type":"struct<type:tinyint,size:int,indices:array<int>,values:array<double>>","name":"probability"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.443123937547E12,"submitTime":1.443123937345E12,"finishTime":1.443123937754E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"0a95885e-df52-4ff2-b458-f4c175edaddc"},{"version":"CommandV1","origId":2602,"guid":"f3d07c5e-9295-49a5-816d-5db461e2c856","subtype":"command","commandType":"auto","position":9.125,"command":"%md\n#### Model Evaluation\n\nTo evaluate our model, we will be making use of the Evaluator in MulticlassClassification. Note that f1-score is the default metric for the MulticlassClassificationEvaluator.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"e63ed6ac-2987-435f-a66d-8d122d316272"},{"version":"CommandV1","origId":2603,"guid":"4fdcdddb-c614-404e-83f0-a80cff12e8ea","subtype":"command","commandType":"auto","position":9.1875,"command":"from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n                                              metricName=\"precision\")\naccuracy = evaluator.evaluate(predictions)\nprint \"Model Accuracy: \", accuracy","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Model Accuracy:  0.777777777778\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.443123940725E12,"submitTime":1.443123940638E12,"finishTime":1.443123941257E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"05b0e508-ef52-409c-a1be-8eda17cb6512"},{"version":"CommandV1","origId":2604,"guid":"65ea993b-0ee9-4e24-820f-c124e433644c","subtype":"command","commandType":"auto","position":9.203125,"command":"%md\nThe Evaluator is able to use a few metrics such as f1-score, precision, recall, weightedPrecision and weightedRecall.\n\nevaluator.setMetricName(\"insert_metric_here\") can be used to change the metric used to evaluate models.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"34048eaa-1861-4791-b682-67c995b5f6ed"},{"version":"CommandV1","origId":2605,"guid":"d766e366-8331-4292-9ad8-e1e5eb774ec2","subtype":"command","commandType":"auto","position":9.21875,"command":"evaluator.explainParam(\"metricName\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">54</span><span class=\"ansired\">]: </span>&apos;metricName: metric name in evaluation (f1|precision|recall|weightedPrecision|weightedRecall) (default: f1, current: precision)&apos;\n</div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;metricName&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-28-0f11490bc3b9&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>evaluator<span class=\"ansiyellow\">.</span>explainParam<span class=\"ansiyellow\">(</span>metricName<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;metricName&apos; is not defined\n</div>","startTime":1.443126184483E12,"submitTime":1.443126184405E12,"finishTime":1.443126184517E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"b2cd3bb1-47f2-4d31-9b68-7f3585e1eda0"},{"version":"CommandV1","origId":2606,"guid":"4708af47-b024-4ba8-83ad-1240d9191b7c","subtype":"command","commandType":"auto","position":9.234375,"command":"%md\nWe can also generate a Confusion Matrix to see the results of the predictions better. ConfusionMatrix() works only with RDDs, so we will have to convert our DataFrame of (prediction, label) into a RDD.\n\nconfusionMatrix() returns a DenseMatrix with the columns representing the predicted class ordered by ascending class label, and each row represents the actual class ordered by ascending class label. The diagonal from top left to bottom right represents the observations that were predicted correctly. \n\nFrom the above confusion matrix, we observe that all Setosas (class 0) and Versicolors (class 1) have been classified correctly, but there are 10 Virginicas (class 2) that have been wrongly classified as Versicolors.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"2263df7d-158a-4cfe-8134-46a75693696f"},{"version":"CommandV1","origId":2607,"guid":"3ad1e4c2-08d4-4d3d-8857-f0dd8dd5213c","subtype":"command","commandType":"auto","position":9.25,"command":"from pyspark.mllib.evaluation import MulticlassMetrics\n# Create (prediction, label) pairs\npredictionAndLabel = predictions.select(\"prediction\", \"label\").rdd\n\n# Generate confusion matrix\nmetrics = MulticlassMetrics(predictionAndLabel)\nprint metrics.confusionMatrix()\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">DenseMatrix([[ 13.,   0.,   0.],\n             [  0.,  14.,   0.],\n             [  0.,  10.,   8.]])\n</div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">AttributeError</span>: &apos;DataFrame&apos; object has no attribute &apos;ctx&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-30-b4a47156cad8&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansired\"># Generate confusion matrix</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 6</span><span class=\"ansiyellow\"> </span>metrics <span class=\"ansiyellow\">=</span> MulticlassMetrics<span class=\"ansiyellow\">(</span>predictionAndLabel<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      7</span> <span class=\"ansigreen\">print</span> metrics<span class=\"ansiyellow\">.</span>confusionMatrix<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/mllib/evaluation.py</span> in <span class=\"ansicyan\">__init__</span><span class=\"ansiblue\">(self, predictionAndLabels)</span>\n<span class=\"ansigreen\">    182</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    183</span>     <span class=\"ansigreen\">def</span> __init__<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> predictionAndLabels<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 184</span><span class=\"ansiyellow\">         </span>sc <span class=\"ansiyellow\">=</span> predictionAndLabels<span class=\"ansiyellow\">.</span>ctx<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    185</span>         sql_ctx <span class=\"ansiyellow\">=</span> SQLContext<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    186</span>         df = sql_ctx.createDataFrame(predictionAndLabels, schema=StructType([\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/dataframe.pyc</span> in <span class=\"ansicyan\">__getattr__</span><span class=\"ansiblue\">(self, name)</span>\n<span class=\"ansigreen\">    744</span>         <span class=\"ansigreen\">if</span> name <span class=\"ansigreen\">not</span> <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>columns<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    745</span>             raise AttributeError(\n<span class=\"ansigreen\">--&gt; 746</span><span class=\"ansiyellow\">                 &quot;&apos;%s&apos; object has no attribute &apos;%s&apos;&quot; % (self.__class__.__name__, name))\n</span><span class=\"ansigreen\">    747</span>         jc <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>apply<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    748</span>         <span class=\"ansigreen\">return</span> Column<span class=\"ansiyellow\">(</span>jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;DataFrame&apos; object has no attribute &apos;ctx&apos;\n</div>","startTime":1.44312394617E12,"submitTime":1.4431239461E12,"finishTime":1.44312394665E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"ac3848e4-b108-4ed1-bdb9-ded2437cfd2e"},{"version":"CommandV1","origId":2608,"guid":"22bdf82f-893f-4a33-a65d-e7c86d623b24","subtype":"command","commandType":"auto","position":10.0,"command":"%md\n####Experimenting with Various Smoothing Parameters\n\nWe can experiment with various smoothing parameters to see which returns the best result. This is easily done with the ParamGridBuilder and CrossValidator.\n\nAs we indicate 6 values for the smoothing parameter, this grid will provide 6 parameter settings for CrossValidator to model, evaluate and choose from.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"d4d1b227-dd94-4f3f-8ba7-9cd8680a278e"},{"version":"CommandV1","origId":2609,"guid":"5bc2f3d8-b224-4793-b8f2-1dae7c35d3bd","subtype":"command","commandType":"auto","position":10.5,"command":"from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid and Evaluator for Cross Validation\nparamGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).build()\ncvEvaluator = MulticlassClassificationEvaluator(metricName=\"precision\")\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;nb&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-1-7c5d04ea36b3&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansired\"># Create ParamGrid and Evaluator for Cross Validation</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\"> </span>paramGrid <span class=\"ansiyellow\">=</span> ParamGridBuilder<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>addGrid<span class=\"ansiyellow\">(</span>nb<span class=\"ansiyellow\">.</span>smoothing<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0.0</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.2</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.4</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.6</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">0.8</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1.0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>build<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> cvEvaluator <span class=\"ansiyellow\">=</span> MulticlassClassificationEvaluator<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;nb&apos; is not defined\n</div>","startTime":1.443123948659E12,"submitTime":1.443123948556E12,"finishTime":1.443123948693E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"c24608df-845a-4689-b561-a2738d0945e8"},{"version":"CommandV1","origId":2610,"guid":"5d327e13-0d6c-4968-ae62-d4169a332f2c","subtype":"command","commandType":"auto","position":10.75,"command":"# Run Cross-validation\ncv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=cvEvaluator)\ncvModel = cv.fit(trainingData)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":"<span class=\"ansired\">IllegalArgumentException</span>: Field &quot;features&quot; does not exist.","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">IllegalArgumentException</span>                  Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-26-1664d8cd4e2c&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Run Cross-validation</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> cv <span class=\"ansiyellow\">=</span> CrossValidator<span class=\"ansiyellow\">(</span>estimator<span class=\"ansiyellow\">=</span>nb<span class=\"ansiyellow\">,</span> estimatorParamMaps<span class=\"ansiyellow\">=</span>paramGrid<span class=\"ansiyellow\">,</span> evaluator<span class=\"ansiyellow\">=</span>cvEvaluator<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>cvModel <span class=\"ansiyellow\">=</span> cv<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>trainingData<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/pipeline.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">     63</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 65</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     66</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     67</span>             raise ValueError(&quot;Params must be either a param map or a list/tuple of param maps, &quot;\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/tuning.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    220</span>             train <span class=\"ansiyellow\">=</span> df<span class=\"ansiyellow\">.</span>filter<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">~</span>condition<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    221</span>             <span class=\"ansigreen\">for</span> j <span class=\"ansigreen\">in</span> range<span class=\"ansiyellow\">(</span>numModels<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 222</span><span class=\"ansiyellow\">                 </span>model <span class=\"ansiyellow\">=</span> est<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>train<span class=\"ansiyellow\">,</span> epm<span class=\"ansiyellow\">[</span>j<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    223</span>                 <span class=\"ansired\"># TODO: duplicate evaluator to take extra params from input</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    224</span>                 metric <span class=\"ansiyellow\">=</span> eva<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>validation<span class=\"ansiyellow\">,</span> epm<span class=\"ansiyellow\">[</span>j<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/pipeline.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">     61</span>         <span class=\"ansigreen\">elif</span> isinstance<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">,</span> dict<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>             <span class=\"ansigreen\">if</span> params<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    130</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 132</span><span class=\"ansiyellow\">         </span>java_model <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_fit_java<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    133</span>         <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_create_model<span class=\"ansiyellow\">(</span>java_model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    134</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit_java</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    127</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    128</span>         self<span class=\"ansiyellow\">.</span>_transfer_params_to_java<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 129</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    130</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">    536</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    537</span>         return_value = get_return_value(answer, self.gateway_client,\n<span class=\"ansigreen\">--&gt; 538</span><span class=\"ansiyellow\">                 self.target_id, self.name)\n</span><span class=\"ansigreen\">    539</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    540</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     40</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     41</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;java.lang.IllegalArgumentException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 42</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> IllegalArgumentException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     43</span>             <span class=\"ansigreen\">raise</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     44</span>     <span class=\"ansigreen\">return</span> deco<span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">IllegalArgumentException</span>: Field &quot;features&quot; does not exist.\n</div>","startTime":1.443123983676E12,"submitTime":1.443123983525E12,"finishTime":1.443123990945E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"f8bac4b4-fc84-44bc-8ca1-c5eeaa2093f9"},{"version":"CommandV1","origId":2611,"guid":"51c88d60-0cd9-48ba-a09b-4a23774894e8","subtype":"command","commandType":"auto","position":10.8125,"command":"# Make predictions on testData. cvModel uses the bestModel.\ncvPredictions = cvModel.transform(testData)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.443124145271E12,"submitTime":1.443124144967E12,"finishTime":1.443124145402E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"09af1df9-b470-434e-bd14-359e4b49760e"},{"version":"CommandV1","origId":2612,"guid":"aca62009-5fcf-4179-bf61-71e902bca713","subtype":"command","commandType":"auto","position":10.875,"command":"# Select results to view\ndisplay(cvPredictions.select(\"label\", \"prediction\", \"probability\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[[0.0,0.0,[1.0,3.0,[],[0.6868393627381153,0.12711603989450915,0.18604459736737544]]],[0.0,0.0,[1.0,3.0,[],[0.6684618917037279,0.1367490168001194,0.19478909149615276]]],[0.0,0.0,[1.0,3.0,[],[0.7875597122960215,0.08012095110789415,0.13231933659608427]]],[0.0,0.0,[1.0,3.0,[],[0.7170920784652458,0.11238091221679915,0.17052700931795503]]],[0.0,0.0,[1.0,3.0,[],[0.7534049144251885,0.09881333146706438,0.14778175410774708]]],[0.0,0.0,[1.0,3.0,[],[0.7632071507845822,0.09161960202581933,0.14517324718959843]]],[0.0,0.0,[1.0,3.0,[],[0.605623223895539,0.16308140017074693,0.23129537593371416]]],[0.0,0.0,[1.0,3.0,[],[0.6673491236451113,0.13395633715183927,0.19869453920304947]]],[0.0,0.0,[1.0,3.0,[],[0.6874881735714546,0.1261172937003672,0.18639453272817813]]],[0.0,0.0,[1.0,3.0,[],[0.8392295772776714,0.05895781753542414,0.1018126051869044]]],[0.0,0.0,[1.0,3.0,[],[0.6997285467177663,0.12007440288626367,0.1801970503959701]]],[0.0,0.0,[1.0,3.0,[],[0.5726717594799834,0.18285896156122008,0.2444692789587965]]],[0.0,0.0,[1.0,3.0,[],[0.7437380193503028,0.10039641293099905,0.155865567718698]]],[2.0,2.0,[1.0,3.0,[],[0.053633744131344856,0.4628720530665372,0.48349420280211797]]],[2.0,1.0,[1.0,3.0,[],[0.04823014653226181,0.4798578466899952,0.471912006777743]]],[2.0,1.0,[1.0,3.0,[],[0.04535737540937939,0.49741494005477904,0.4572276845358416]]],[2.0,2.0,[1.0,3.0,[],[0.08785131783272965,0.4541542069509349,0.4579944752163353]]],[2.0,1.0,[1.0,3.0,[],[0.036438077436838474,0.5062107583900328,0.4573511641731287]]],[2.0,1.0,[1.0,3.0,[],[0.022824263329112304,0.526918146189768,0.45025759048111985]]],[2.0,2.0,[1.0,3.0,[],[0.06839767459306285,0.4632737905999316,0.46832853480700565]]],[2.0,1.0,[1.0,3.0,[],[0.022945365173280333,0.5174042724184489,0.4596503624082708]]],[2.0,2.0,[1.0,3.0,[],[0.06162658044536087,0.4639888049614414,0.4743846145931976]]],[2.0,2.0,[1.0,3.0,[],[0.11964484509576968,0.4240330103846083,0.45632214451962216]]],[2.0,1.0,[1.0,3.0,[],[0.018097565364416375,0.531587893142125,0.45031454149345856]]],[2.0,1.0,[1.0,3.0,[],[0.0436504541626871,0.49190634848468434,0.46444319735262857]]],[2.0,1.0,[1.0,3.0,[],[0.05102148922592954,0.490200445374273,0.4587780653997973]]],[2.0,2.0,[1.0,3.0,[],[0.10249942300855021,0.44805468533114284,0.4494458916603069]]],[2.0,1.0,[1.0,3.0,[],[0.05039804293825467,0.48787004569347603,0.4617319113682694]]],[2.0,2.0,[1.0,3.0,[],[0.0700214503079957,0.46368220712242536,0.4662963425695789]]],[2.0,1.0,[1.0,3.0,[],[0.05778468845655409,0.47787187925738756,0.46434343228605834]]],[2.0,2.0,[1.0,3.0,[],[0.05924322852522969,0.46909525447342926,0.4716615170013411]]],[1.0,1.0,[1.0,3.0,[],[0.01109729151489298,0.5465373989397894,0.4423653095453177]]],[1.0,1.0,[1.0,3.0,[],[0.005922408526249183,0.5715993013220414,0.4224782901517094]]],[1.0,1.0,[1.0,3.0,[],[0.004612701517668427,0.5585413929920833,0.43684590549024827]]],[1.0,1.0,[1.0,3.0,[],[0.010985898369257214,0.5495902511146449,0.4394238505160978]]],[1.0,1.0,[1.0,3.0,[],[0.009166870919037538,0.5698449062221548,0.4209882228588076]]],[1.0,1.0,[1.0,3.0,[],[0.0166209924181674,0.5353313499019962,0.4480476576798365]]],[1.0,1.0,[1.0,3.0,[],[0.004445516039411959,0.5566442569540518,0.43891022700653615]]],[1.0,1.0,[1.0,3.0,[],[0.009294829933082028,0.5510123475961775,0.43969282247074054]]],[1.0,1.0,[1.0,3.0,[],[0.006926114532812348,0.5675823543554729,0.42549153111171484]]],[1.0,1.0,[1.0,3.0,[],[0.013853966616770394,0.5367281796392049,0.44941785374402476]]],[1.0,1.0,[1.0,3.0,[],[0.0057686558867658345,0.574072321799472,0.42015902231376223]]],[1.0,1.0,[1.0,3.0,[],[0.005719688672959502,0.5692540023459688,0.42502630898107163]]],[1.0,1.0,[1.0,3.0,[],[0.008581148821612334,0.5611190194436501,0.43029983173473757]]],[1.0,1.0,[1.0,3.0,[],[0.012643326325544033,0.544378784548863,0.44297788912559294]]]],"arguments":{},"schema":[{"type":"double","name":"label"},{"type":"double","name":"prediction"},{"type":"struct<type:tinyint,size:int,indices:array<int>,values:array<double>>","name":"probability"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.443124173733E12,"submitTime":1.443124173666E12,"finishTime":1.443124173956E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"4a5f9010-ffac-4594-88bd-15b9d0ad58a9"},{"version":"CommandV1","origId":2613,"guid":"9e491b71-9bef-4da8-9644-ae32d1f2d986","subtype":"command","commandType":"auto","position":10.9375,"command":"# Evaluate bestModel found from Cross Validation\nevaluator.evaluate(cvPredictions)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">30</span><span class=\"ansired\">]: </span>0.7777777777777778\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.44312422411E12,"submitTime":1.443124224006E12,"finishTime":1.443124224355E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"raela@databricks.com","iPythonMetadata":null,"nuid":"99fc7a01-416e-4f5a-86c5-4def659f3d96"},{"version":"CommandV1","origId":2614,"guid":"5a4085ae-41f9-48d1-89e3-b1501e3a6f89","subtype":"command","commandType":"auto","position":12.0,"command":"%md\nTurns out that smoothing has no effect on this dataset!","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"85adec6e-58d0-4063-aea4-0297f28d5d68"}],"guid":"6f9bb0c2-59f6-4504-a7d2-cca20114c577","globalVars":{},"iPythonMetadata":null};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":-1,"guid":"e096d6a7-3c7f-4c59-ad13-5eeba4fa82ca","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](../../index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>