<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Sample Applications / Wikipedia / Parse XML in Python - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/img/favicon.ico"/>
<script>window.settings = {"sparkDocsSearchGoogleCx":"004588677886978090460:_rj0wilqwdm","dbcForumURL":"http://forums.databricks.com/","dbfsS3Host":"https://databricks-prod-storage-oregon.s3.amazonaws.com","enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"isAdmin":false,"enablePresentationTimerConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"clusters":false,"hideOffHeapCache":false,"applications":false,"useStaticGuide":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"sparkVersions":[{"key":"1.3.x","displayName":"Spark 1.3.0","packageLabel":"spark-1.3-jenkins-ip-10-2-0-138-U094163cf51-S47b89c350f-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.4.x","displayName":"Spark 1.4.1","packageLabel":"spark-1.4-jenkins-ip-10-2-0-138-U094163cf51-S2f95f6c227-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x","displayName":"Spark 1.6 Branch Preview","packageLabel":"spark-1.6-jenkins-ip-10-2-0-138-U094163cf51-S3436f2ea50-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.8.1","local":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":false,"enableStaticNotebooks":true,"dbcGuideURL":"#workspace/databricks_guide/00 Welcome to Databricks","enableClusterAclsConfig":false,"orgId":0,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":false,"driverLog4jFilePrefix":"log4j","enableMavenLibraries":true,"defaultSparkVersion":{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},"clusterPublisherRootId":5,"enableLatestJobRunResultPermalink":true,"enableSparkConfUI":true,"enableJdbcImport":true,"logfiles":"logfiles/","enableClusterDeltaUpdates":true,"csrfToken":"d3dde7ae-fd45-4989-86b8-e91415a5ebcf","useFixedStaticNotebookVersionForDevelopment":false,"enableBasicReactDialogBoxes":true,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableWorkspaceAclService":true,"enableWorkspaceAcls":true,"gitHash":"094163cf51fcd4717c3ea96799d1008723ae8985","userFullname":"Suresh Jayaram","enableImportFromUrl":true,"enableMiniClusters":false,"enableWebSocketDeltaUpdates":true,"enableDebugUI":false,"showHiddenSparkVersions":false,"allowNonAdminUsers":true,"userId":100017,"dbcSupportURL":"","staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/","enableSparkPackages":true,"enableNotebookHistoryUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"databricksGuideStaticUrl":"","notebookLoadingBackground":"#fff","enableNewJobRunDetailsPage":true,"enableDashboardExport":true,"user":"surjayaram@paypal.com","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"tablesPublisherRootId":7,"accounts":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":3495,"name":"Sample Applications / Wikipedia / Parse XML in Python","language":"python","commands":[{"version":"CommandV1","origId":3496,"guid":"fc4d4d44-9089-41f2-a3ae-9fd6150c5c86","subtype":"command","commandType":"auto","position":1.0,"command":"%md\n\n# **Create Wikipedia Table**\nUse Python to parse the wikipedia files and register a Spark SQL table.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.426530468944E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"5a901c39-7844-414e-a881-8fc8c116ba61"},{"version":"CommandV1","origId":3497,"guid":"eec7a03d-2ce2-4272-8db4-7dae6130d51e","subtype":"command","commandType":"auto","position":1.5,"command":"%md ### **Optional:** If you haven't mounted your S3 Bucket to DBFS, do so now.\nSearch for the \"DBFS in Python\" Notebook for more details. ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.426530562115E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"88ba506d-8214-477e-8839-3cdce54f4d3c"},{"version":"CommandV1","origId":3498,"guid":"6f3f9ca4-3553-484c-9b56-43527318e9f5","subtype":"command","commandType":"auto","position":1.75,"command":"# dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % YOUR_MOUNT_NAME)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989747795E12,"submitTime":1.431989747749E12,"finishTime":1.431989747838E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"95b35da1-a63a-4769-917e-c2cb3761ba10"},{"version":"CommandV1","origId":3499,"guid":"82c1daf0-bbe5-4a54-b2e4-11fbf68d09e7","subtype":"command","commandType":"auto","position":2.0,"command":"%md ### **Step 1:** Configure with the path where you stored the wikipedia files.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.426530479401E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"cc46c9ec-1fa3-4165-ba81-0a7e8101022c"},{"version":"CommandV1","origId":3500,"guid":"461aaed8-77a6-460d-8a9c-a34a97719a94","subtype":"command","commandType":"auto","position":3.0,"command":"DBFS_MOUNT_NAME = getArgument(\"1. YOUR_DBFS_MOUNT_NAME\", \"YOUR_MOUNT_NAME\")\nWIKIPEDIA_FOLDER =  getArgument(\"2. FOLDER_FOR_YOUR_WIKIPEDIA_FILES\", \"YOUR_WIKIPEDIA_FOLDER\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{"2. FOLDER_FOR_YOUR_WIKIPEDIA_FILES":"YOUR_WIKIPEDIA_FOLDER","1. YOUR_DBFS_MOUNT_NAME":"YOUR_MOUNT_NAME"},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431988884897E12,"submitTime":1.431988884851E12,"finishTime":1.431988884939E12,"collapsed":false,"bindings":{"2. FOLDER_FOR_YOUR_WIKIPEDIA_FILES":"YOUR_WIKIPEDIA_FOLDER","1. YOUR_DBFS_MOUNT_NAME":"YOUR_MOUNT_NAME"},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"f58368ec-e950-4be6-b494-18d185f4cb84"},{"version":"CommandV1","origId":3501,"guid":"a9c0ef84-95fb-41bc-b12a-9ea75377a778","subtype":"command","commandType":"auto","position":4.0,"command":"%md ### **Step 2:** Create a function to parse the XML into a PySpark Row.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.426530483263E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"fadfdd97-4d8d-4c52-bde0-4fdb4824b2cb"},{"version":"CommandV1","origId":3502,"guid":"c3071be7-ca03-4f99-8296-e8e052869737","subtype":"command","commandType":"auto","position":5.0,"command":"import xml.etree.ElementTree as ET\nfrom pyspark.sql import Row\n\ndef parse_xml_to_row(xmlString):\n  root = ET.fromstring(xmlString.encode('utf-8'))\n   \n  dict = {\"title\": None, \"redirect_title\": None, \"timestamp\": None, \"last_contributor_username\": None, \"text\": None}\n  title = root.find(\"title\")\n  if title is not None:\n    dict[\"title\"] = title.text\n  redirect = root.find(\"redirect\")\n  if redirect is not None:\n    dict[\"redirect_title\"] = redirect.attrib[\"title\"]\n  revision = root.find(\"revision\")\n  if revision is not None:\n    timestamp = revision.find(\"timestamp\")\n    dict[\"timestamp\"] = timestamp.text\n    contributor = revision.find(\"contributor\")\n    if contributor is not None:\n      username = contributor.find(\"username\")\n      if username is not None:\n        dict[\"last_contributor_username\"] = username.text\n    text = revision.find(\"text\")\n    if text is not None and text.text is not None:\n      dict[\"text\"] = text.text.replace(\"\\\\n\", \" \")\n  \n  return Row(**dict)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989761175E12,"submitTime":1.431989761112E12,"finishTime":1.431989761218E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"f7fd6a34-2533-45ff-a558-63339294bf12"},{"version":"CommandV1","origId":3503,"guid":"2ad96a65-3fe2-49c4-9399-e97cef997417","subtype":"command","commandType":"auto","position":6.0,"command":"%md ### **Step 3:** Create a dataFrame from the xml files.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.43198976227E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"7d7f9677-7d9d-4804-822a-ee5129d49d81"},{"version":"CommandV1","origId":3504,"guid":"020a3db8-7f33-4a4b-96b0-6100cec22c6c","subtype":"command","commandType":"auto","position":7.0,"command":"row_rdd = sc.textFile(\n  \"dbfs:/mnt/%s/%s/enwiki-latest-pages-articles*.xml*.bz2-part-*\" % (DBFS_MOUNT_NAME, WIKIPEDIA_FOLDER)).map(parse_xml_to_row)\nwikipedia_df = sqlContext.createDataFrame(row_rdd)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-16-fbbc1f72fc75&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> row_rdd = sc.textFile(\n<span class=\"ansigreen\">      2</span>   &quot;dbfs:/mnt/%s/%s/enwiki-latest-pages-articles*.xml*.bz2-part-*&quot; % (DBFS_MOUNT_NAME, WIKIPEDIA_FOLDER)).map(parse_xml_to_row)\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>wikipedia_df <span class=\"ansiyellow\">=</span> sqlContext<span class=\"ansiyellow\">.</span>createDataFrame<span class=\"ansiyellow\">(</span>row_rdd<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.pyc</span> in <span class=\"ansicyan\">createDataFrame</span><span class=\"ansiblue\">(self, data, schema, samplingRatio)</span>\n<span class=\"ansigreen\">    282</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    283</span>         <span class=\"ansigreen\">if</span> schema <span class=\"ansigreen\">is</span> None<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 284</span><span class=\"ansiyellow\">             </span>schema <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_inferSchema<span class=\"ansiyellow\">(</span>rdd<span class=\"ansiyellow\">,</span> samplingRatio<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    285</span>             converter <span class=\"ansiyellow\">=</span> _create_converter<span class=\"ansiyellow\">(</span>schema<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    286</span>             rdd <span class=\"ansiyellow\">=</span> rdd<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>converter<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.pyc</span> in <span class=\"ansicyan\">_inferSchema</span><span class=\"ansiblue\">(self, rdd, samplingRatio)</span>\n<span class=\"ansigreen\">    162</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    163</span>     <span class=\"ansigreen\">def</span> _inferSchema<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> rdd<span class=\"ansiyellow\">,</span> samplingRatio<span class=\"ansiyellow\">=</span>None<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 164</span><span class=\"ansiyellow\">         </span>first <span class=\"ansiyellow\">=</span> rdd<span class=\"ansiyellow\">.</span>first<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    165</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> first<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    166</span>             raise ValueError(&quot;The first row in RDD is empty, &quot;\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc</span> in <span class=\"ansicyan\">first</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">   1240</span>         ValueError<span class=\"ansiyellow\">:</span> RDD <span class=\"ansigreen\">is</span> empty<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1241</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">-&gt; 1242</span><span class=\"ansiyellow\">         </span>rs <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>take<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1243</span>         <span class=\"ansigreen\">if</span> rs<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1244</span>             <span class=\"ansigreen\">return</span> rs<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc</span> in <span class=\"ansicyan\">take</span><span class=\"ansiblue\">(self, num)</span>\n<span class=\"ansigreen\">   1192</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">   1193</span>         items <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1194</span><span class=\"ansiyellow\">         </span>totalParts <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>getNumPartitions<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1195</span>         partsScanned <span class=\"ansiyellow\">=</span> <span class=\"ansicyan\">0</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1196</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc</span> in <span class=\"ansicyan\">getNumPartitions</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">   2265</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   2266</span>     <span class=\"ansigreen\">def</span> getNumPartitions<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 2267</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_prev_jrdd<span class=\"ansiyellow\">.</span>partitions<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>size<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   2268</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   2269</span>     <span class=\"ansiyellow\">@</span>property<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">    536</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    537</span>         return_value = get_return_value(answer, self.gateway_client,\n<span class=\"ansigreen\">--&gt; 538</span><span class=\"ansiyellow\">                 self.target_id, self.name)\n</span><span class=\"ansigreen\">    539</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    540</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    298</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    299</span>                     <span class=\"ansiblue\">&apos;An error occurred while calling {0}{1}{2}.\\n&apos;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 300</span><span class=\"ansiyellow\">                     format(target_id, &apos;.&apos;, name), value)\n</span><span class=\"ansigreen\">    301</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    302</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o476.partitions.\n: java.io.FileNotFoundException: /mnt/YOUR_MOUNT_NAME/YOUR_WIKIPEDIA_FOLDER\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:52)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:39)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:179)\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:862)\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:922)\n\tat org.apache.hadoop.fs.FileSystem.globStatusInternal(FileSystem.java:1052)\n\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1007)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:177)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:208)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:203)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:217)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:32)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:217)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:64)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:46)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n\n</div>","startTime":1.431989800314E12,"submitTime":1.431989800262E12,"finishTime":1.431989801826E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"893f6650-3f78-469e-a0f0-0b7f7830dee9"},{"version":"CommandV1","origId":3505,"guid":"7ed7083c-8e00-4815-b746-3161e2eaf596","subtype":"command","commandType":"auto","position":8.0,"command":"%md \n\n### **Step 4:** Load into a SQL table \n\nThis will save the table as parquet format which is recommended for querying from Spark SQL.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.431989803839E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"8bd1f8a3-abe5-44cf-a0ab-c4edb825ba02"},{"version":"CommandV1","origId":3506,"guid":"0c6c8216-4454-4667-afb3-b01f144f738f","subtype":"command","commandType":"auto","position":9.0,"command":"%sql DROP TABLE IF EXISTS wikipedia","commandVersion":0,"state":"finished","results":{"type":"table","data":[],"arguments":{},"schema":[],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.431989991657E12,"submitTime":1.431989991617E12,"finishTime":1.431989993119E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"74ae6190-5126-4c3c-bab7-f284e4a5ab6e"},{"version":"CommandV1","origId":3507,"guid":"cc4ae345-7600-4d1b-be53-c5c40e37846a","subtype":"command","commandType":"auto","position":9.5,"command":"wikipedia_df.saveAsTable(\"wikipedia\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"0aa126b9-a308-4ba7-b050-0f342cfcf607"},{"version":"CommandV1","origId":3508,"guid":"ddda05b9-bcfd-4264-ae80-cd52e4e63839","subtype":"script","commandType":"auto","position":10.321428571428571,"command":"%md\n\n# **Parquet Files in Python**\nThis notebook describes how to register a table in Spark SQL from parquet files.","commandVersion":0,"state":"finished","results":{"type":"markdown","data":"# **Parquet Files in Python**\nThis notebook describes how to register a table in Spark SQL from parquet files.","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989359571E12,"submitTime":1.427390718515E12,"finishTime":1.431989359577E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"8d91d673-1a5b-4303-aa60-7b26b671e34e"},{"version":"CommandV1","origId":3509,"guid":"02f8b006-1346-4b98-9ca8-b07502d9eabc","subtype":"script","commandType":"auto","position":10.392857142857142,"command":"%md\n\n### **Parquet Files** are a great format for storing large tables in SparkSQL.\n* Consider converting text files with a schema into parquet files for more efficient storage.\n* Just call .saveAsParquetFile on a DataFrame to encode in into Parquet.","commandVersion":0,"state":"finished","results":{"type":"markdown","data":"### **Parquet Files** are a great format for storing large tables in SparkSQL.\n* Consider converting text files with a schema into parquet files for more efficient storage.\n* Just call .saveAsParquetFile on a DataFrame to encode in into Parquet.","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989359584E12,"submitTime":1.427390718534E12,"finishTime":1.431989359589E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"cd6908b0-602e-4a07-8595-82fbcf33a26e"},{"version":"CommandV1","origId":3510,"guid":"2103c7c1-e1c5-41a1-a2f0-6bbcd85f36b0","subtype":"script","commandType":"auto","position":10.464285714285714,"command":"%md \n\n### **Setup:** Write some test parquet files that can be read in. ","commandVersion":0,"state":"finished","results":{"type":"markdown","data":"### **Setup:** Write some test parquet files that can be read in.","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989359594E12,"submitTime":1.427390718553E12,"finishTime":1.431989359601E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"4c79ef04-7813-40a6-b74e-420dad35cad0"},{"version":"CommandV1","origId":3511,"guid":"4ac940e6-17c2-416b-a3dd-6366b6e165ab","subtype":"script","commandType":"auto","position":10.535714285714286,"command":"from pyspark.sql import Row\n\narray = [Row(key=\"a\", group=\"vowels\", value=1, someints=[1], map = {\"a\" : 1}),\n         Row(key=\"b\", group=\"consonants\", value=2, someints=[2, 2], map = {\"b\" : 2}),\n         Row(key=\"c\", group=\"consonants\", value=3, someints=[3, 3, 3], map = {\"c\" : 3}),\n         Row(key=\"d\", group=\"consonants\", value=4, someints=[4, 4, 4, 4], map = {\"d\" : 4}),\n         Row(key=\"e\", group=\"vowels\", value=5, someints=[5, 5, 5, 5, 5], map = {\"3\" : 5})]\ndataframe = sqlContext.createDataFrame(sc.parallelize(array))\ntry:\n  dataframe.saveAsParquetFile(\"/tmp/testParquetFiles\")\nexcept:\n  # Ignore - this is because the files already exist.\n  pass","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989359606E12,"submitTime":1.427390718569E12,"finishTime":1.431989363537E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"df8ff7af-026b-4e05-9ae0-907ecef19254"},{"version":"CommandV1","origId":3512,"guid":"9e0879e4-7e27-4c2d-b5ce-321fc7a9ba1d","subtype":"script","commandType":"auto","position":10.607142857142858,"command":"%md\n\n### **Registering a Temp Table from parquet files**\n* Taking Parquet files and registering them as a temp table is super easy in Spark SQL.","commandVersion":0,"state":"finished","results":{"type":"markdown","data":"### **Registering a Temp Table from parquet files**\n* Taking Parquet files and registering them as a temp table is super easy in Spark SQL.","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989363543E12,"submitTime":1.427390718586E12,"finishTime":1.431989363549E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"c8ba1c19-9ec5-4222-b9ab-b47ea8c65dcb"},{"version":"CommandV1","origId":3513,"guid":"bf11c48a-e1a5-499e-97fa-39c661e69587","subtype":"script","commandType":"auto","position":10.678571428571429,"command":"dataframeFromParquet = sqlContext.parquetFile(\"/tmp/testParquetFiles\")  \ndataframeFromParquet.registerTempTable(\"parquetTable1\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989363554E12,"submitTime":1.427390718607E12,"finishTime":1.431989364567E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"5aace7f8-629d-4d25-9990-4a766d392b65"},{"version":"CommandV1","origId":3514,"guid":"88b51206-e7dc-42a8-be1a-326ca07b4b91","subtype":"script","commandType":"auto","position":10.75,"command":"%sql select * from parquetTable1","commandVersion":0,"state":"finished","results":{"type":"table","data":[["d","consonants",4.0,[4.0,4.0,4.0,4.0],{"d":4.0}],["e","vowels",5.0,[5.0,5.0,5.0,5.0,5.0],{"e":5.0}],["a","vowels",1.0,[1.0],{"a":1.0}],["b","consonants",2.0,[2.0,2.0],{"b":2.0}],["c","consonants",3.0,[3.0,3.0,3.0],{"c":3.0}]],"arguments":{},"schema":[{"type":"string","name":"key"},{"type":"string","name":"group"},{"type":"int","name":"value"},{"type":"array<int>","name":"someints"},{"type":"map<string,int>","name":"somemap"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.431989364573E12,"submitTime":1.427390718623E12,"finishTime":1.431989368494E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"85f3b0e3-22aa-4931-a5ae-6639fbecd754"},{"version":"CommandV1","origId":3515,"guid":"31b67014-7ada-4121-bcea-1fb9fd47ab49","subtype":"script","commandType":"auto","position":10.821428571428571,"command":"%md\n\n### **Registering a Permanent Table from parquet files**\n* To register a permanent table from parquet files, use a **CREATE EXTERNAL TABLE** command that points to the files.","commandVersion":0,"state":"finished","results":{"type":"markdown","data":"### **Registering a Permanent Table from parquet files**\n* To register a permanent table from parquet files, use a **CREATE EXTERNAL TABLE** command that points to the files.","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989368629E12,"submitTime":1.427390718643E12,"finishTime":1.431989368634E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"e6f0cce1-6edf-493b-aff0-885a6ea3ee8d"},{"version":"CommandV1","origId":3516,"guid":"55c2adf3-b864-4e2e-9a7a-d0397f3051c2","subtype":"script","commandType":"auto","position":10.892857142857142,"command":"%md Here is a helper command to generate the **\"CREATE EXTERNAL TABLE\"** command from the table.","commandVersion":0,"state":"finished","results":{"type":"markdown","data":"Here is a helper command to generate the **\"CREATE EXTERNAL TABLE\"** command from the table.","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989368641E12,"submitTime":1.427390718657E12,"finishTime":1.431989368647E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"67865c89-e56e-4c43-840f-dad0c312246a"},{"version":"CommandV1","origId":3517,"guid":"4808ba8a-c651-49ed-b399-28b1bed68623","subtype":"script","commandType":"auto","position":10.964285714285714,"command":"SIMPLE_CATALYST_TO_HIVE_TYPES_DICT = {\n  \"StringType\" : \"string\",\n  \"FloatType\" : \"float\",\n  \"IntegerType\" : \"int\",\n  \"ByteType\" : \"tinyint\",\n  \"ShortType\" : \"smallint\",\n  \"DoubleType\" : \"double\",\n  \"LongType\" : \"bigint\",\n  \"BinaryType\" : \"binary\",\n  \"BooleanType\" : \"boolean\",\n  \"TimestampType\" : \"timestamp\"\n}\n\ndef toHiveMetastoreType(data_type):\n  data_type_str = str(data_type)\n  if SIMPLE_CATALYST_TO_HIVE_TYPES_DICT.has_key(data_type_str):\n    return SIMPLE_CATALYST_TO_HIVE_TYPES_DICT[data_type_str] \n  elif data_type_str.startswith(\"ArrayType\"):\n    return \"array<%s>\" % toHiveMetastoreType(data_type.elementType)\n  elif data_type_str.startswith(\"MapType\"):\n    return \"Map<%s,%s>\" % (toHiveMetastoreType(data_type.keyType), toHiveMetastoreType(data_type.valueType))\n  else:\n    raise Exception(\"Enhance this to support type: %s\" % data_type) \n# TODO: Support more complex types as here: \n# https://github.com/apache/spark/blob/51b1fe1426ffecac6c4644523633ea1562ff9a4e/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala\n# DecimalType\n# StructField\n\n# Missing from python:\n# Data Type, NullType, & UserDefinedType.\n\n# For now, you can use the Scala notebook to register your table.\n# If you cannot use Scala, please use the help portal if you have a complex or missing type to support.\n\ndef createParquetTable(name, file):\n  rdd = sqlContext.parquetFile(file)\n  schema = \"\"\n  for field in rdd.schema.fields:\n    schema += \"`%s` %s,\\n\" % (field.name, toHiveMetastoreType(field.dataType))\n  ddl = \"\"\"CREATE EXTERNAL TABLE `%s` (\n      %s\n    )\n    STORED AS PARQUET\n    LOCATION '%s'\"\"\" % (name, schema[:-2], file)\n  sqlContext.sql(ddl)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.431989368654E12,"submitTime":1.427390718671E12,"finishTime":1.431989368733E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"c7b7524d-f165-45a5-bea5-76ba32f88f67"},{"version":"CommandV1","origId":3518,"guid":"6f87572b-d0b6-42f4-bacb-918ec5cd2074","subtype":"command","commandType":"auto","position":11.0,"command":"%md ### **Step 5:** Optional: cache the table for faster lookups.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.426530508309E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"549c9d5e-9920-4543-98fa-7540905f1d96"},{"version":"CommandV1","origId":3519,"guid":"212937fe-c9bc-444f-8286-0e24e33c4330","subtype":"script","commandType":"auto","position":11.035714285714286,"command":"createParquetTable(\"parquetTable2\", \"/tmp/testParquetFiles\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.43198936874E12,"submitTime":1.42739071869E12,"finishTime":1.431989370051E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"d73a5fcc-c3cc-4dee-b5a7-c99e390b12b7"},{"version":"CommandV1","origId":3520,"guid":"5b3e0f01-375e-470e-8d51-da214f6546ee","subtype":"script","commandType":"auto","position":11.107142857142858,"command":"%sql select * from parquetTable2","commandVersion":0,"state":"finished","results":{"type":"table","data":[["d","consonants",4.0,null,{"d":4.0}],["e","vowels",5.0,null,{"e":5.0}],["a","vowels",1.0,null,{"a":1.0}],["b","consonants",2.0,null,{"b":2.0}],["c","consonants",3.0,null,{"c":3.0}]],"arguments":{},"schema":[{"type":"string","name":"key"},{"type":"string","name":"group"},{"type":"int","name":"value"},{"type":"array<int>","name":"someints"},{"type":"map<string,int>","name":"somemap"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.431989370058E12,"submitTime":1.427390718706E12,"finishTime":1.431989371931E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"ad8de118-dd7a-4d94-95ea-a6aa71baabbb"},{"version":"CommandV1","origId":3521,"guid":"4f69f678-b1e0-4839-9e89-f7ac7b8042b5","subtype":"script","commandType":"auto","position":11.178571428571429,"command":"%sql DROP TABLE IF EXISTS parquetTable2","commandVersion":0,"state":"finished","results":{"type":"table","data":[],"arguments":{},"schema":[],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.431989371938E12,"submitTime":1.427390718731E12,"finishTime":1.431989372276E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["ea09082f-d109-4fb8-9a10-4c759c2ec185"],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"9310d54b-1eb5-4c74-b6db-a85565c93f6d"},{"version":"CommandV1","origId":3522,"guid":"405e7dba-90c5-42ba-a791-90fc8af12157","subtype":"command","commandType":"auto","position":12.0,"command":"%sql CACHE TABLE wikipedia","commandVersion":0,"state":"finished","results":{"type":"table","data":[],"arguments":{},"schema":[],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":null,"plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.416354071492E12,"submitTime":1.416351681448E12,"finishTime":1.416354124756E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"67947e19-0c1d-4a60-a6ac-49be0fe10927"},{"version":"CommandV1","origId":3523,"guid":"31968b85-2c03-463f-9a3c-722a9202960c","subtype":"command","commandType":"auto","position":13.0,"command":"%md ### **Step 6:** Do some quick test queries against the wikipedia dataset.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.426530513637E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"markdown","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"5b6a6c55-f784-4787-84a7-c82c29010088"},{"version":"CommandV1","origId":3524,"guid":"faae4485-bb31-4876-9a93-bc079b27d36c","subtype":"command","commandType":"auto","position":14.0,"command":"%sql DESCRIBE wikipedia","commandVersion":0,"state":"finished","results":{"type":"table","data":[["title","string",""],["redirecttitle","string",""],["timestamp","string",""],["lastcontributorusername","string",""],["text","string",""]],"arguments":{},"schema":[{"type":"string","name":"col_name"},{"type":"string","name":"data_type"},{"type":"string","name":"comment"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.418171368439E12,"submitTime":1.418171364769E12,"finishTime":1.418171368617E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"f47df7ef-016a-494d-bfea-33bb66479242"},{"version":"CommandV1","origId":3525,"guid":"d71fdcd1-b136-49f7-a307-910de9643059","subtype":"command","commandType":"auto","position":15.0,"command":"%sql select count(*) from wikipedia","commandVersion":0,"state":"finished","results":{"type":"table","data":[[9770551.0]],"arguments":{},"schema":[{"type":"bigint","name":"c_0"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.41817137012E12,"submitTime":1.418171366443E12,"finishTime":1.418171370728E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"2508e1a4-de5f-4d60-a31a-de0049dc379e"},{"version":"CommandV1","origId":3526,"guid":"fab74eed-73d7-4b69-9cf8-1cf7216826ed","subtype":"command","commandType":"auto","position":16.0,"command":"%sql select title from wikipedia","commandVersion":0,"state":"finished","results":{"type":"table","data":[["AccessibleComputing"],["Anarchism"],["AfghanistanHistory"],["AfghanistanGeography"],["AfghanistanPeople"],["AfghanistanCommunications"],["AfghanistanTransportations"],["AfghanistanMilitary"],["AfghanistanTransnationalIssues"],["AssistiveTechnology"],["AmoeboidTaxa"],["Autism"],["AlbaniaHistory"],["AlbaniaPeople"],["AsWeMayThink"],["AlbaniaGovernment"],["AlbaniaEconomy"],["Albedo"],["AfroAsiaticLanguages"],["ArtificalLanguages"],["AbacuS"],["AbalonE"],["AbbadideS"],["AbbesS"],["AbbevilleFrance"],["AbbeY"],["AbboT"],["Abbreviations"],["AtlasShrugged"],["ArtificialLanguages"],["AtlasShruggedCharacters"],["AtlasShruggedCompanies"],["AyersMusicPublishingCompany"],["AfricanAmericanPeople"],["AdolfHitler"],["AbeceDarians"],["AbeL"],["AbensbergGermany"],["AberdeenSouthDakota"],["ArthurKoestler"],["AynRand"],["AlexanderTheGreat"],["AnchorageAlaska"],["ArgumentForms"],["ArgumentsForTheExistenceOfGod"],["AnarchY"],["AsciiArt"],["AcademyAwards"],["AcademyAwards/BestPicture"],["AustriaLanguage"],["AcademicElitism"],["AxiomOfChoice"],["AmericanFootball"],["AmericA"],["AnnaKournikova"],["AndorrA"],["AustroAsiaticLanguages"],["ActresseS"],["A"],["AnarchoCapitalism"],["AnarchoCapitalists"],["ActressesS"],["AnAmericanInParis"],["AutoMorphism"],["ActionFilm"],["Alabama"],["AfricA"],["Achilles"],["AppliedStatistics"],["Abraham Lincoln"],["Aristotle"],["An American in Paris"],["Academy Award for Best Production Design"],["Academy Awards"],["Action Film"],["Actrius"],["Animalia (book)"],["International Atomic Time"],["Altruism"],["AutoRacing"],["Ayn Rand"],["Alain Connes"],["Allan Dwan"],["Algeria/People"],["Algeria/Transnational Issues"],["Algeria"],["List of Atlas Shrugged characters"],["Topics of note in Atlas Shrugged"],["Anthropology"],["Agricultural science"],["Alchemy"],["Air Transport"],["Alien"],["Astronomer"],["Ameboid stage"],["Amebas (pseudopod protists)"],["ASCII"],["Ashmore And Cartier Islands"],["Austin (disambiguation)"],["Ascii Art"],["Animation"],["Apollo"],["Andre Agassi"],["Artificial languages"],["Austroasiatic languages"],["Afro-asiatic languages"],["Afroasiatic languages"],["Andorra"],["Andorra/Transnational issues"],["Arithmetic mean"],["American Football Conference"],["Albert Gore"],["AnEnquiryConcerningHumanUnderstanding"],["Animal Farm"],["Amphibian"],["Albert Arnold Gore/Criticisms"],["Alaska"],["Auteur Theory Film"],["Agriculture"],["Aldous Huxley"],["Abstract Algebra"],["Ada"],["Aberdeen (disambiguation)"],["Algae"],["Analysis of variance"],["ANOVA"],["Alkane"],["Appellate procedure in the United States"],["Answer"],["Appellate court"],["Arithmetic and logic unit"],["Actress"],["Arraignment"],["America the Beautiful"],["Assistive technology"],["Accessible computing"],["Abacus"],["Acid"],["Asphalt"],["American National Standards Institute"],["Argument (disambiguation)"],["Apollo 11"],["Apollo 8"],["Astronaut"],["A Modest Proposal"],["Alkali metal"],["Argument form"],["Allotrope"],["Alphabet"],["Atomic number"],["Anatomy"],["Affirming the consequent"],["Andrei Tarkovsky"],["Ambiguity"],["Abel"],["Animal (disambiguation)"],["Aardvark"],["Aardwolf"],["Adobe"],["Adventure"],["Amaltheia"],["Analysis of Variance"],["Asia"],["Aruba"],["Articles of Confederation"],["Archaeology/Broch"],["Asia Minor (disambiguation)"],["Aa River"],["Atlantic Ocean"],["Arthur Schopenhauer"],["Angola"],["Demographics of Angola"],["Politics of Angola"],["Economy of Angola"],["Transport in Angola"],["Angolan Armed Forces"],["Foreign relations of Angola"],["Albert Sidney Johnston"],["Android (robot)"],["Alberta"],["Wikipedia:Adding Wikipedia articles to Nupedia"],["Astronomy/History"],["List of anthropologists"],["Astronomy and Astrophysics/History"],["Actinopterygii"],["Al Gore/Criticisms"],["Albert Einstein"],["Afghanistan"],["Albania"],["Allah"],["Algorithms (journal)"],["Antigua And Barbuda"],["Azerbaijan"],["Amateur astronomy"],["Astronomers and Astrophysicists"],["Aikido"],["Art"],["Albania/History"],["Albania/Transnational Issues"],["Albania/People"],["Albania/Foreign relations"],["Agnostida"],["Abortion"],["Abstract (law)"],["A.E. van Vogt"],["AOLamer"],["American Revolutionary War"],["Ampere"],["Algorithm"],["Annual plant"],["Anthophyta"],["Atlas (disambiguation)"],["Mouthwash"],["Alexander the Great"],["Alfred Korzybski"],["Asteroids (video game)"],["Asparagales"],["Alismatales"],["Apiales"],["Asterales"],["Asteroid"],["Allocution"],["Affidavit"],["Aries (constellation)"],["Aquarius (constellation)"],["Anime"],["Asterism"],["Ankara"],["Arabic language"],["AlbaniaCommunications"],["Alfred Hitchcock"],["Anaconda"],["Afghanistan/History"],["Afghanistan/Geography"],["Afghanistan/Government"],["Afghanistan/People"],["Afghanistan/Economy"],["Afghanistan/Communications"],["Afghanistan/Military"],["Afghanistan/Transnational Issues"],["Afghanistan (1911 Encyclopedia)"],["Altaic languages"],["Austrian German"],["Austria/Transnational issues"],["Anglican Church"],["Axiom of choice"],["Attila"],["Aegean Sea"],["A Clockwork Orange"],["Amsterdam"],["Museum of Work"],["Audi"],["Aircraft"],["Alfred Nobel"],["Alexander Graham Bell"],["Anatolia"],["Abiotic factors"],["Apple Inc."],["Aberdeenshire"],["AU"],["Aztlan Underground"],["Aland"],["American Civil War"],["Andy Warhol"],["Alp Arslan"],["American Film Institute"],["Akira Kurosawa"],["Ancient civilization"],["Ancient Egypt"],["Analog Brothers"],["Motor neuron disease"],["Abjad"],["Abugida"],["ABBA"],["Allegiance"],["Absolute majority"],["Altenberg"],["MessagePad"],["A. E. van Vogt"],["Anna Kournikova"],["Accountancy"],["Alfons Maria Jakob"],["Agnosticism"],["Argon"],["Arsenic"],["Antimony"],["Actinium"],["Americium"],["Astatine"],["Atom"],["Arable land"],["Aluminium"],["Advanced Chemistry"],["Awk"],["AgoraNomic"],["Anglican Communion"],["Arne Kaijser"],["Archipelago"],["Author"],["Andrey Markov"],["Anti-semitism"],["Anti-semitic"],["Angst"],["Anxiety"],["A.A. Milne"],["A. A. Milne"],["Asociacin Alumni"],["Alumna"],["Axiom"],["Alpha"],["Alvin Toffler"],["The Amazing Spider-Man"],["AM"],["Automated Alice/XII"],["Automated Alice/XI"],["Automated Alice/X"],["Automated Alice/IX"],["Automated Alice/VIII"],["Automated Alice/VI"],["Automated Alice/VII"],["Automated Alice/V"],["Automated Alice/IV"],["Automated Alice/II"],["Automated Alice/I"],["Automated Alice/III"],["Antigua and Barbuda"],["Azincourt"],["Albert Speer"],["Allioideae"],["Asteraceae"],["Apiaceae"],["Axon"],["Agma"],["Aramaic alphabet"],["Arguments for the existence of God"],["American shot"],["Acute disseminated encephalomyelitis"],["Ataxia"],["AmbientCalculusOnline"],["Abdul Alhazred"],["A priori and a posterior knowledge"],["Ada Lovelace"],["AmbientCalculiOnline"],["August Derleth"],["Alps"],["A priori and a posteriori knowledge"],["Albert Camus"],["Agatha Christie"],["The Plague"],["Applied ethics"],["Absolute value"],["Analog signal"],["Arecales"],["Hercule Poirot"],["Miss Marple"],["April"],["August"],["Aaron"],["April 6"],["April 12"],["April 15"],["April 30"],["August 22"],["August 27"],["Alcohol"],["Achill Island"],["Allen Ginsberg"],["Algebraically closed field"],["August 6"],["Anatoly Karpov"],["Aspect ratio"],["Auto racing"],["Anarcho-capitalism"],["Anarcho-capitalists"],["August 9"],["Aristophanes"],["Albert Schweitzer"],["Austrian School"],["Abscess"],["Ancient Pueblo peoples"],["Aal"],["Aalborg Municipality"],["Aarhus"],["Northern cavefish"],["Abatement"],["Amateur"],["Alexis Carrel"],["All Souls' Day"],["Anatole France"],["Andr Gide"],["Applied statistics"],["Analysis of variance/Random effects models"],["Analysis of variance/Degrees of freedom"],["Algorithms for calculating variance"],["Almond"],["Demographics of Antigua and Barbuda"],["Politics of Antigua and Barbuda"],["Telecommunications in Antigua and Barbuda"],["Royal Antigua and Barbuda Defence Force"],["Antigua and Barbuda/Transnational issues"],["Antisemitism"],["Economy of Azerbaijan"],["Geography of Azerbaijan"],["Azerbaijan/People"],["Azerbaijan/Communications"],["Foreign relations of Azerbaijan"],["Azerbaijani Armed Forces"],["Azerbaijan/Foreign relations"],["Geography of Armenia"],["Demographics of Armenia"],["Politics of Armenia"],["Economy of Armenia"],["Transport in Armenia"],["Armed Forces of Armenia"],["Foreign relations of Armenia"],["Argentina/Transnational issues"],["Argentina/Foreign relations"],["Geography of American Samoa"],["Demographics of American Samoa"],["Politics of American Samoa"],["Economy of American Samoa"],["Transportation in American Samoa"],["American Samoa/Military"],["Australia/Transnational issues"],["August 13"],["Avicenna"],["The Ashes"],["Analysis"],["Abner Doubleday"],["America's National Game"],["Amplitude modulation"],["Augustin-Jean Fresnel"],["Abbot"],["Ardipithecus"],["Assembly line"],["Adelaide"],["AK47"],["Alan Garner"],["Amhrann na bhFiann"],["August 2"],["Atlantic (disambiguation)"],["Algebraic number"],["Automorphism"],["Accordion"],["Artificial intelligence"],["Afro Celt Sound System"],["Ancient philosophy"],["Anaximander"],["APL"],["Architect"],["Abbreviation"],["Aphrodite"],["April 1"],["Antisymmetric relation"],["Aleister Crowley"],["Afterlife"],["Admiral Doenitz"],["Astrometry"],["Athena"],["Amber Diceless Roleplaying Game"],["Athene (disambiguation)"],["AphexTwin"],["Alloy"],["Articles of Faith"],["Alternative history"],["Artistic revolution"],["Agrarianism"],["Atomic"],["Allotropes"],["Angle"],["Asa"],["Acoustics"],["Angle tribe"],["Atomic physics"],["American Sign Language"],["Applet"],["Alternate history"],["Atomic orbitals"],["Atomic orbital"],["Amino acid"],["Alan Turing"],["Area"],["Astronomical unit"],["Artist"],["Actaeon"],["Anglicanism"],["Athens"],["Anguilla"],["Anguilla/Transnational issues"],["Anguilla/Military"],["Telecommunications in Anguilla"],["Ashmore and Cartier Islands"],["Ashmore and Cartier Islands/Geography"],["Ashmore and Cartier Islands/People"],["Ashmore and Cartier Islands/Government"],["Ashmore and Cartier Islands/Transportation"],["Ashmore and Cartier Islands/Economy"],["Ashmore and Cartier Islands/Military"],["Acoustic theory"],["Alexander Mackenzie"],["Atomic bomb"],["Ashoka"],["American (word)"],["Ada (programming language)"],["Alpha ray"],["Alfonso Aru"],["Alfonso Cuarn"],["Arianism"],["August 1"],["Astronomical Units"],["Antoninus Pius"],["August 3"],["Advanced Encryption Standard"],["April 26"],["Argot"],["Anisotropy"],["Alpha decay"],["AI"],["Extreme poverty"],["Analytical Engine"],["Augustus"],["Geography of Antarctica"],["Economy of Antarctica"],["Government of Antarctica"],["Transport in Antarctica"],["Military of Antarctica"],["Geography of Alabama"],["List of Governors of Alabama"],["Apocrypha"],["Antartic Treaty"],["Antarctic Treaty System"],["Algernon Swinburne"],["Alfred Lawson"],["ALCS"],["Apocrypha/Tanakh"],["Ames, Iowa"],["Abbadides"],["Abalone"],["Abbess"],["Human abdomen"],["Abdominal surgery"],["Abduction"],["Abensberg"],["Arminianism"],["The Alan Parsons Project"],["Almost all"],["Ada Byron's notes on the analytical engine"],["Augustine"],["Aromatic hydrocarbon"],["Abbey"],["Annales School"],["Antimatter"],["Antonio Gaudi/Sagrada Familia"],["Casa Batll"],["Park Gell"],["Casa Mil"],["Antiparticle"],["A.D."],["Arabian Prince"],["August 7"],["August 8"],["April 16"],["Associative property"],["Apache Software Foundation"],["Americans with Disabilities Act of 1990"],["Americans with Disabilities Act of 1990/Findings and Purposes"],["Americans with Disabilities Act of 1990/Definitions"],["Americans with Disabilities Act of 1990/Title III"],["A.D"],["Apple I"],["Apache webserver"],["Apatosaurus"],["Allosaurus"],["AK-47"],["AtanasoffBerry computer"],["Andes"],["Anderida"],["Ancylopoda"],["Anchor"],["Anbar (town)"],["Anazarbus"],["Anagram"],["Anadyr River"],["Andr-Marie Ampre"],["Ammonia"],["Amethyst"],["Albertosaurus"],["Assembly language"],["Ambrosia"],["Ambrose"],["Ambracia"],["Amber"],["Amalaric"],["Alphorn"],["Army"],["Alligatoridae"],["Alder"],["Amos Bronson Alcott"],["Arachnophobia"],["Alabaster"],["Ahab"],["ASIC (disambiguation)"],["Dasyproctidae"],["Algol"],["Amazing Grace"],["AOL"],["ADHD"],["Anno Domini"],["AV"],["Amino group"],["Antony van Leeuwenhook"],["Alcuin"],["Angilbert"],["Antony van Leeuwenhoek"],["Amine"],["Adrian I"],["April 29"],["August 14"],["Absolute zero"],["Adiabatic process"],["Amide"],["Animism"],["Antonio Vivaldi"],["Adrian II"],["Adrian"],["Adrian IV"],["Adrian VI"],["Aare"],["Abgar"],["Abbotsford House"],["Abraham"],["Abraxas"],["Absalom"],["Abydos"],["Abydos, Egypt"],["Abydos (Hellespont)"],["August 15"],["Acacia"],["Acapulco"],["August 16"],["Alan Kay"],["APL (programming language)"],["ALGOL"],["AWK"],["Alzheimers disease"],["Ascorbic Acid"],["Asgard"],["Apollo program"],["Assault"],["Australian Prime Ministers"],["lfheimr"],["Ask and Embla"],["Alabama River"],["Alain de Lille"],["Alemanni"],["NYSE MKT"],["August 17"],["August 12"],["Alfred Russel Wallace"],["Australian Labor Party"],["August 18"],["August 19"],["August 21"],["Dodo (Alice's Adventures in Wonderland)"],["Lory (disambiguation)"],["Eaglet (Alice's Adventures in Wonderland)"],["Albert"],["Albert I"],["Albert II"],["Albert III"],["Albert Alcibiades, Margrave of Brandenburg-Kulmbach"],["Albert the Bear"],["Albert I of Hapsburg"],["Albert of Mainz"],["Albert, Duke of Prussia"],["Albert III, Elector of Saxony"],["Albert the Degenerate"],["Albert Of Aix"],["August 25"],["Aachen"],["Agate"],["Aspirin"],["Abner"],["Ahmed I"],["Ahmed II"],["Ahmed III"],["Ainu people"],["Aix-la-Chapelle"],["Acorn (fruit of the oak tree)"],["Acropolis"],["Acupuncture"],["Adder"],["Adirondacks"],["Aeneas"],["April 13"],["Amaranth"],["Agapanthus africanus"],["Agamemnon"],["Aga Khan I"],["Aga Khan III"],["Agasias"],["Alexander Emanuel Agassiz"],["Agathon"],["Agesilaus II"],["Agis"],["Antonio Agliardi"],["Agnes of Merania"],["Agni"],["Agrippina the Elder"],["Agrippina the Younger"],["American Chinese cuisine"],["Ahenobarbus"],["Ahmad Shah Durrani"],["Aidan of Dalriada"],["Arthur Aikin"],["Ailanthus"],["Aimoin"],["Akkadian Empire"],["Ajax the Lesser"],["Ajax (mythology)"],["Ajax"],["Alaric I"],["Alaric II"],["Albategnius"],["Albertus Magnus"],["Alboin"],["Afonso de Albuquerque"],["Alcaeus of Mytilene"],["Alcamenes"],["Alcmene"],["Alcidamas"],["Aldine Press"],["Ealdred (archbishop of York)"],["Alexander I of Epirus"],["Alexander Balas"],["Alexander of Pherae"],["Alexander II of Epirus"],["Alexander Jagiellon"],["Alexander III of Russia"],["Alexander I of Scotland"],["Alexander II of Scotland"],["Alexander I of Serbia"],["Alexander III of Scotland"],["Alexander of Greece (disambiguation)"],["Alexander of Aphrodisias"],["Alexander Severus"],["Alexander"],["Alexander I"],["Alexander II"],["Alexander III"],["Alexander Aetolus"],["Alexander Jannaeus"],["Alexander IV"],["Alexander V"],["Alexander VI"],["Alexander VII"],["Alexander VIII"],["Alexandrists"],["Alexios I Komnenos"],["Alexis (poet)"],["Alexios II Komnenos"],["Alexios III Angelos"],["Alexios V Doukas"],["Alexei Petrovich, Tsarevich of Russia"],["Andrew Jackson"],["Andrew Johnson"],["Aleksandr Solzhenitsyn"],["Aleksandr Isaevich Solzhenitsyn"],["Aberdeen"],["August 23"],["August 24"],["Antipope"],["Aquaculture"],["Kolmogorov complexity"],["Antoine de Saint-Exupery"],["Hymn to Proserpine"],["The Triumph of Time"],["April 28"],["Alfred the Great"],["Alfred Ernest Albert"],["Alessandro Algardi"],["Alger of Lige"],["Algiers"],["Alhazen"],["Alessandro Allori"],["Almoravid dynasty"],["Aloe"],["Alured of Berkeley"],["Alyattes of Lydia"],["Age of consent"],["Alypius of Antioch"],["Amalasuntha"],["Amalric of Bena"],["Afonso I of Portugal"],["Afonso II of Portugal"],["Afonso III of Portugal"],["Afonso IV of Portugal"],["Afonso V of Portugal"],["Afonso VI of Portugal"],["Alphonso I of Spain"],["Alfonso II of Asturias"],["Amara Sinha"],["Alphonso VIII of Spain"],["Alfonso IX of Spain"],["Alfonso XII of Spain"],["Alfonso XIII of Spain"],["Alphonsus a Sancta Maria"],["Alfonso the Battler"],["Amaryllis"],["Amasis I"],["Alfonso III of Aragon"],["Alfonso IV of Aragon"],["Amasis II"],["Alfonso V of Aragon"],["Amathus"],["Alphons"],["Alfonso I"],["Amati"],["Alfonso II"],["Alfonso III"],["Alfonso IV"],["Amazons"],["Alfonso V"],["Ambergris"],["Ambiorix"],["Alfonso VI"],["August Wilhelm Ambros"],["Amazon River"],["Alfred of Beverley"],["Alphonso VII"],["Alphonso VIII"],["Alphonso IX"],["Alphonso X"],["Alphonso XI"],["Alphonso XII"],["Alphonso XIII"],["April 22"],["August 31"],["Autpert Ambrose"],["Abu Bakr"],["St. Ambrose Traversari"],["Ambrosians"],["Ambrosiaster"],["Ambrosius Aurelianus"],["Ammon"],["Ammonius Hermiae"],["Ammonius Saccas"],["Book of Amos"],["Amphipolis"],["Amram"],["Amyntas I of Macedon"],["Amyntas III of Macedon"],["Anacharsis"],["Anacreon (poet)"],["Anah"],["Ananda"],["Anaxagoras"],["Anaxarchus"],["Ancyra (genus)"],["Anastasius I"],["Anastasius II"],["Anastasius III"],["Anastasius IV"],["Anaximenes of Lampsacus"],["Anastasius"],["Anaximenes of Miletus"],["Ancus Marcius"],["Andaman Islands"],["Alexander Anderson (mathematician)"],["Andocides"],["Andrea Andreani"],["Andrew II of Hungary"],["An Enquiry Concerning Human Understanding"],["Andr de Longjumeau"],["Andriscus"],["Andronikos III Palaiologos"],["Andronikos II Palaiologos"],["Andronikos I Komnenos"],["Andronicus of Cyrrhus"],["Andronicus of Rhodes"],["Andronicus"],["Asteroid Belt"],["Ammianus Marcellinus"],["ALICE"],["An Enquiry Concerning Human Understanding/Text"],["Apollo 13"],["Apollo Program"],["Arthritus"],["Apollo 7"],["Apollo 9"],["Applied discrete math"],["Arthritis"],["April 2"],["Acetylene"],["Alfred"],["August 28"],["Athenian democracy"],["Arabic numerals"],["April 9"],["ABM"],["Apuleius"],["Alexander Selkirk"],["Anti-ballistic missile"],["August 29"],["August 30"],["Acre"],["ATP"],["Adenosine triphosphate"],["gir"],["Antibiotics"],["Arnold Schwarzenegger"],["ASA"],["Aquinas"],["Actium"],["Amide hydrolysis"],["Amway"],["Adam Smith"],["Antoine Laurent Lavoisier"],["Antoine Lavoisier"],["A roll"],["Hermann Kolbe"],["April 18"],["April 23"],["Amitabh Bachchan"],["Air Pollution"],["Antarctic-Environmental Protocol"],["Allomorph"],["American bias"],["Allophone"],["Affix"],["Allegory"],["Amazon river"],["Allotropy"],["Agathocles of Syracuse"],["Economy of Alberta"],["Augustin-Louis Cauchy"],["Archimedes"],["Alternative medicine"],["Archimedean solid"],["Antiprism"],["Ancient Greeks"],["Natural history of Africa"],["Geography of Africa"],["Africa/History"],["Approval voting"],["Aromatic compound"],["Arizona State University"],["April 14"],["Astoria, Oregon"],["Alarums and Excursions"],["Alfred Jarry"],["Amalric"],["Amalric I of Jerusalem"],["Amalric II of Jerusalem"],["Anthemius of Tralles"],["Absalon"],["Adhemar of Le Puy"],["Adhemar de Chabannes"],["Albigenses"],["Alphonse, Count of Poitiers"],["Alfonso Jordan"],["Ambroise"],["Art Deco"],["ASCII art"],["Autoerotic asphyxiation"],["Alexius"],["Ban on assault rifles"],["American English"],["Albert Spalding"],["Africa Alphabet"],["Acquire"],["Australian English"],["American Airlines Flight 77"],["American Airlines flight 77"],["American Airlines flight 11"],["Ambush"],["Astronomical aberration"],["Abzyme"],["Adaptive radiation"],["Agarose gel electrophoresis"],["Allele"],["Ampicillin"],["Annealing"],["Antibiotic resistance"],["Antigen"],["Autosome"],["Antwerp (disambiguation)"],["Aquila"],["Al-Qaeda"],["Alessandro Volta"],["Argo Navis"],["Andromeda (mythology)"],["Antlia"],["Ara (constellation)"],["Auriga"],["Arkansas"],["Atmosphere (disambiguation)"],["Apus"],["Abadan, Iran"],["Attorney"]],"arguments":{},"schema":[{"type":"string","name":"title"}],"overflow":true,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.418171371984E12,"submitTime":1.418171368287E12,"finishTime":1.418171372107E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":null,"commentThread":[],"commentsVisible":false,"parentHierarchy":null,"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":null,"iPythonMetadata":null,"nuid":"970db0d7-b665-4213-b3fd-20ba9fb83219"}],"guid":"14763c49-1604-4a9c-914d-754f5c6bae27","globalVars":{},"iPythonMetadata":null};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":-1,"guid":"206319ed-602c-4dd4-ac68-fb75ea64a22c","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](../../index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>