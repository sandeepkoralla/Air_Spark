<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Accessing Data / Common File Formats / LZO Files - py - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/img/favicon.ico"/>
<script>window.settings = {"sparkDocsSearchGoogleCx":"004588677886978090460:_rj0wilqwdm","dbcForumURL":"http://forums.databricks.com/","dbfsS3Host":"https://databricks-prod-storage-oregon.s3.amazonaws.com","enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"isAdmin":false,"enablePresentationTimerConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"clusters":false,"hideOffHeapCache":false,"applications":false,"useStaticGuide":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"sparkVersions":[{"key":"1.3.x","displayName":"Spark 1.3.0","packageLabel":"spark-1.3-jenkins-ip-10-2-0-138-U094163cf51-S47b89c350f-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.4.x","displayName":"Spark 1.4.1","packageLabel":"spark-1.4-jenkins-ip-10-2-0-138-U094163cf51-S2f95f6c227-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x","displayName":"Spark 1.6 Branch Preview","packageLabel":"spark-1.6-jenkins-ip-10-2-0-138-U094163cf51-S3436f2ea50-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":false,"enableFeedback":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.8.1","local":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":false,"enableStaticNotebooks":true,"dbcGuideURL":"#workspace/databricks_guide/00 Welcome to Databricks","enableClusterAclsConfig":false,"orgId":0,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":false,"driverLog4jFilePrefix":"log4j","enableMavenLibraries":true,"defaultSparkVersion":{"key":"1.5.x","displayName":"Spark 1.5.2","packageLabel":"spark-1.5-jenkins-ip-10-2-0-138-U094163cf51-S336f76a5be-2015-12-03-00:16:18.916275","upgradable":true,"deprecated":false,"customerVisible":true},"clusterPublisherRootId":5,"enableLatestJobRunResultPermalink":true,"enableSparkConfUI":true,"enableJdbcImport":true,"logfiles":"logfiles/","enableClusterDeltaUpdates":true,"csrfToken":"d3dde7ae-fd45-4989-86b8-e91415a5ebcf","useFixedStaticNotebookVersionForDevelopment":false,"enableBasicReactDialogBoxes":true,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableWorkspaceAclService":true,"enableWorkspaceAcls":true,"gitHash":"094163cf51fcd4717c3ea96799d1008723ae8985","userFullname":"Suresh Jayaram","enableImportFromUrl":true,"enableMiniClusters":false,"enableWebSocketDeltaUpdates":true,"enableDebugUI":false,"showHiddenSparkVersions":false,"allowNonAdminUsers":true,"userId":100017,"dbcSupportURL":"","staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/","enableSparkPackages":true,"enableNotebookHistoryUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"databricksGuideStaticUrl":"","notebookLoadingBackground":"#fff","enableNewJobRunDetailsPage":true,"enableDashboardExport":true,"user":"surjayaram@paypal.com","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"tablesPublisherRootId":7,"accounts":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":1283,"name":"Accessing Data / Common File Formats / LZO Files - py","language":"python","commands":[{"version":"CommandV1","origId":1284,"guid":"b7812321-f947-4916-ab68-fb00ca8e59ba","subtype":"command","commandType":"auto","position":1.0,"command":"%md\n\n# Reading LZO Files in Python\n\nThe LZO compression codec is not available by default for licensing reasons, but you can install it on your own.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.438643095853E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"a4a55f17-8b76-4241-a9b1-c015af64833e"},{"version":"CommandV1","origId":1285,"guid":"7a48f7b2-78d7-42fd-89bd-bec4a3107dd7","subtype":"command","commandType":"auto","position":1.25,"command":"%md\n\n### Step 1: Compile a Hadoop-LZO jar which is needed to read LZO files.\n**NOTE:** The Hadoop LZO jar needs to be compiled on the same machine type as the Spark cluster to pick up the right gplcompression files.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"baa96154-5693-4653-85d1-edbebaf84b43"},{"version":"CommandV1","origId":1286,"guid":"d44183c0-65a8-4f4c-93a9-19e57e3c3c41","subtype":"command","commandType":"auto","position":1.5,"command":"%sh\n\ncd /home/ubuntu\n\nsudo apt-get update\nsudo apt-get install -y --force-yes liblzo2-2 liblzo2-dev\nsudo apt-get install -y --force-yes lzop\nsudo apt-get install -y --force-yes maven\nsudo apt-get install -y --force-yes make\nsudo apt-get install -y --force-yes git\nsudo apt-get install -y --force-yes default-jdk\nsudo apt-get install -y --force-yes build-essential\n\nrm -rf hadoop-lzo\ngit clone https://github.com/twitter/hadoop-lzo.git\n  \ncd hadoop-lzo; mvn package\n\ncp /home/ubuntu/hadoop-lzo/target/hadoop-lzo-0.4.20-SNAPSHOT.jar /dbfs/hadoop-lzo-0.4.20-SNAPSHOT.jar","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null,"nuid":"80a95642-40c6-49fb-ac54-d32cb2d159f2"},{"version":"CommandV1","origId":1287,"guid":"91145632-5c8d-403e-84a4-478dcf4cb365","subtype":"command","commandType":"auto","position":2.0,"command":"%md\n\n### Step 2: Install the LZO Codec on the cluster.\n\nCreate an Init Script to run when the Spark cluster starts up to:\n* Install lzo.\n* Copy the hadoop-lzo.jar to be picked up by the Spark cluster.\n* Configures Spark to use the LZO Compression Codec.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.438645469571E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"e42a18a2-098b-4dac-ac1c-5305d63261ad"},{"version":"CommandV1","origId":1288,"guid":"1c2027ab-a3e9-4d7a-9253-90799d89aa2d","subtype":"command","commandType":"auto","position":3.0,"command":"# TODO: Replace the cluster name here with your cluster name.\ndbutils.fs.put(\"/databricks/init/LZOTest/install_lzo_and_configure.sh\",\"\"\"\n#!/usr/bin/bash\n\ncd /home/ubuntu\n\necho \"----Begining Install----\"\n\nsudo apt-get update\nsudo apt-get install -y --force-yes liblzo2-2 liblzo2-dev\nsudo apt-get install -y --force-yes lzop\n\ncp /dbfs/hadoop-lzo-0.4.20-SNAPSHOT.jar /mnt/driver-daemon/jars/hadoop-lzo-0.4.20-SNAPSHOT.jar\ncp /dbfs/hadoop-lzo-0.4.20-SNAPSHOT.jar /mnt/jars/driver-daemon/hadoop-lzo-0.4.20-SNAPSHOT.jar\n\necho '[driver].\"spark.hadoop.io.compression.codecs\" = \"org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec\"' >> /home/ubuntu/databricks/common/conf/my-spark.conf\n\"\"\", True)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Wrote 974 bytes.\n<span class=\"ansired\">Out[</span><span class=\"ansired\">1</span><span class=\"ansired\">]: </span>True\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":"<div class=\"ansiout\">ERROR: An unexpected error occurred while tokenizing input\nThe following traceback may be corrupted or invalid\nThe error message is: (&apos;EOF in multi-line string&apos;, (1, 0))\n\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-3-0d1ce6bc4ec3&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     24</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     25</span> echo <span class=\"ansiblue\">&apos;[driver].&quot;spark.hadoop.io.compression.codecs&quot; = &quot;com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec&quot;&apos;</span> <span class=\"ansiyellow\">&gt;&gt;</span> <span class=\"ansiyellow\">/</span>home<span class=\"ansiyellow\">/</span>ubuntu<span class=\"ansiyellow\">/</span>databricks<span class=\"ansiyellow\">/</span>common<span class=\"ansiyellow\">/</span>conf<span class=\"ansiyellow\">/</span>my<span class=\"ansiyellow\">-</span>spark<span class=\"ansiyellow\">.</span>conf<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 26</span><span class=\"ansiyellow\"> &quot;&quot;&quot; % cluster_name, True)\n</span>\n<span class=\"ansired\">TypeError</span>: not all arguments converted during string formatting\n</div>","startTime":1.441999028192E12,"submitTime":1.441999028059E12,"finishTime":1.441999028832E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"0c67b05c-8082-4b87-8ac7-e4c7849dc1b7"},{"version":"CommandV1","origId":1289,"guid":"96ba2be4-a244-40e6-888f-655c6c8bce29","subtype":"command","commandType":"auto","position":4.0,"command":"%md\n\n### Step 3: Restart your cluster for these changes to take effect","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.438645808309E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"3a05a57b-789c-41a4-8bda-7d3bc673bbd9"},{"version":"CommandV1","origId":1290,"guid":"e571b807-95fe-435a-b326-e6291d29081e","subtype":"command","commandType":"auto","position":5.0,"command":"# Verify that lzop is properly installed - Should see /usr/bin/lzop.\nimport os\n\nprint os.popen(\"which lzop\").read()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">/usr/bin/lzop\n\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.438646884794E12,"submitTime":1.438646884697E12,"finishTime":1.438646884874E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"5a3cf71e-4ee1-4aa2-9017-86d6ba16cc37"},{"version":"CommandV1","origId":1291,"guid":"d564a9d1-7246-44dc-8333-80e8598aaa48","subtype":"command","commandType":"auto","position":5.25,"command":"# Check for the Hadoop LZO Jar.\ndisplay(dbutils.fs.ls(\"file:/mnt/driver-daemon/jars/hadoop-lzo-0.4.20-SNAPSHOT.jar\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["file:/mnt/driver-daemon/jars/hadoop-lzo-0.4.20-SNAPSHOT.jar","hadoop-lzo-0.4.20-SNAPSHOT.jar",181658.0]],"arguments":{},"schema":[{"type":"string","name":"path"},{"type":"string","name":"name"},{"type":"bigint","name":"size"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":null,"startTime":1.438646890626E12,"submitTime":1.43864689057E12,"finishTime":1.438646891163E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"bf7c4b2c-d9d3-4226-8f5d-edd7e41b5b00"},{"version":"CommandV1","origId":1292,"guid":"5df60389-1c9e-46c2-84b9-d5e5e53659fe","subtype":"command","commandType":"auto","position":5.375,"command":"# Make sure Spark is configured to use the LzoCodec\nsc._conf.get(\"spark.hadoop.io.compression.codecs\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">30</span><span class=\"ansired\">]: </span>u&apos;com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec&apos;\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.438646907457E12,"submitTime":1.438646907406E12,"finishTime":1.438646907536E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"cff4573e-4889-4300-80ae-39be2ac2574d"},{"version":"CommandV1","origId":1293,"guid":"cd4b547e-cab9-414e-96e8-cb52a886ece2","subtype":"command","commandType":"auto","position":6.0,"command":"%md\n\n### Step 4: Create a test LZO file.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.438646908484E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"b82d5f8e-32eb-4fd8-9f7f-ba071343d116"},{"version":"CommandV1","origId":1294,"guid":"7a6bf6b6-dfae-4c02-9a99-232585720dbf","subtype":"command","commandType":"auto","position":6.5,"command":"dbutils.fs.rm(\"file:/tmp/lzo\", True)\ndbutils.fs.rm(\"dbfs:/tmp/lzo\", True)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">31</span><span class=\"ansired\">]: </span>False\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.438646909573E12,"submitTime":1.438646909501E12,"finishTime":1.438646910052E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"77391346-7d6d-4692-8aee-9b8edd7010f7"},{"version":"CommandV1","origId":1295,"guid":"4000840b-c073-4d57-b2e8-742179ea1d03","subtype":"command","commandType":"auto","position":7.0,"command":"sc.parallelize([\"This is line %i\" % i for i in range(1, 3000)]).coalesce(1).saveAsTextFile(\"dbfs:/tmp/lzo\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-10-40ef919951b5&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      4</span>                 <span class=\"ansiblue\">&quot;This is line 4&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span>                 &quot;This is line 5&quot;]\n<span class=\"ansigreen\">----&gt; 6</span><span class=\"ansiyellow\">                ).coalesce(1).saveAsTextFile(&quot;dbfs:/tmp/lzo&quot;)\n</span>\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">saveAsTextFile</span><span class=\"ansiblue\">(self, path, compressionCodecClass)</span>\n<span class=\"ansigreen\">   1429</span>             keyed<span class=\"ansiyellow\">.</span>_jrdd<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>ctx<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>BytesToString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>saveAsTextFile<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">,</span> compressionCodec<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1430</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1431</span><span class=\"ansiyellow\">             </span>keyed<span class=\"ansiyellow\">.</span>_jrdd<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>ctx<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>BytesToString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>saveAsTextFile<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1432</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1433</span>     <span class=\"ansired\"># Pair functions</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">    536</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    537</span>         return_value = get_return_value(answer, self.gateway_client,\n<span class=\"ansigreen\">--&gt; 538</span><span class=\"ansiyellow\">                 self.target_id, self.name)\n</span><span class=\"ansigreen\">    539</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    540</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    298</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    299</span>                     <span class=\"ansiblue\">&apos;An error occurred while calling {0}{1}{2}.\\n&apos;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 300</span><span class=\"ansiyellow\">                     format(target_id, &apos;.&apos;, name), value)\n</span><span class=\"ansigreen\">    301</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    302</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o366.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory dbfs:/tmp/lzo already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:121)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1053)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:954)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:863)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1290)\n\tat org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:497)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:46)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n\n</div>","startTime":1.438646911058E12,"submitTime":1.438646910965E12,"finishTime":1.438646912876E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"846fda19-0420-4406-8d73-aec16493cd14"},{"version":"CommandV1","origId":1296,"guid":"ef809d4f-9980-4c78-a498-95e262ed2933","subtype":"command","commandType":"auto","position":7.5,"command":"display(dbutils.fs.ls(\"dbfs:/tmp/lzo\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["dbfs:/tmp/lzo/_SUCCESS","_SUCCESS",0.0],["dbfs:/tmp/lzo/part-00000","part-00000",52875.0]],"arguments":{},"schema":[{"type":"string","name":"path"},{"type":"string","name":"name"},{"type":"bigint","name":"size"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-5-0758a6162bbf&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>display<span class=\"ansiyellow\">(</span>dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>ls<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;file:/tmp/lzo&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/tmp/1438376321505-0/PythonShell.py</span> in <span class=\"ansicyan\">display</span><span class=\"ansiblue\">(self, input)</span>\n<span class=\"ansigreen\">    345</span>             self<span class=\"ansiyellow\">.</span>displayRDD <span class=\"ansiyellow\">=</span> input<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    346</span>         <span class=\"ansigreen\">elif</span> isinstance<span class=\"ansiyellow\">(</span>input<span class=\"ansiyellow\">,</span> list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 347</span><span class=\"ansiyellow\">             </span>self<span class=\"ansiyellow\">.</span>displayRDD <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>sc<span class=\"ansiyellow\">.</span>parallelize<span class=\"ansiyellow\">(</span>input<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>toDF<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    348</span>         <span class=\"ansigreen\">elif</span> type<span class=\"ansiyellow\">(</span>input<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">is</span> mpl<span class=\"ansiyellow\">.</span>figure<span class=\"ansiyellow\">.</span>Figure<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    349</span>             _format <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">&apos;png&apos;</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.pyc</span> in <span class=\"ansicyan\">toDF</span><span class=\"ansiblue\">(self, schema, sampleRatio)</span>\n<span class=\"ansigreen\">     60</span>         <span class=\"ansiyellow\">[</span>Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Alice&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     61</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">---&gt; 62</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> sqlContext<span class=\"ansiyellow\">.</span>createDataFrame<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> schema<span class=\"ansiyellow\">,</span> sampleRatio<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     63</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>     RDD<span class=\"ansiyellow\">.</span>toDF <span class=\"ansiyellow\">=</span> toDF<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.pyc</span> in <span class=\"ansicyan\">createDataFrame</span><span class=\"ansiblue\">(self, data, schema, samplingRatio)</span>\n<span class=\"ansigreen\">    402</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    403</span>         <span class=\"ansigreen\">if</span> isinstance<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">,</span> RDD<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 404</span><span class=\"ansiyellow\">             </span>rdd<span class=\"ansiyellow\">,</span> schema <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_createFromRDD<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">,</span> schema<span class=\"ansiyellow\">,</span> samplingRatio<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    405</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    406</span>             rdd<span class=\"ansiyellow\">,</span> schema <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_createFromLocal<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">,</span> schema<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.pyc</span> in <span class=\"ansicyan\">_createFromRDD</span><span class=\"ansiblue\">(self, rdd, schema, samplingRatio)</span>\n<span class=\"ansigreen\">    283</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    284</span>         <span class=\"ansigreen\">if</span> schema <span class=\"ansigreen\">is</span> None <span class=\"ansigreen\">or</span> isinstance<span class=\"ansiyellow\">(</span>schema<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">(</span>list<span class=\"ansiyellow\">,</span> tuple<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 285</span><span class=\"ansiyellow\">             </span>struct <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_inferSchema<span class=\"ansiyellow\">(</span>rdd<span class=\"ansiyellow\">,</span> samplingRatio<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    286</span>             converter <span class=\"ansiyellow\">=</span> _create_converter<span class=\"ansiyellow\">(</span>struct<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    287</span>             rdd <span class=\"ansiyellow\">=</span> rdd<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>converter<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.pyc</span> in <span class=\"ansicyan\">_inferSchema</span><span class=\"ansiblue\">(self, rdd, samplingRatio)</span>\n<span class=\"ansigreen\">    227</span>         <span class=\"ansiyellow\">:</span><span class=\"ansigreen\">return</span><span class=\"ansiyellow\">:</span> StructType<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    228</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 229</span><span class=\"ansiyellow\">         </span>first <span class=\"ansiyellow\">=</span> rdd<span class=\"ansiyellow\">.</span>first<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    230</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> first<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    231</span>             raise ValueError(&quot;The first row in RDD is empty, &quot;\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc</span> in <span class=\"ansicyan\">first</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">   1315</span>         <span class=\"ansigreen\">if</span> rs<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1316</span>             <span class=\"ansigreen\">return</span> rs<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1317</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">raise</span> ValueError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;RDD is empty&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1318</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1319</span>     <span class=\"ansigreen\">def</span> isEmpty<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ValueError</span>: RDD is empty\n</div>","startTime":1.438646913904E12,"submitTime":1.438646913842E12,"finishTime":1.438646914645E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"84f73f4c-bebd-4edd-96c0-a0267b521c95"},{"version":"CommandV1","origId":1297,"guid":"827c8f4f-b8fb-4f5c-9965-327e17bb0356","subtype":"command","commandType":"auto","position":7.75,"command":"dbutils.fs.cp(\"dbfs:/tmp/lzo/part-00000\", \"file:/tmp/lzo/part-00000\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>True\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.438646917018E12,"submitTime":1.43864691697E12,"finishTime":1.438646917196E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"3e50e249-6ed7-4ec5-889b-8e06cef422aa"},{"version":"CommandV1","origId":1298,"guid":"96f1565f-b9a8-4615-9e08-e2c4cdddecb9","subtype":"command","commandType":"auto","position":8.0,"command":"import os\n\nos.system(\"lzop /tmp/lzo/part-00000\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>256\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-5-73e9fc39da2e&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>os<span class=\"ansiyellow\">.</span>popen<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;lzop /tmp/lzo/part-00000&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>read<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;os&apos; is not defined\n</div>","startTime":1.438646934154E12,"submitTime":1.438646934065E12,"finishTime":1.438646934231E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"fdb57841-acf1-4173-b142-b01454828533"},{"version":"CommandV1","origId":1299,"guid":"82889adf-b50a-45b7-b9e0-46bfab637320","subtype":"command","commandType":"auto","position":8.5,"command":"display(dbutils.fs.ls(\"file:/tmp/lzo\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["file:/tmp/lzo/part-00000.lzo","part-00000.lzo",13678.0],["file:/tmp/lzo/part-00000","part-00000",52875.0]],"arguments":{},"schema":[{"type":"string","name":"path"},{"type":"string","name":"name"},{"type":"bigint","name":"size"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":false},"errorSummary":null,"error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-6-0758a6162bbf&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>display<span class=\"ansiyellow\">(</span>dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>ls<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;file:/tmp/lzo&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/tmp/1438381611201-0/PythonShell.py</span> in <span class=\"ansicyan\">display</span><span class=\"ansiblue\">(self, input)</span>\n<span class=\"ansigreen\">    345</span>             self<span class=\"ansiyellow\">.</span>displayRDD <span class=\"ansiyellow\">=</span> input<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    346</span>         <span class=\"ansigreen\">elif</span> isinstance<span class=\"ansiyellow\">(</span>input<span class=\"ansiyellow\">,</span> list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 347</span><span class=\"ansiyellow\">             </span>self<span class=\"ansiyellow\">.</span>displayRDD <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>sc<span class=\"ansiyellow\">.</span>parallelize<span class=\"ansiyellow\">(</span>input<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>toDF<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    348</span>         <span class=\"ansigreen\">elif</span> type<span class=\"ansiyellow\">(</span>input<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">is</span> mpl<span class=\"ansiyellow\">.</span>figure<span class=\"ansiyellow\">.</span>Figure<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    349</span>             _format <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">&apos;png&apos;</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.py</span> in <span class=\"ansicyan\">toDF</span><span class=\"ansiblue\">(self, schema, sampleRatio)</span>\n<span class=\"ansigreen\">     52</span>         <span class=\"ansiyellow\">[</span>Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Alice&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     53</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">---&gt; 54</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> sqlCtx<span class=\"ansiyellow\">.</span>createDataFrame<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> schema<span class=\"ansiyellow\">,</span> sampleRatio<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     55</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     56</span>     RDD<span class=\"ansiyellow\">.</span>toDF <span class=\"ansiyellow\">=</span> toDF<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.py</span> in <span class=\"ansicyan\">createDataFrame</span><span class=\"ansiblue\">(self, data, schema, samplingRatio)</span>\n<span class=\"ansigreen\">    282</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    283</span>         <span class=\"ansigreen\">if</span> schema <span class=\"ansigreen\">is</span> None<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 284</span><span class=\"ansiyellow\">             </span>schema <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_inferSchema<span class=\"ansiyellow\">(</span>rdd<span class=\"ansiyellow\">,</span> samplingRatio<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    285</span>             converter <span class=\"ansiyellow\">=</span> _create_converter<span class=\"ansiyellow\">(</span>schema<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    286</span>             rdd <span class=\"ansiyellow\">=</span> rdd<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>converter<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/sql/context.py</span> in <span class=\"ansicyan\">_inferSchema</span><span class=\"ansiblue\">(self, rdd, samplingRatio)</span>\n<span class=\"ansigreen\">    162</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    163</span>     <span class=\"ansigreen\">def</span> _inferSchema<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> rdd<span class=\"ansiyellow\">,</span> samplingRatio<span class=\"ansiyellow\">=</span>None<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 164</span><span class=\"ansiyellow\">         </span>first <span class=\"ansiyellow\">=</span> rdd<span class=\"ansiyellow\">.</span>first<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    165</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> first<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    166</span>             raise ValueError(&quot;The first row in RDD is empty, &quot;\n\n<span class=\"ansigreen\">/home/ubuntu/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">first</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">   1243</span>         <span class=\"ansigreen\">if</span> rs<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1244</span>             <span class=\"ansigreen\">return</span> rs<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1245</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">raise</span> ValueError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;RDD is empty&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1246</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1247</span>     <span class=\"ansigreen\">def</span> isEmpty<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ValueError</span>: RDD is empty\n</div>","startTime":1.438646935434E12,"submitTime":1.43864693536E12,"finishTime":1.438646936016E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"58e1a518-a749-4a5d-9794-559def11cdc9"},{"version":"CommandV1","origId":1300,"guid":"4b8c0e65-3a83-480e-80b4-2d2ad3b8b11d","subtype":"command","commandType":"auto","position":9.0,"command":"# Copy the file to DBFS so it's accessible to all the Spark workers.\ndbutils.fs.cp(\"file:/tmp/lzo/part-00000.lzo\", \"dbfs:/tmp/lzo/part-00000.lzo\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">39</span><span class=\"ansired\">]: </span>True\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-19-f7ba5978d6b9&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Copy the file to DBFS so it&apos;s accessible to all the workers.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>cp<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;file:/tmp/lzo/part-00000.lzo&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;dbfs:/tmp/lzo/part-00000.lzo&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/tmp/1438645737304-0/dbutils.py</span> in <span class=\"ansicyan\">f_with_exception_handling</span><span class=\"ansiblue\">(*args, **kwargs)</span>\n<span class=\"ansigreen\">    111</span>                     <span class=\"ansigreen\">class</span> ExecutionError<span class=\"ansiyellow\">(</span>BaseException<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    112</span>                         <span class=\"ansigreen\">pass</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 113</span><span class=\"ansiyellow\">                     </span><span class=\"ansigreen\">raise</span> ExecutionError<span class=\"ansiyellow\">(</span>str<span class=\"ansiyellow\">(</span>e<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    114</span>             <span class=\"ansigreen\">return</span> f_with_exception_handling<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    115</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ExecutionError</span>: An error occurred while calling z:com.databricks.backend.daemon.dbutils.FSUtils.cp.\n: java.io.FileNotFoundException: File file:/tmp/lzo/part-00000.lzo does not exist.\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:402)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:255)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.cp(DBUtilsCore.scala:75)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.cp(DBUtilsCore.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n\n</div>","startTime":1.438646937723E12,"submitTime":1.438646937665E12,"finishTime":1.438646937951E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"bb2c13fb-cedb-4b7f-87c5-11d81cc6ee9a"},{"version":"CommandV1","origId":1301,"guid":"2c9ace2b-ad16-4970-958f-f7565dfb0183","subtype":"command","commandType":"auto","position":9.5,"command":"%md\n\n### Step 5: Validate that the LZO file can be read.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.438646940556E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"705efd72-27ee-4463-894e-49460920ea71"},{"version":"CommandV1","origId":1302,"guid":"89863900-1efa-4a15-bdff-f738e0bab095","subtype":"command","commandType":"auto","position":10.5,"command":"sc.textFile(\"dbfs:/tmp/lzo/part-00000.lzo\").collect()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">41</span><span class=\"ansired\">]: </span>\n[u&apos;This is line 1&apos;,\n u&apos;This is line 2&apos;,\n u&apos;This is line 3&apos;,\n u&apos;This is line 4&apos;,\n u&apos;This is line 5&apos;,\n u&apos;This is line 6&apos;,\n u&apos;This is line 7&apos;,\n u&apos;This is line 8&apos;,\n u&apos;This is line 9&apos;,\n u&apos;This is line 10&apos;,\n u&apos;This is line 11&apos;,\n u&apos;This is line 12&apos;,\n u&apos;This is line 13&apos;,\n u&apos;This is line 14&apos;,\n u&apos;This is line 15&apos;,\n u&apos;This is line 16&apos;,\n u&apos;This is line 17&apos;,\n u&apos;This is line 18&apos;,\n u&apos;This is line 19&apos;,\n u&apos;This is line 20&apos;,\n u&apos;This is line 21&apos;,\n u&apos;This is line 22&apos;,\n u&apos;This is line 23&apos;,\n u&apos;This is line 24&apos;,\n u&apos;This is line 25&apos;,\n u&apos;This is line 26&apos;,\n u&apos;This is line 27&apos;,\n u&apos;This is line 28&apos;,\n u&apos;This is line 29&apos;,\n u&apos;This is line 30&apos;,\n u&apos;This is line 31&apos;,\n u&apos;This is line 32&apos;,\n u&apos;This is line 33&apos;,\n u&apos;This is line 34&apos;,\n u&apos;This is line 35&apos;,\n u&apos;This is line 36&apos;,\n u&apos;This is line 37&apos;,\n u&apos;This is line 38&apos;,\n u&apos;This is line 39&apos;,\n u&apos;This is line 40&apos;,\n u&apos;This is line 41&apos;,\n u&apos;This is line 42&apos;,\n u&apos;This is line 43&apos;,\n u&apos;This is line 44&apos;,\n u&apos;This is line 45&apos;,\n u&apos;This is line 46&apos;,\n u&apos;This is line 47&apos;,\n u&apos;This is line 48&apos;,\n u&apos;This is line 49&apos;,\n u&apos;This is line 50&apos;,\n u&apos;This is line 51&apos;,\n u&apos;This is line 52&apos;,\n u&apos;This is line 53&apos;,\n u&apos;This is line 54&apos;,\n u&apos;This is line 55&apos;,\n u&apos;This is line 56&apos;,\n u&apos;This is line 57&apos;,\n u&apos;This is line 58&apos;,\n u&apos;This is line 59&apos;,\n u&apos;This is line 60&apos;,\n u&apos;This is line 61&apos;,\n u&apos;This is line 62&apos;,\n u&apos;This is line 63&apos;,\n u&apos;This is line 64&apos;,\n u&apos;This is line 65&apos;,\n u&apos;This is line 66&apos;,\n u&apos;This is line 67&apos;,\n u&apos;This is line 68&apos;,\n u&apos;This is line 69&apos;,\n u&apos;This is line 70&apos;,\n u&apos;This is line 71&apos;,\n u&apos;This is line 72&apos;,\n u&apos;This is line 73&apos;,\n u&apos;This is line 74&apos;,\n u&apos;This is line 75&apos;,\n u&apos;This is line 76&apos;,\n u&apos;This is line 77&apos;,\n u&apos;This is line 78&apos;,\n u&apos;This is line 79&apos;,\n u&apos;This is line 80&apos;,\n u&apos;This is line 81&apos;,\n u&apos;This is line 82&apos;,\n u&apos;This is line 83&apos;,\n u&apos;This is line 84&apos;,\n u&apos;This is line 85&apos;,\n u&apos;This is line 86&apos;,\n u&apos;This is line 87&apos;,\n u&apos;This is line 88&apos;,\n u&apos;This is line 89&apos;,\n u&apos;This is line 90&apos;,\n u&apos;This is line 91&apos;,\n u&apos;This is line 92&apos;,\n u&apos;This is line 93&apos;,\n u&apos;This is line 94&apos;,\n u&apos;This is line 95&apos;,\n u&apos;This is line 96&apos;,\n u&apos;This is line 97&apos;,\n u&apos;This is line 98&apos;,\n u&apos;This is line 99&apos;,\n u&apos;This is line 100&apos;,\n u&apos;This is line 101&apos;,\n u&apos;This is line 102&apos;,\n u&apos;This is line 103&apos;,\n u&apos;This is line 104&apos;,\n u&apos;This is line 105&apos;,\n u&apos;This is line 106&apos;,\n u&apos;This is line 107&apos;,\n u&apos;This is line 108&apos;,\n u&apos;This is line 109&apos;,\n u&apos;This is line 110&apos;,\n u&apos;This is line 111&apos;,\n u&apos;This is line 112&apos;,\n u&apos;This is line 113&apos;,\n u&apos;This is line 114&apos;,\n u&apos;This is line 115&apos;,\n u&apos;This is line 116&apos;,\n u&apos;This is line 117&apos;,\n u&apos;This is line 118&apos;,\n u&apos;This is line 119&apos;,\n u&apos;This is line 120&apos;,\n u&apos;This is line 121&apos;,\n u&apos;This is line 122&apos;,\n u&apos;This is line 123&apos;,\n u&apos;This is line 124&apos;,\n u&apos;This is line 125&apos;,\n u&apos;This is line 126&apos;,\n u&apos;This is line 127&apos;,\n u&apos;This is line 128&apos;,\n u&apos;This is line 129&apos;,\n u&apos;This is line 130&apos;,\n u&apos;This is line 131&apos;,\n u&apos;This is line 132&apos;,\n u&apos;This is line 133&apos;,\n u&apos;This is line 134&apos;,\n u&apos;This is line 135&apos;,\n u&apos;This is line 136&apos;,\n u&apos;This is line 137&apos;,\n u&apos;This is line 138&apos;,\n u&apos;This is line 139&apos;,\n u&apos;This is line 140&apos;,\n u&apos;This is line 141&apos;,\n u&apos;This is line 142&apos;,\n u&apos;This is line 143&apos;,\n u&apos;This is line 144&apos;,\n u&apos;This is line 145&apos;,\n u&apos;This is line 146&apos;,\n u&apos;This is line 147&apos;,\n u&apos;This is line 148&apos;,\n u&apos;This is line 149&apos;,\n u&apos;This is line 150&apos;,\n u&apos;This is line 151&apos;,\n u&apos;This is line 152&apos;,\n u&apos;This is line 153&apos;,\n u&apos;This is line 154&apos;,\n u&apos;This is line 155&apos;,\n u&apos;This is line 156&apos;,\n u&apos;This is line 157&apos;,\n u&apos;This is line 158&apos;,\n u&apos;This is line 159&apos;,\n u&apos;This is line 160&apos;,\n u&apos;This is line 161&apos;,\n u&apos;This is line 162&apos;,\n u&apos;This is line 163&apos;,\n u&apos;This is line 164&apos;,\n u&apos;This is line 165&apos;,\n u&apos;This is line 166&apos;,\n u&apos;This is line 167&apos;,\n u&apos;This is line 168&apos;,\n u&apos;This is line 169&apos;,\n u&apos;This is line 170&apos;,\n u&apos;This is line 171&apos;,\n u&apos;This is line 172&apos;,\n u&apos;This is line 173&apos;,\n u&apos;This is line 174&apos;,\n u&apos;This is line 175&apos;,\n u&apos;This is line 176&apos;,\n u&apos;This is line 177&apos;,\n u&apos;This is line 178&apos;,\n u&apos;This is line 179&apos;,\n u&apos;This is line 180&apos;,\n u&apos;This is line 181&apos;,\n u&apos;This is line 182&apos;,\n u&apos;This is line 183&apos;,\n u&apos;This is line 184&apos;,\n u&apos;This is line 185&apos;,\n u&apos;This is line 186&apos;,\n u&apos;This is line 187&apos;,\n u&apos;This is line 188&apos;,\n u&apos;This is line 189&apos;,\n u&apos;This is line 190&apos;,\n u&apos;This is line 191&apos;,\n u&apos;This is line 192&apos;,\n u&apos;This is line 193&apos;,\n u&apos;This is line 194&apos;,\n u&apos;This is line 195&apos;,\n u&apos;This is line 196&apos;,\n u&apos;This is line 197&apos;,\n u&apos;This is line 198&apos;,\n u&apos;This is line 199&apos;,\n u&apos;This is line 200&apos;,\n u&apos;This is line 201&apos;,\n u&apos;This is line 202&apos;,\n u&apos;This is line 203&apos;,\n u&apos;This is line 204&apos;,\n u&apos;This is line 205&apos;,\n u&apos;This is line 206&apos;,\n u&apos;This is line 207&apos;,\n u&apos;This is line 208&apos;,\n u&apos;This is line 209&apos;,\n u&apos;This is line 210&apos;,\n u&apos;This is line 211&apos;,\n u&apos;This is line 212&apos;,\n u&apos;This is line 213&apos;,\n u&apos;This is line 214&apos;,\n u&apos;This is line 215&apos;,\n u&apos;This is line 216&apos;,\n u&apos;This is line 217&apos;,\n u&apos;This is line 218&apos;,\n u&apos;This is line 219&apos;,\n u&apos;This is line 220&apos;,\n u&apos;This is line 221&apos;,\n u&apos;This is line 222&apos;,\n u&apos;This is line 223&apos;,\n u&apos;This is line 224&apos;,\n u&apos;This is line 225&apos;,\n u&apos;This is line 226&apos;,\n u&apos;This is line 227&apos;,\n u&apos;This is line 228&apos;,\n u&apos;This is line 229&apos;,\n u&apos;This is line 230&apos;,\n u&apos;This is line 231&apos;,\n u&apos;This is line 232&apos;,\n u&apos;This is line 233&apos;,\n u&apos;This is line 234&apos;,\n u&apos;This is line 235&apos;,\n u&apos;This is line 236&apos;,\n u&apos;This is line 237&apos;,\n u&apos;This is line 238&apos;,\n u&apos;This is line 239&apos;,\n u&apos;This is line 240&apos;,\n u&apos;This is line 241&apos;,\n u&apos;This is line 242&apos;,\n u&apos;This is line 243&apos;,\n u&apos;This is line 244&apos;,\n u&apos;This is line 245&apos;,\n u&apos;This is line 246&apos;,\n u&apos;This is line 247&apos;,\n u&apos;This is line 248&apos;,\n u&apos;This is line 249&apos;,\n u&apos;This is line 250&apos;,\n u&apos;This is line 251&apos;,\n u&apos;This is line 252&apos;,\n u&apos;This is line 253&apos;,\n u&apos;This is line 254&apos;,\n u&apos;This is line 255&apos;,\n u&apos;This is line 256&apos;,\n u&apos;This is line 257&apos;,\n u&apos;This is line 258&apos;,\n u&apos;This is line 259&apos;,\n u&apos;This is line 260&apos;,\n u&apos;This is line 261&apos;,\n u&apos;This is line 262&apos;,\n u&apos;This is line 263&apos;,\n u&apos;This is line 264&apos;,\n u&apos;This is line 265&apos;,\n u&apos;This is line 266&apos;,\n u&apos;This is line 267&apos;,\n u&apos;This is line 268&apos;,\n u&apos;This is line 269&apos;,\n u&apos;This is line 270&apos;,\n u&apos;This is line 271&apos;,\n u&apos;This is line 272&apos;,\n u&apos;This is line 273&apos;,\n u&apos;This is line 274&apos;,\n u&apos;This is line 275&apos;,\n u&apos;This is line 276&apos;,\n u&apos;This is line 277&apos;,\n u&apos;This is line 278&apos;,\n u&apos;This is line 279&apos;,\n u&apos;This is line 280&apos;,\n u&apos;This is line 281&apos;,\n u&apos;This is line 282&apos;,\n u&apos;This is line 283&apos;,\n u&apos;This is line 284&apos;,\n u&apos;This is line 285&apos;,\n u&apos;This is line 286&apos;,\n u&apos;This is line 287&apos;,\n u&apos;This is line 288&apos;,\n u&apos;This is line 289&apos;,\n u&apos;This is line 290&apos;,\n u&apos;This is line 291&apos;,\n u&apos;This is line 292&apos;,\n u&apos;This is line 293&apos;,\n u&apos;This is line 294&apos;,\n u&apos;This is line 295&apos;,\n u&apos;This is line 296&apos;,\n u&apos;This is line 297&apos;,\n u&apos;This is line 298&apos;,\n u&apos;This is line 299&apos;,\n u&apos;This is line 300&apos;,\n u&apos;This is line 301&apos;,\n u&apos;This is line 302&apos;,\n u&apos;This is line 303&apos;,\n u&apos;This is line 304&apos;,\n u&apos;This is line 305&apos;,\n u&apos;This is line 306&apos;,\n u&apos;This is line 307&apos;,\n u&apos;This is line 308&apos;,\n u&apos;This is line 309&apos;,\n u&apos;This is line 310&apos;,\n u&apos;This is line 311&apos;,\n u&apos;This is line 312&apos;,\n u&apos;This is line 313&apos;,\n u&apos;This is line 314&apos;,\n u&apos;This is line 315&apos;,\n u&apos;This is line 316&apos;,\n u&apos;This is line 317&apos;,\n u&apos;This is line 318&apos;,\n u&apos;This is line 319&apos;,\n u&apos;This is line 320&apos;,\n u&apos;This is line 321&apos;,\n u&apos;This is line 322&apos;,\n u&apos;This is line 323&apos;,\n u&apos;This is line 324&apos;,\n u&apos;This is line 325&apos;,\n u&apos;This is line 326&apos;,\n u&apos;This is line 327&apos;,\n u&apos;This is line 328&apos;,\n u&apos;This is line 329&apos;,\n u&apos;This is line 330&apos;,\n u&apos;This is line 331&apos;,\n u&apos;This is line 332&apos;,\n u&apos;This is line 333&apos;,\n u&apos;This is line 334&apos;,\n u&apos;This is line 335&apos;,\n u&apos;This is line 336&apos;,\n u&apos;This is line 337&apos;,\n u&apos;This is line 338&apos;,\n u&apos;This is line 339&apos;,\n u&apos;This is line 340&apos;,\n u&apos;This is line 341&apos;,\n u&apos;This is line 342&apos;,\n u&apos;This is line 343&apos;,\n u&apos;This is line 344&apos;,\n u&apos;This is line 345&apos;,\n u&apos;This is line 346&apos;,\n u&apos;This is line 347&apos;,\n u&apos;This is line 348&apos;,\n u&apos;This is line 349&apos;,\n u&apos;This is line 350&apos;,\n u&apos;This is line 351&apos;,\n u&apos;This is line 352&apos;,\n u&apos;This is line 353&apos;,\n u&apos;This is line 354&apos;,\n u&apos;This is line 355&apos;,\n u&apos;This is line 356&apos;,\n u&apos;This is line 357&apos;,\n u&apos;This is line 358&apos;,\n u&apos;This is line 359&apos;,\n u&apos;This is line 360&apos;,\n u&apos;This is line 361&apos;,\n u&apos;This is line 362&apos;,\n u&apos;This is line 363&apos;,\n u&apos;This is line 364&apos;,\n u&apos;This is line 365&apos;,\n u&apos;This is line 366&apos;,\n u&apos;This is line 367&apos;,\n u&apos;This is line 368&apos;,\n u&apos;This is line 369&apos;,\n u&apos;This is line 370&apos;,\n u&apos;This is line 371&apos;,\n u&apos;This is line 372&apos;,\n u&apos;This is line 373&apos;,\n u&apos;This is line 374&apos;,\n u&apos;This is line 375&apos;,\n u&apos;This is line 376&apos;,\n u&apos;This is line 377&apos;,\n u&apos;This is line 378&apos;,\n u&apos;This is line 379&apos;,\n u&apos;This is line 380&apos;,\n u&apos;This is line 381&apos;,\n u&apos;This is line 382&apos;,\n u&apos;This is line 383&apos;,\n u&apos;This is line 384&apos;,\n u&apos;This is line 385&apos;,\n u&apos;This is line 386&apos;,\n u&apos;This is line 387&apos;,\n u&apos;This is line 388&apos;,\n u&apos;This is line 389&apos;,\n u&apos;This is line 390&apos;,\n u&apos;This is line 391&apos;,\n u&apos;This is line 392&apos;,\n u&apos;This is line 393&apos;,\n u&apos;This is line 394&apos;,\n u&apos;This is line 395&apos;,\n u&apos;This is line 396&apos;,\n u&apos;This is line 397&apos;,\n u&apos;This is line 398&apos;,\n u&apos;This is line 399&apos;,\n u&apos;This is line 400&apos;,\n u&apos;This is line 401&apos;,\n u&apos;This is line 402&apos;,\n u&apos;This is line 403&apos;,\n u&apos;This is line 404&apos;,\n u&apos;This is line 405&apos;,\n u&apos;This is line 406&apos;,\n u&apos;This is line 407&apos;,\n u&apos;This is line 408&apos;,\n u&apos;This is line 409&apos;,\n u&apos;This is line 410&apos;,\n u&apos;This is line 411&apos;,\n u&apos;This is line 412&apos;,\n u&apos;This is line 413&apos;,\n u&apos;This is line 414&apos;,\n u&apos;This is line 415&apos;,\n u&apos;This is line 416&apos;,\n u&apos;This is line 417&apos;,\n u&apos;This is line 418&apos;,\n u&apos;This is line 419&apos;,\n u&apos;This is line 420&apos;,\n u&apos;This is line 421&apos;,\n u&apos;This is line 422&apos;,\n u&apos;This is line 423&apos;,\n u&apos;This is line 424&apos;,\n u&apos;This is line 425&apos;,\n u&apos;This is line 426&apos;,\n u&apos;This is line 427&apos;,\n u&apos;This is line 428&apos;,\n u&apos;This is line 429&apos;,\n u&apos;This is line 430&apos;,\n u&apos;This is line 431&apos;,\n u&apos;This is line 432&apos;,\n u&apos;This is line 433&apos;,\n u&apos;This is line 434&apos;,\n u&apos;This is line 435&apos;,\n u&apos;This is line 436&apos;,\n u&apos;This is line 437&apos;,\n u&apos;This is line 438&apos;,\n u&apos;This is line 439&apos;,\n u&apos;This is line 440&apos;,\n u&apos;This is line 441&apos;,\n u&apos;This is line 442&apos;,\n u&apos;This is line 443&apos;,\n u&apos;This is line 444&apos;,\n u&apos;This is line 445&apos;,\n u&apos;This is line 446&apos;,\n u&apos;This is line 447&apos;,\n u&apos;This is line 448&apos;,\n u&apos;This is line 449&apos;,\n u&apos;This is line 450&apos;,\n u&apos;This is line 451&apos;,\n u&apos;This is line 452&apos;,\n u&apos;This is line 453&apos;,\n u&apos;This is line 454&apos;,\n u&apos;This is line 455&apos;,\n u&apos;This is line 456&apos;,\n u&apos;This is line 457&apos;,\n u&apos;This is line 458&apos;,\n... skipped 1936 bytes ...\n u&apos;This is line 547&apos;,\n u&apos;This is line 548&apos;,\n u&apos;This is line 549&apos;,\n u&apos;This is line 550&apos;,\n u&apos;This is line 551&apos;,\n u&apos;This is line 552&apos;,\n u&apos;This is line 553&apos;,\n u&apos;This is line 554&apos;,\n u&apos;This is line 555&apos;,\n u&apos;This is line 556&apos;,\n u&apos;This is line 557&apos;,\n u&apos;This is line 558&apos;,\n u&apos;This is line 559&apos;,\n u&apos;This is line 560&apos;,\n u&apos;This is line 561&apos;,\n u&apos;This is line 562&apos;,\n u&apos;This is line 563&apos;,\n u&apos;This is line 564&apos;,\n u&apos;This is line 565&apos;,\n u&apos;This is line 566&apos;,\n u&apos;This is line 567&apos;,\n u&apos;This is line 568&apos;,\n u&apos;This is line 569&apos;,\n u&apos;This is line 570&apos;,\n u&apos;This is line 571&apos;,\n u&apos;This is line 572&apos;,\n u&apos;This is line 573&apos;,\n u&apos;This is line 574&apos;,\n u&apos;This is line 575&apos;,\n u&apos;This is line 576&apos;,\n u&apos;This is line 577&apos;,\n u&apos;This is line 578&apos;,\n u&apos;This is line 579&apos;,\n u&apos;This is line 580&apos;,\n u&apos;This is line 581&apos;,\n u&apos;This is line 582&apos;,\n u&apos;This is line 583&apos;,\n u&apos;This is line 584&apos;,\n u&apos;This is line 585&apos;,\n u&apos;This is line 586&apos;,\n u&apos;This is line 587&apos;,\n u&apos;This is line 588&apos;,\n u&apos;This is line 589&apos;,\n u&apos;This is line 590&apos;,\n u&apos;This is line 591&apos;,\n u&apos;This is line 592&apos;,\n u&apos;This is line 593&apos;,\n u&apos;This is line 594&apos;,\n u&apos;This is line 595&apos;,\n u&apos;This is line 596&apos;,\n u&apos;This is line 597&apos;,\n u&apos;This is line 598&apos;,\n u&apos;This is line 599&apos;,\n u&apos;This is line 600&apos;,\n u&apos;This is line 601&apos;,\n u&apos;This is line 602&apos;,\n u&apos;This is line 603&apos;,\n u&apos;This is line 604&apos;,\n u&apos;This is line 605&apos;,\n u&apos;This is line 606&apos;,\n u&apos;This is line 607&apos;,\n u&apos;This is line 608&apos;,\n u&apos;This is line 609&apos;,\n u&apos;This is line 610&apos;,\n u&apos;This is line 611&apos;,\n u&apos;This is line 612&apos;,\n u&apos;This is line 613&apos;,\n u&apos;This is line 614&apos;,\n u&apos;This is line 615&apos;,\n u&apos;This is line 616&apos;,\n u&apos;This is line 617&apos;,\n u&apos;This is line 618&apos;,\n u&apos;This is line 619&apos;,\n u&apos;This is line 620&apos;,\n u&apos;This is line 621&apos;,\n u&apos;This is line 622&apos;,\n u&apos;This is line 623&apos;,\n u&apos;This is line 624&apos;,\n u&apos;This is line 625&apos;,\n u&apos;This is line 626&apos;,\n u&apos;This is line 627&apos;,\n u&apos;This is line 628&apos;,\n u&apos;This is line 629&apos;,\n u&apos;This is line 630&apos;,\n u&apos;This is line 631&apos;,\n u&apos;This is line 632&apos;,\n u&apos;This is line 633&apos;,\n u&apos;This is line 634&apos;,\n u&apos;This is line 635&apos;,\n u&apos;This is line 636&apos;,\n u&apos;This is line 637&apos;,\n u&apos;This is line 638&apos;,\n u&apos;This is line 639&apos;,\n u&apos;This is line 640&apos;,\n u&apos;This is line 641&apos;,\n u&apos;This is line 642&apos;,\n u&apos;This is line 643&apos;,\n u&apos;This is line 644&apos;,\n u&apos;This is line 645&apos;,\n u&apos;This is line 646&apos;,\n u&apos;This is line 647&apos;,\n u&apos;This is line 648&apos;,\n u&apos;This is line 649&apos;,\n u&apos;This is line 650&apos;,\n u&apos;This is line 651&apos;,\n u&apos;This is line 652&apos;,\n u&apos;This is line 653&apos;,\n u&apos;This is line 654&apos;,\n u&apos;This is line 655&apos;,\n u&apos;This is line 656&apos;,\n u&apos;This is line 657&apos;,\n u&apos;This is line 658&apos;,\n u&apos;This is line 659&apos;,\n u&apos;This is line 660&apos;,\n u&apos;This is line 661&apos;,\n u&apos;This is line 662&apos;,\n u&apos;This is line 663&apos;,\n u&apos;This is line 664&apos;,\n u&apos;This is line 665&apos;,\n u&apos;This is line 666&apos;,\n u&apos;This is line 667&apos;,\n u&apos;This is line 668&apos;,\n u&apos;This is line 669&apos;,\n u&apos;This is line 670&apos;,\n u&apos;This is line 671&apos;,\n u&apos;This is line 672&apos;,\n u&apos;This is line 673&apos;,\n u&apos;This is line 674&apos;,\n u&apos;This is line 675&apos;,\n u&apos;This is line 676&apos;,\n u&apos;This is line 677&apos;,\n u&apos;This is line 678&apos;,\n u&apos;This is line 679&apos;,\n u&apos;This is line 680&apos;,\n u&apos;This is line 681&apos;,\n u&apos;This is line 682&apos;,\n u&apos;This is line 683&apos;,\n u&apos;This is line 684&apos;,\n u&apos;This is line 685&apos;,\n u&apos;This is line 686&apos;,\n u&apos;This is line 687&apos;,\n u&apos;This is line 688&apos;,\n u&apos;This is line 689&apos;,\n u&apos;This is line 690&apos;,\n u&apos;This is line 691&apos;,\n u&apos;This is line 692&apos;,\n u&apos;This is line 693&apos;,\n u&apos;This is line 694&apos;,\n u&apos;This is line 695&apos;,\n u&apos;This is line 696&apos;,\n u&apos;This is line 697&apos;,\n u&apos;This is line 698&apos;,\n u&apos;This is line 699&apos;,\n u&apos;This is line 700&apos;,\n u&apos;This is line 701&apos;,\n u&apos;This is line 702&apos;,\n u&apos;This is line 703&apos;,\n u&apos;This is line 704&apos;,\n u&apos;This is line 705&apos;,\n u&apos;This is line 706&apos;,\n u&apos;This is line 707&apos;,\n u&apos;This is line 708&apos;,\n u&apos;This is line 709&apos;,\n u&apos;This is line 710&apos;,\n u&apos;This is line 711&apos;,\n u&apos;This is line 712&apos;,\n u&apos;This is line 713&apos;,\n u&apos;This is line 714&apos;,\n u&apos;This is line 715&apos;,\n u&apos;This is line 716&apos;,\n u&apos;This is line 717&apos;,\n u&apos;This is line 718&apos;,\n u&apos;This is line 719&apos;,\n u&apos;This is line 720&apos;,\n u&apos;This is line 721&apos;,\n u&apos;This is line 722&apos;,\n u&apos;This is line 723&apos;,\n u&apos;This is line 724&apos;,\n u&apos;This is line 725&apos;,\n u&apos;This is line 726&apos;,\n u&apos;This is line 727&apos;,\n u&apos;This is line 728&apos;,\n u&apos;This is line 729&apos;,\n u&apos;This is line 730&apos;,\n u&apos;This is line 731&apos;,\n u&apos;This is line 732&apos;,\n u&apos;This is line 733&apos;,\n u&apos;This is line 734&apos;,\n u&apos;This is line 735&apos;,\n u&apos;This is line 736&apos;,\n u&apos;This is line 737&apos;,\n u&apos;This is line 738&apos;,\n u&apos;This is line 739&apos;,\n u&apos;This is line 740&apos;,\n u&apos;This is line 741&apos;,\n u&apos;This is line 742&apos;,\n u&apos;This is line 743&apos;,\n u&apos;This is line 744&apos;,\n u&apos;This is line 745&apos;,\n u&apos;This is line 746&apos;,\n u&apos;This is line 747&apos;,\n u&apos;This is line 748&apos;,\n u&apos;This is line 749&apos;,\n u&apos;This is line 750&apos;,\n u&apos;This is line 751&apos;,\n u&apos;This is line 752&apos;,\n u&apos;This is line 753&apos;,\n u&apos;This is line 754&apos;,\n u&apos;This is line 755&apos;,\n u&apos;This is line 756&apos;,\n u&apos;This is line 757&apos;,\n u&apos;This is line 758&apos;,\n u&apos;This is line 759&apos;,\n u&apos;This is line 760&apos;,\n u&apos;This is line 761&apos;,\n u&apos;This is line 762&apos;,\n u&apos;This is line 763&apos;,\n u&apos;This is line 764&apos;,\n u&apos;This is line 765&apos;,\n u&apos;This is line 766&apos;,\n u&apos;This is line 767&apos;,\n u&apos;This is line 768&apos;,\n u&apos;This is line 769&apos;,\n u&apos;This is line 770&apos;,\n u&apos;This is line 771&apos;,\n u&apos;This is line 772&apos;,\n u&apos;This is line 773&apos;,\n u&apos;This is line 774&apos;,\n u&apos;This is line 775&apos;,\n u&apos;This is line 776&apos;,\n u&apos;This is line 777&apos;,\n u&apos;This is line 778&apos;,\n u&apos;This is line 779&apos;,\n u&apos;This is line 780&apos;,\n u&apos;This is line 781&apos;,\n u&apos;This is line 782&apos;,\n u&apos;This is line 783&apos;,\n u&apos;This is line 784&apos;,\n u&apos;This is line 785&apos;,\n u&apos;This is line 786&apos;,\n u&apos;This is line 787&apos;,\n u&apos;This is line 788&apos;,\n u&apos;This is line 789&apos;,\n u&apos;This is line 790&apos;,\n u&apos;This is line 791&apos;,\n u&apos;This is line 792&apos;,\n u&apos;This is line 793&apos;,\n u&apos;This is line 794&apos;,\n u&apos;This is line 795&apos;,\n u&apos;This is line 796&apos;,\n u&apos;This is line 797&apos;,\n u&apos;This is line 798&apos;,\n u&apos;This is line 799&apos;,\n u&apos;This is line 800&apos;,\n u&apos;This is line 801&apos;,\n u&apos;This is line 802&apos;,\n u&apos;This is line 803&apos;,\n u&apos;This is line 804&apos;,\n u&apos;This is line 805&apos;,\n u&apos;This is line 806&apos;,\n u&apos;This is line 807&apos;,\n u&apos;This is line 808&apos;,\n u&apos;This is line 809&apos;,\n u&apos;This is line 810&apos;,\n u&apos;This is line 811&apos;,\n u&apos;This is line 812&apos;,\n u&apos;This is line 813&apos;,\n u&apos;This is line 814&apos;,\n u&apos;This is line 815&apos;,\n u&apos;This is line 816&apos;,\n u&apos;This is line 817&apos;,\n u&apos;This is line 818&apos;,\n u&apos;This is line 819&apos;,\n u&apos;This is line 820&apos;,\n u&apos;This is line 821&apos;,\n u&apos;This is line 822&apos;,\n u&apos;This is line 823&apos;,\n u&apos;This is line 824&apos;,\n u&apos;This is line 825&apos;,\n u&apos;This is line 826&apos;,\n u&apos;This is line 827&apos;,\n u&apos;This is line 828&apos;,\n u&apos;This is line 829&apos;,\n u&apos;This is line 830&apos;,\n u&apos;This is line 831&apos;,\n u&apos;This is line 832&apos;,\n u&apos;This is line 833&apos;,\n u&apos;This is line 834&apos;,\n u&apos;This is line 835&apos;,\n u&apos;This is line 836&apos;,\n u&apos;This is line 837&apos;,\n u&apos;This is line 838&apos;,\n u&apos;This is line 839&apos;,\n u&apos;This is line 840&apos;,\n u&apos;This is line 841&apos;,\n u&apos;This is line 842&apos;,\n u&apos;This is line 843&apos;,\n u&apos;This is line 844&apos;,\n u&apos;This is line 845&apos;,\n u&apos;This is line 846&apos;,\n u&apos;This is line 847&apos;,\n u&apos;This is line 848&apos;,\n u&apos;This is line 849&apos;,\n u&apos;This is line 850&apos;,\n u&apos;This is line 851&apos;,\n u&apos;This is line 852&apos;,\n u&apos;This is line 853&apos;,\n u&apos;This is line 854&apos;,\n u&apos;This is line 855&apos;,\n u&apos;This is line 856&apos;,\n u&apos;This is line 857&apos;,\n u&apos;This is line 858&apos;,\n u&apos;This is line 859&apos;,\n u&apos;This is line 860&apos;,\n u&apos;This is line 861&apos;,\n u&apos;This is line 862&apos;,\n u&apos;This is line 863&apos;,\n u&apos;This is line 864&apos;,\n u&apos;This is line 865&apos;,\n u&apos;This is line 866&apos;,\n u&apos;This is line 867&apos;,\n u&apos;This is line 868&apos;,\n u&apos;This is line 869&apos;,\n u&apos;This is line 870&apos;,\n u&apos;This is line 871&apos;,\n u&apos;This is line 872&apos;,\n u&apos;This is line 873&apos;,\n u&apos;This is line 874&apos;,\n u&apos;This is line 875&apos;,\n u&apos;This is line 876&apos;,\n u&apos;This is line 877&apos;,\n u&apos;This is line 878&apos;,\n u&apos;This is line 879&apos;,\n u&apos;This is line 880&apos;,\n u&apos;This is line 881&apos;,\n u&apos;This is line 882&apos;,\n u&apos;This is line 883&apos;,\n u&apos;This is line 884&apos;,\n u&apos;This is line 885&apos;,\n u&apos;This is line 886&apos;,\n u&apos;This is line 887&apos;,\n u&apos;This is line 888&apos;,\n u&apos;This is line 889&apos;,\n u&apos;This is line 890&apos;,\n u&apos;This is line 891&apos;,\n u&apos;This is line 892&apos;,\n u&apos;This is line 893&apos;,\n u&apos;This is line 894&apos;,\n u&apos;This is line 895&apos;,\n u&apos;This is line 896&apos;,\n u&apos;This is line 897&apos;,\n u&apos;This is line 898&apos;,\n u&apos;This is line 899&apos;,\n u&apos;This is line 900&apos;,\n u&apos;This is line 901&apos;,\n u&apos;This is line 902&apos;,\n u&apos;This is line 903&apos;,\n u&apos;This is line 904&apos;,\n u&apos;This is line 905&apos;,\n u&apos;This is line 906&apos;,\n u&apos;This is line 907&apos;,\n u&apos;This is line 908&apos;,\n u&apos;This is line 909&apos;,\n u&apos;This is line 910&apos;,\n u&apos;This is line 911&apos;,\n u&apos;This is line 912&apos;,\n u&apos;This is line 913&apos;,\n u&apos;This is line 914&apos;,\n u&apos;This is line 915&apos;,\n u&apos;This is line 916&apos;,\n u&apos;This is line 917&apos;,\n u&apos;This is line 918&apos;,\n u&apos;This is line 919&apos;,\n u&apos;This is line 920&apos;,\n u&apos;This is line 921&apos;,\n u&apos;This is line 922&apos;,\n u&apos;This is line 923&apos;,\n u&apos;This is line 924&apos;,\n u&apos;This is line 925&apos;,\n u&apos;This is line 926&apos;,\n u&apos;This is line 927&apos;,\n u&apos;This is line 928&apos;,\n u&apos;This is line 929&apos;,\n u&apos;This is line 930&apos;,\n u&apos;This is line 931&apos;,\n u&apos;This is line 932&apos;,\n u&apos;This is line 933&apos;,\n u&apos;This is line 934&apos;,\n u&apos;This is line 935&apos;,\n u&apos;This is line 936&apos;,\n u&apos;This is line 937&apos;,\n u&apos;This is line 938&apos;,\n u&apos;This is line 939&apos;,\n u&apos;This is line 940&apos;,\n u&apos;This is line 941&apos;,\n u&apos;This is line 942&apos;,\n u&apos;This is line 943&apos;,\n u&apos;This is line 944&apos;,\n u&apos;This is line 945&apos;,\n u&apos;This is line 946&apos;,\n u&apos;This is line 947&apos;,\n u&apos;This is line 948&apos;,\n u&apos;This is line 949&apos;,\n u&apos;This is line 950&apos;,\n u&apos;This is line 951&apos;,\n u&apos;This is line 952&apos;,\n u&apos;This is line 953&apos;,\n u&apos;This is line 954&apos;,\n u&apos;This is line 955&apos;,\n u&apos;This is line 956&apos;,\n u&apos;This is line 957&apos;,\n u&apos;This is line 958&apos;,\n u&apos;This is line 959&apos;,\n u&apos;This is line 960&apos;,\n u&apos;This is line 961&apos;,\n u&apos;This is line 962&apos;,\n u&apos;This is line 963&apos;,\n u&apos;This is line 964&apos;,\n u&apos;This is line 965&apos;,\n u&apos;This is line 966&apos;,\n u&apos;This is line 967&apos;,\n u&apos;This is line 968&apos;,\n u&apos;This is line 969&apos;,\n u&apos;This is line 970&apos;,\n u&apos;This is line 971&apos;,\n u&apos;This is line 972&apos;,\n u&apos;This is line 973&apos;,\n u&apos;This is line 974&apos;,\n u&apos;This is line 975&apos;,\n u&apos;This is line 976&apos;,\n u&apos;This is line 977&apos;,\n u&apos;This is line 978&apos;,\n u&apos;This is line 979&apos;,\n u&apos;This is line 980&apos;,\n u&apos;This is line 981&apos;,\n u&apos;This is line 982&apos;,\n u&apos;This is line 983&apos;,\n u&apos;This is line 984&apos;,\n u&apos;This is line 985&apos;,\n u&apos;This is line 986&apos;,\n u&apos;This is line 987&apos;,\n u&apos;This is line 988&apos;,\n u&apos;This is line 989&apos;,\n u&apos;This is line 990&apos;,\n u&apos;This is line 991&apos;,\n u&apos;This is line 992&apos;,\n u&apos;This is line 993&apos;,\n u&apos;This is line 994&apos;,\n u&apos;This is line 995&apos;,\n u&apos;This is line 996&apos;,\n u&apos;This is line 997&apos;,\n u&apos;This is line 998&apos;,\n u&apos;This is line 999&apos;,\n u&apos;This is line 1000&apos;,\n ...]\n</div>","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":1.438646968219E12,"submitTime":1.438646968135E12,"finishTime":1.438646968852E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"0235b932-5189-4467-bd10-21843213e651"},{"version":"CommandV1","origId":1303,"guid":"f13c07d5-24fc-45ed-9c87-7be03a8e9a28","subtype":"command","commandType":"auto","position":11.5,"command":"%md\n\n### Troubleshooting\n\nIf you see an error like this when you are reading in your LZO files:\n\n`java.io.IOException: Compressed with incompatible lzo version: 0x2080 (expected 0x2050)`\n\nThen this means the LZO version that was installed on your Databricks Spark cluster is not the same one you used to compress your files.  If you have this error, go back to the install script and change it to install your version of LZO.\n\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"startTime":0.0,"submitTime":1.438657350067E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":null,"diffDeletes":null,"globalVars":{},"latestUser":"vida","iPythonMetadata":null,"nuid":"ccf553f7-37ec-4a80-9415-821e08dfe8c3"}],"guid":"ebb05969-1af3-47ca-8ff6-72e1ba8c4391","globalVars":{},"iPythonMetadata":null};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":-1,"guid":"44ed0874-2e53-4b68-8905-e4b6caa3657f","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](../../index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{},"plotOptions":null},"errorSummary":null,"error":null,"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","iPythonMetadata":null};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201512022229240000-094163cf51fcd4717c3ea96799d1008723ae8985/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>